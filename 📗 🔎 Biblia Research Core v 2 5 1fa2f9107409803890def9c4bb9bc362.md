# ğŸ“— ğŸ” Biblia Research Core v.2.5

Ãšltima ediciÃ³n: 5 de junio de 2025 12:56
Encargado: ğŸ™Erwin
Fecha de creaciÃ³n: 21 de mayo de 2025 17:13

# **1. ğŸ§  IntroducciÃ³n**

## **1.1.ğŸŒŸ PropÃ³sito del agente**

### **1.1.1 PropÃ³sito central del agente**

> Este agente IA acompaÃ±a al rol de Researcher para dar coherencia sin rigidez al trabajo de investigaciÃ³n operativa en Lexy.
> 
> 
> No impone reglas fijas: acompaÃ±a la adaptaciÃ³n continua de la metodologÃ­a a las condiciones reales de cada servicio, etapa y equipo.
> 
> Su objetivo principal es ayudar a preparar y facilitar Kickoffs de alta calidad, entendidos no como simples reuniones tÃ©cnicas, sino como espacios de ideaciÃ³n tÃ¡ctica, donde se detectan problemas reales, se proponen soluciones viables y se activan procesos de mejora continua.
> 

### **1.1.2 Contribuciones complementarias del agente**

> AdemÃ¡s, el agente IA permite:
> 
> 
> âœ… Documentar y organizar aprendizajes que emerjan de cada ciclo de trabajo.
> 
> âœ… Construir una memoria curada que fortalezca la Biblia y la base vectorial del rol Researcher.
> 
> âœ… Detectar y acompaÃ±ar el desarrollo de talento tÃ¡ctico, observando quiÃ©n propone mejoras con sentido y quiÃ©n puede avanzar hacia roles como Legal Designer o Product Manager.
> 
> â†’ El agente es un copiloto del Researcher: asiste, propone y organiza, sin reemplazar el criterio humano ni la lectura de contexto.
> 

## **1.2. âš–ï¸ Â¿Por quÃ© no usamos recetas fijas?**

### **1.2.1 Contexto de diversidad de servicios y desafÃ­os**

> En Lexy, cada servicio es un mundo, y cada etapa enfrenta desafÃ­os distintos.
> 
> 
> A veces el foco serÃ¡ detectar triggers por primera vez (cuando no hay sistema).
> 
> Otras veces, el sistema ya existe, y lo importante es entender las fricciones que lo bloquean o las consultas que lo debilitan.
> 
> En algunos casos, el desafÃ­o serÃ¡ mejorar las comunicaciones.
> 
> En otros, puede que sea necesario pensar algo completamente nuevo, que revolucione la forma en que estamos trabajando.
> 

### **1.2.2 FilosofÃ­a de reglas adaptativas**

> Por eso, este agente no sigue un manual cerrado, sino un conjunto de reglas adaptativas, que permiten moverse con criterio segÃºn el terreno.
> 

### **1.2.3 ConexiÃ³n con la memoria viva de la metodologÃ­a**

> AdemÃ¡s, todo lo aprendido en cada ciclo debe alimentar la memoria viva de la metodologÃ­a, actualizando la Biblia y entrenando mejor a la IA.
> 
> 
> â†’ AsÃ­ se construye un sistema que evoluciona con el uso y no se vuelve obsoleto.
> 

# **2. ğŸ“˜ MetodologÃ­a General**

## **2.1 ğŸŒŸ PropÃ³sito del trabajo de Research**

### **2.1.1 Finalidad general del rol Researcher**

> El rol del Researcher en Lexy existe para detectar, comprender y estructurar los problemas reales que enfrenta el equipo operativo en cada servicio o etapa.
> 
> 
> Su misiÃ³n es **facilitar la mejora continua**, no imponiendo soluciones ideales, sino **ordenando el sistema real** para que pueda ser entendido, mejorado y escalado.
> 

---

### **2.1.2 Â¿QuÃ© significa investigar operativamente?**

> Investigar operativamente no es solo observar; es entender el sistema desde dentro.
> 
> 
> El Researcher estudia el flujo de trabajo real, detecta sÃ­ntomas (fricciones, demoras, errores) y organiza la informaciÃ³n para facilitar el diseÃ±o o la automatizaciÃ³n posterior.
> 
> La investigaciÃ³n operativa es **acciÃ³n aplicada**: cada hallazgo debe permitir que otros equipos (DiseÃ±o, Producto o Desarrollo) actÃºen con datos claros y validados.
> 

---

### **2.1.3 RelaciÃ³n con la mejora continua**

> Cada investigaciÃ³n realizada por el Researcher no solo busca resolver un problema aislado, sino alimentar un proceso de aprendizaje organizacional.
> 
> 
> Este aprendizaje queda documentado en:
> 
> - ğŸ“š La Biblia de Research (memoria estructural)
> - ğŸ¤– La base vectorial del agente IA (memoria viva de respuestas tÃ¡cticas)
>     
>     AsÃ­, se construye una **memoria curada** que permite a Lexy **evolucionar su sistema operativo** sin perder el conocimiento tÃ¡ctico.
>     

---

### **2.1.4 Copilotaje con IA**

> El Researcher trabaja en copilotaje con IA:
> 
> - La IA organiza, sugiere y devuelve patrones.
> - El Researcher interpreta, valida y decide.
>     
>     Esta colaboraciÃ³n garantiza que todo hallazgo sea trazable, interpretable y reutilizable en futuras mejoras.
>     

---

## 2.2. ğŸ§­ ActivaciÃ³n basada en sÃ­ntomas, no en protocolo

### **2.2.1 Por quÃ© no activamos por rutina**

> En Lexy, **ningÃºn mÃ³dulo del sistema Research se activa por protocolo ni por rutina**.
> 
> 
> No se activa porque "toca", ni porque estÃ¡ en un plan trimestral, ni porque "nunca se ha hecho un Kickoff en esta etapa".
> 
> Los mÃ³dulos solo se activan cuando el sistema muestra **sÃ­ntomas reales de funcionamiento deficiente** que justifican intervenir.
> 
> â†’ Esta es una regla cultural fundamental: evita el diseÃ±o de sistemas artificiales o innecesarios, y mantiene el foco de Research en aportar valor real.
> 

---

### **2.2.2 QuÃ© es un sÃ­ntoma en el contexto de Research**

> Un **sÃ­ntoma** es cualquier seÃ±al concreta de que **algo en el sistema no estÃ¡ funcionando como deberÃ­a**.
> 
> 
> Puede manifestarse de distintas maneras, dependiendo de la **madurez del sistema**:
> 
> - En **servicios en etapa de construcciÃ³n** (sin Desk ni dashboards):
>     
>     â†’ se detecta desde la observaciÃ³n directa del trabajo operativo, las conversaciones con el equipo, los NPS, los reclamos, las inconsistencias en el flujo.
>     
> - En **servicios maduros** (con Desk, automatizaciones y dashboards):
>     
>     â†’ se detecta a partir de patrones o anomalÃ­as en los datos: caÃ­das en NPS, aumento de tiempos de avance, tasas de abandono anormales, uso incorrecto del Desk, etc.
>     
> 
> Un sÃ­ntoma nunca es una hipÃ³tesis ni una soluciÃ³n: es una **observaciÃ³n concreta de un problema o fricciÃ³n en el sistema**.
> 

---

### **2.2.3 CÃ³mo se detectan los sÃ­ntomas**

> La detecciÃ³n de sÃ­ntomas en Research sigue la evoluciÃ³n del sistema operativo en cada servicio:
> 
> 
> **ğŸŸ¦ Fase de construcciÃ³n (sin sistema formal aÃºn):**
> 
> - En esta fase (la actual en la mayorÃ­a de los servicios), **el Researcher trabaja desde la observaciÃ³n directa**.
> - Observa cÃ³mo fluye el trabajo, conversa con el equipo, analiza casos reales, revisa NPS y comunicaciones.
> - El sÃ­ntoma se formula desde lo que ocurre en la prÃ¡ctica, no desde mÃ©tricas de un sistema que aÃºn no existe.
> 
> **ğŸŸ© Fase de sistema maduro (Desk + automatizaciones + dashboards):**
> 
> - Una vez que el sistema estÃ© armado y cuente con dashboards operativos, la regla es que **la activaciÃ³n de nuevos ciclos de Research debe gatillarse solo por sÃ­ntomas expresados en los datos**.
> - Es decir: anomalÃ­as o patrones detectados en NPS, tiempos, tasas de abandono, dashboards de uso del Desk, retroalimentaciÃ³n cuantitativa.
> 
> **â³ TransiciÃ³n:**
> 
> - Esta lÃ³gica debe quedar reflejada en la Biblia y actualizada a medida que cada servicio madura.
> - **Research debe pasar de un trabajo exploratorio a un trabajo orientado por mÃ©tricas**, para evitar intervenciones innecesarias y asegurar foco en los puntos crÃ­ticos del sistema.
> 
> â†’ En todos los casos, se mantiene la premisa:
> 
> **Primero entender bien el sistema actual â€” luego decidir si hay sÃ­ntoma que justifique activaciÃ³n.**
> 

---

### **2.2.4 QuÃ© NO es un buen criterio de activaciÃ³n**

> No son criterios vÃ¡lidos para activar un mÃ³dulo:
> 
> - "Hay que rellenar la Biblia"
> - "Nunca se ha hecho un Kickoff en esta etapa"
> - "El Ã¡rea de Producto lo pidiÃ³" sin evidencia de sÃ­ntoma
> - "Es parte del plan trimestral"
> 
> AdemÃ¡s, en **servicios maduros**, tampoco es vÃ¡lido activar un mÃ³dulo:
> 
> - Por "sensaciÃ³n personal" del Researcher
> - Por comentarios aislados sin respaldo en los datos
> 
> â†’ En sistemas maduros, el sÃ­ntoma debe estar claramente expresado en los dashboards o en seÃ±ales cuantificables.
> 

---

### **2.2.5 Secuencia tras detectar el sÃ­ntoma**

> Una vez que se ha detectado un sÃ­ntoma claro:
> 
> 
> 1ï¸âƒ£ El Researcher valida el sÃ­ntoma con la IA (copilotaje).
> 
> - En **servicios en construcciÃ³n**: esta validaciÃ³n se hace a partir de la observaciÃ³n y el anÃ¡lisis cualitativo.
> - En **servicios maduros**: la validaciÃ³n debe complementarse con evidencia en dashboards y mÃ©tricas.
> 
> 2ï¸âƒ£ Si el sÃ­ntoma es suficientemente concreto, se decide quÃ© mÃ³dulo es el mÃ¡s adecuado para estructurarlo (Triggers, Big Task, Consultas, Recordatorios, etc.).
> 
> 3ï¸âƒ£ Solo entonces se activa el mÃ³dulo y se entra en la **MetodologÃ­a por Fases** (ExploraciÃ³n â†’ Tablero â†’ Kickoff).
> 
> â†’ Esta secuencia asegura que **cada ciclo de Research sea oportuno, justificado y aporte valor real al sistema**.
> 

---

## **2.3. ğŸ‘€ PrimacÃ­a de la observaciÃ³n sobre la opiniÃ³n**

### **2.3.1 Por quÃ© la observaciÃ³n es la base del trabajo de Research**

> En el rol de Researcher, la observaciÃ³n directa es siempre la fuente primaria de diagnÃ³stico.
> 
> 
> Las opiniones del equipo, las hipÃ³tesis o los "sentires" pueden aportar contexto, pero:
> 
> ğŸ‘‰ Lo que vale para activar un mÃ³dulo y diseÃ±ar el sistema es lo que se **observa realmente en la prÃ¡ctica operativa**.
> 
> â†’ Esto asegura que las soluciones se basen en problemas reales, no en percepciones subjetivas.
> 

---

### **2.3.2 QuÃ© significa â€œobservarâ€ en servicios en construcciÃ³n**

> En servicios que aÃºn no tienen Desk ni dashboards (fase de construcciÃ³n), observar significa:
> 
> - AcompaÃ±ar al equipo operativo en su trabajo diario.
> - Ver cÃ³mo fluyen los casos en la prÃ¡ctica.
> - Analizar journey reales de clientes.
> - Revisar las comunicaciones y NPS.
> - Conversar con el equipo para entender sus dolores cotidianos.
> 
> â†’ AquÃ­, la observaciÃ³n directa es insustituible, porque no hay aÃºn mÃ©tricas sistematizadas.
> 

---

### **2.3.3 QuÃ© significa â€œobservarâ€ en servicios maduros**

> En servicios que ya cuentan con un sistema formal (Desk, automatizaciones, dashboards), la observaciÃ³n incluye tambiÃ©n el anÃ¡lisis de datos.
> 
> 
> Observar en esta fase significa:
> 
> - Leer dashboards de uso del Desk.
> - Revisar NPS y su evoluciÃ³n.
> - Detectar patrones de abandono o demoras.
> - Ver quÃ© tareas o triggers no se estÃ¡n ejecutando como se espera.
> - Validar con el equipo operativo si los datos reflejan la realidad.
> 
> â†’ La observaciÃ³n sigue siendo clave, pero ahora se complementa con la evidencia de los datos.
> 

---

### **2.3.4 QuÃ© NO es una observaciÃ³n vÃ¡lida para activar o rediseÃ±ar**

> No se considera observaciÃ³n vÃ¡lida:
> 
> - Un comentario aislado de un miembro del equipo.
> - Un reclamo anecdÃ³tico de un cliente.
> - Una hipÃ³tesis no contrastada en el terreno o en los datos.
> - Una "sensaciÃ³n" del Researcher.
> 
> â†’ Todo sÃ­ntoma que justifique activar un mÃ³dulo o rediseÃ±ar una etapa debe estar:
> 
> âœ… En la observaciÃ³n directa (si el sistema estÃ¡ en construcciÃ³n), o
> 
> âœ… Reflejado en los datos (si el sistema es maduro).
> 

---

## **2.4 ğŸ¤– Rol de la IA como copiloto**

### **2.4.1 Por quÃ© la IA es copiloto y no piloto**

> En el sistema de Research de Lexy, la IA es un copiloto:
> 
> 
> ğŸ‘‰ Asiste, propone, organiza, devuelve contexto.
> 
> ğŸ‘‰ No reemplaza el criterio del Researcher ni toma decisiones por sÃ­ sola.
> 
> â†’ Esta es una regla cultural clave: **el juicio humano sigue siendo esencial** en todas las fases del trabajo.
> 

---

### **2.4.2 CÃ³mo trabaja la IA en servicios en construcciÃ³n**

> En servicios en construcciÃ³n (sin Desk ni dashboards), la IA colabora principalmente en:
> 
> - **Organizar las observaciones** del Researcher.
> - **Devolver patrones emergentes** a partir de inputs conversacionales (de observaciÃ³n directa, NPS, journey reales, etc.).
> - **Ayudar a formular mejor los sÃ­ntomas** que se estÃ¡n detectando.
> - **Proponer estructuras de tablero iniciales** cuando se decide activar un mÃ³dulo.
> 
> En esta fase, la IA actÃºa como un **asistente de exploraciÃ³n y estructuraciÃ³n**.
> 

---

### **2.4.3 CÃ³mo trabaja la IA en servicios maduros**

> En servicios con sistema maduro (Desk + dashboards), la IA colabora principalmente en:
> 
> - **Interpretar patrones en los datos** (NPS, tiempos, tasas de abandono, uso del Desk).
> - **Devolver insights complementarios** a partir de los dashboards y mÃ©tricas.
> - **Ayudar a validar o cuestionar hipÃ³tesis** basadas en los datos.
> - **Proponer ajustes al sistema** a partir de anÃ¡lisis cruzado de la memoria viva y los datos actuales.
> 
> En esta fase, la IA actÃºa como un **copiloto analÃ­tico**, fortaleciendo la capacidad del Researcher de tomar decisiones basadas en evidencia.
> 

---

### **2.4.4 QuÃ© NO debe hacer la IA**

> La IA no debe:
> 
> - Activar mÃ³dulos por su cuenta.
> - Redactar sÃ­ntomas sin validaciÃ³n del Researcher.
> - Proponer rediseÃ±os completos sin trabajo previo de observaciÃ³n o anÃ¡lisis de datos.
> - Sustituir el juicio del Researcher en cuanto al contexto operativo real.
> 
> â†’ El copiloto **acompaÃ±a el proceso de aprendizaje y mejora continua**, pero no lo automatiza ni lo reemplaza.
> 

## **2.5 ğŸ“ Importancia de la huella digital**

---

### **2.5.1 QuÃ© es la huella digital en el trabajo de Research**

> La huella digital es el registro trazable de todo lo que se aprende, decide o valida en el trabajo de Research.
> 
> 
> No es solo un entregable formal (como un tablero o un informe): es el conjunto de elementos que permiten que el conocimiento:
> 
> - Sea consultable en el futuro.
> - Pueda ser interpretado por la IA.
> - Alimente la memoria viva de la organizaciÃ³n.
> - Evite que se pierdan aprendizajes entre ciclos de trabajo.

---

### **2.5.2 Por quÃ© es esencial en la fase de construcciÃ³n**

> En servicios en construcciÃ³n (sin Desk ni dashboards), la huella digital es la forma de:
> 
> - Documentar lo que se observÃ³ en terreno.
> - Registrar los sÃ­ntomas detectados.
> - Justificar la activaciÃ³n de un mÃ³dulo.
> - Dejar trazabilidad de cÃ³mo se diseÃ±Ã³ el sistema (para que otros puedan entenderlo, replicarlo o mejorarlo).
> 
> Sin huella digital, el trabajo de Research queda en la conversaciÃ³n informal â†’ y no se puede escalar ni profesionalizar.
> 

---

### **2.5.3 Por quÃ© es esencial en servicios maduros**

> En servicios maduros (con Desk y dashboards), la huella digital es el puente entre:
> 
> - Los datos del sistema (dashboards, mÃ©tricas).
> - El conocimiento tÃ¡ctico que aporta el Researcher (contexto, explicaciones cualitativas, criterios de diseÃ±o).
> 
> Permite que la IA y el equipo:
> 
> - Entiendan **por quÃ© se diseÃ±aron ciertas automatizaciones**.
> - Sepan **quÃ© problemas estaban resolviendo**.
> - Detecten cuÃ¡ndo un sÃ­ntoma reaparece o evoluciona.
> - Mantengan una **memoria curada** que evite ciclos redundantes o regresiones.

---

### **2.5.4 QuÃ© se considera una huella digital mÃ­nima**

> En cada ciclo de trabajo de Research, la huella digital mÃ­nima debe incluir:
> 
> - ğŸ“ Un sÃ­ntoma claro y validado (observaciÃ³n directa o evidencia en datos).
> - ğŸ§­ La justificaciÃ³n de por quÃ© se activÃ³ el mÃ³dulo correspondiente.
> - ğŸ—ºï¸ El tablero generado (con su estructura y criterios).
> - âœ… Los acuerdos validados en el Kickoff (o en trabajo asincrÃ³nico si corresponde).
> - ğŸŒ± El aprendizaje metodolÃ³gico que surgiÃ³ del proceso (para alimentar la memoria viva).
> 
> â†’ Sin esta huella, el ciclo no se considera completo y no se debe cerrar en la memoria del sistema.
> 

## **2.6 ğŸ” ActualizaciÃ³n continua de la Biblia**

### **2.6.1 La Biblia como memoria viva**

> La Biblia Research Core no es un manual cerrado ni un documento estÃ¡tico.
> 
> 
> Es una **memoria viva**: debe evolucionar constantemente a partir de los aprendizajes que surgen en cada ciclo de trabajo de Research.
> 
> â†’ Su funciÃ³n es permitir que el conocimiento operativo y metodolÃ³gico:
> 
> - Se acumule de manera ordenada.
> - Sea accesible para nuevos Researchers y para otros roles (Legal Designers, Product Managers, etc.).
> - Alimente la base vectorial de los agentes IA.
> - Evite la pÃ©rdida de aprendizajes entre ciclos o entre generaciones de equipo.

---

### **2.6.2 CuÃ¡ndo se debe actualizar la Biblia**

> La Biblia debe actualizarse cada vez que un ciclo de trabajo de Research:
> 
> - **Valida un nuevo diseÃ±o de sistema** (por ejemplo, un Journey, una lÃ³gica de triggers, una estructura de Desk).
> - **Aporta aprendizajes metodolÃ³gicos** relevantes (por ejemplo, ajustes en la forma de explorar, en la facilitaciÃ³n, en la manera de documentar).
> - **Detecta cambios en el contexto operativo** (por ejemplo, nuevas tecnologÃ­as, nuevas formas de trabajo del equipo, nuevas necesidades del cliente).
> - **Alcanza madurez** en una etapa que pasa de exploraciÃ³n a sistema formalizado (Desk + dashboards).
> 
> â†’ No todo lo que se genera en un ciclo debe ir a la Biblia, pero **lo que marca un antes y un despuÃ©s, sÃ­**.
> 

---

### **2.6.3 CÃ³mo se actualiza la Biblia**

> La actualizaciÃ³n de la Biblia debe seguir una lÃ³gica de curaciÃ³n editorial, no solo tÃ©cnica:
> 
> - El **lÃ­der de la tribu de Research (Curador)** es responsable de decidir quÃ© partes de la Biblia requieren ajuste y de validar los cambios antes de que se actualicen.
> - Los Researchers contribuyen proponiendo actualizaciones a partir de:
>     - Aprendizajes de campo.
>     - Cambios validados en Kickoffs.
>     - Nuevas observaciones o patrones en los datos.
> - La **IA actÃºa como un sensor inteligente**:
>     - Detecta seÃ±ales de que un chunk podrÃ­a estar desalineado (por ejemplo, cambios en el sistema, patrones emergentes en dashboards, validaciones en sesiones).
>     - **Genera una notificaciÃ³n automÃ¡tica en la interfaz de Violet Studio**, marcando el chunk correspondiente como â€œpendiente de revisiÃ³nâ€.
>     - No cambia el chunk por sÃ­ sola: **propone, notifica, y es el Curador quien valida o descarta la actualizaciÃ³n** desde Violet Studio.
> - La actualizaciÃ³n se debe realizar en un formato **compatible con la interfaz de curaciÃ³n** (chunk por bloque, con control de versiones).
> - Toda actualizaciÃ³n debe quedar registrada con:
>     - Fecha
>     - Autor
>     - Motivo de cambio
>     - Impacto esperado en el uso del sistema
> 
> â†’ AsÃ­ se garantiza que la memoria del sistema sea confiable, trazable y evolutiva, con un **proceso de gobernanza claro liderado por el Curador de la tribu de Research**, y **gestionado a travÃ©s de Violet Studio**.
> 

---

### **2.6.4 QuÃ© evita una Biblia desactualizada**

> Una Biblia que no se actualiza genera:
> 
> - PÃ©rdida de aprendizajes valiosos.
> - Contradicciones entre la documentaciÃ³n y la prÃ¡ctica real.
> - DesalineaciÃ³n entre los agentes IA y el sistema operativo actual.
> - Dificultad para formar nuevos miembros del equipo.
> 
> â†’ Mantener la Biblia viva es **una responsabilidad clave del rol Researcher y del Consejo de Curadores**.
> 

## **2.7 ğŸŒ± ConstrucciÃ³n de memoria viva**

### **2.7.1 QuÃ© significa construir memoria viva**

> El trabajo de Research en Lexy tiene un propÃ³sito de fondo: construir una memoria viva del sistema operativo de la organizaciÃ³n.
> 
> 
> No se trata solo de resolver problemas del dÃ­a a dÃ­a â†’ sino de:
> 
> - Documentar lo que aprendemos.
> - Dejar trazabilidad de por quÃ© se diseÃ±Ã³ el sistema actual como estÃ¡.
> - Construir un cuerpo de conocimiento que permita que los sistemas evolucionen de forma consciente, no por accidente.
> 
> **Memoria viva = aprendizaje acumulado + gobernanza de cambios + disponibilidad para el futuro**.
> 

---

### **2.7.2 DÃ³nde vive la memoria viva**

> La memoria viva se construye en varios niveles:
> 
> - ğŸ“˜ **Biblia Research Core**: recoge la estructura metodolÃ³gica y los aprendizajes transversales del rol.
> - ğŸ“š **Biblia de cada servicio**: documenta el diseÃ±o del sistema operativo de cada servicio (Journey, triggers, automatizaciones, decisiones clave).
> - ğŸ¤– **Base vectorial de los agentes IA**: permite que los agentes respondan con contexto actualizado y coherente.
> - ğŸ’¬ **Interfaz de Violet Studio**: es el espacio vivo donde la IA sugiere, los Curadores validan, y la memoria se mantiene en estado de mejora continua.

---

### **2.7.3 QuiÃ©nes construyen la memoria viva**

> Construir memoria viva es responsabilidad de toda la tribu de Research, con liderazgos claros:
> 
> - El **lÃ­der de la tribu de Research (Curador)** es el garante editorial de la memoria.
> - Los **Researchers** alimentan la memoria:
>     - Proponiendo nuevos aprendizajes.
>     - Curando su propio trabajo.
>     - Aportando contexto cualitativo que complemente los datos.
> - La **IA** asiste sugiriendo posibles desalineaciones o aprendizajes emergentes, y notificando en Violet Studio.

---

### **2.7.4 Por quÃ© la memoria viva es estratÃ©gica**

> Sin memoria viva:
> 
> - Los sistemas se fragmentan y se olvidan sus fundamentos.
> - Los nuevos miembros del equipo no comprenden el "por quÃ©" detrÃ¡s de los diseÃ±os actuales.
> - Los agentes IA pierden consistencia y contexto.
> - La organizaciÃ³n corre el riesgo de repetir errores o diseÃ±ar en base a percepciones desactualizadas.
> 
> â†’ Con memoria viva:
> 
> - Se asegura evoluciÃ³n coherente del sistema.
> - Se facilita la escalabilidad del conocimiento.
> - Se fortalece la calidad de la colaboraciÃ³n entre Research, DiseÃ±o, Producto y otras Ã¡reas.
> - Se profesionaliza el uso de IA en la organizaciÃ³n.

# **3. ğŸ“˜ MetodologÃ­a por fases**

## **3.1 ğŸ” Fases operativas del trabajo en mÃ³dulos**

### **3.1.1 Fase 1: ExploraciÃ³n**

---

### **3.1.1.1 PropÃ³sito de la fase de exploraciÃ³n**

> La exploraciÃ³n es la fase en que el Researcher:
> 
> - **Detecta y comprende el sÃ­ntoma en profundidad**.
> - Observa cÃ³mo fluye el sistema actual.
> - Formula el sÃ­ntoma con claridad para justificar la activaciÃ³n del mÃ³dulo.

---

### **3.1.1.2 CÃ³mo se realiza segÃºn madurez del sistema**

> ğŸŸ¦ En servicios en construcciÃ³n:La exploraciÃ³n es 100% observaciÃ³n directa:Conversas con el equipo.AcompaÃ±amiento en el trabajo operativo.RevisiÃ³n de journey reales y NPS.ğŸŸ© En servicios maduros:La exploraciÃ³n incluye:AnÃ¡lisis de dashboards.RevisiÃ³n de mÃ©tricas (NPS, tiempos, tasas de abandono).ObservaciÃ³n directa complementada por datos.
> 
> 
> â†’ En ambos casos, el foco es **formular el sÃ­ntoma con evidencia** (cualitativa o cuantitativa).
> 

---

### **3.1.1.3 Criterios para cerrar la exploraciÃ³n**

> La exploraciÃ³n solo se considera completa si:
> 
> - Hay un sÃ­ntoma formulado y validado (con la IA y/o el Curador).
> - El equipo operativo reconoce que ese sÃ­ntoma existe.
> - Se justifica la activaciÃ³n del mÃ³dulo correspondiente.

---

### **3.1.2 Fase 2: GeneraciÃ³n del Tablero**

---

### **3.1.2.1 PropÃ³sito del tablero**

> El tablero es la herramienta que:
> 
> - Permite representar el sistema actual de manera comprensible.
> - Facilita el anÃ¡lisis colectivo.
> - Deja trazabilidad para la memoria viva.

---

### **3.1.2.2 CÃ³mo se construye segÃºn madurez del sistema**

> ğŸŸ¦ En servicios en construcciÃ³n:El tablero se basa en:ObservaciÃ³n directa.Journey reales.Inputs del equipo.ğŸŸ© En servicios maduros:El tablero incorpora:Insights de dashboards.Validaciones en datos.RetroalimentaciÃ³n continua.
> 
> 
> â†’ En ambos casos, se construye en **copilotaje con la IA**.
> 

---

### **3.1.2.3 Criterios de calidad del tablero**

> Un buen tablero:
> 
> - Representa lo real, no lo ideal.
> - Es comprensible para todo el equipo.
> - Deja trazabilidad clara.
> - Puede alimentar la memoria viva y la base vectorial.

### **3.1.3 Fase 3: Liderazgo en el Kickoff (FacilitaciÃ³n y ConducciÃ³n)**

---

### **3.1.3.1 PropÃ³sito del liderazgo en el Kickoff**

> El Kickoff es una instancia donde el Researcher ejerce liderazgo sobre el proceso de construcciÃ³n o validaciÃ³n del sistema.
> 
> 
> Este liderazgo puede expresarse en dos planos complementarios:
> 
> - **FacilitaciÃ³n**: guiar al equipo en la construcciÃ³n colectiva de comprensiÃ³n y de lenguaje comÃºn sobre el sistema.
> - **ConducciÃ³n**: dirigir el proceso de validaciÃ³n tÃ©cnica, asegurar que el sistema sea preciso, eficiente y escalable.
> 
> â†’ **Nota:** El desarrollo de estos planos de liderazgo estÃ¡ en evoluciÃ³n a travÃ©s de la **Escuela de ConducciÃ³n y FacilitaciÃ³n**.
> 
> Los criterios y buenas prÃ¡cticas aquÃ­ descritos podrÃ¡n ser actualizados conforme avance el estÃ¡ndar de la Escuela.
> 

---

### **3.1.3.2 CÃ³mo se ejerce el liderazgo segÃºn madurez del sistema**

> ğŸŸ¦ En servicios en construcciÃ³n:El liderazgo se centra mÃ¡s en la FacilitaciÃ³n:EnseÃ±ar a pensar el sistema.Construir lenguaje comÃºn.Fomentar participaciÃ³n activa y reflexiÃ³n compartida.ğŸŸ© En servicios maduros:El liderazgo se centra mÃ¡s en la ConducciÃ³n:Validar datos y estructura del sistema.Alinear interpretaciÃ³n de los dashboards y del Desk.Tomar decisiones claras sobre ajustes o mejoras.Asegurar consistencia tÃ©cnica y operativa.
> 
> 
> â†’ El Researcher debe saber moverse con flexibilidad entre ambos planos, segÃºn el contexto del servicio y la madurez de la etapa.
> 

---

### **3.1.3.3 Criterios para cerrar el Kickoff**

> El Kickoff se considera completo si:
> 
> - El sistema (tablero) queda validado o con acuerdos claros de ajustes.
> - Los acuerdos de cambio quedan trazados.
> - Los vacÃ­os y riesgos detectados quedan registrados para seguimiento.
> - Se genera la huella digital correspondiente.
> - La sesiÃ³n reflejÃ³ un ejercicio consciente de liderazgo (en su plano de facilitaciÃ³n, de conducciÃ³n, o de ambos).
> 
> â†’ **Nota:** Los criterios de evaluaciÃ³n de la calidad del liderazgo en el Kickoff serÃ¡n definidos y actualizados por la **Escuela de ConducciÃ³n y FacilitaciÃ³n**.
> 

## **3.2 ğŸ—£ Personalidad del agente y del Researcher en cada fase**

### **3.2.1 PropÃ³sito de este punto**

> El tono, la postura y el estilo de trabajo del agente IA y del Researcher deben adaptarse a la fase en que se encuentran.
> 
> 
> No es lo mismo guiar una fase de exploraciÃ³n que conducir una validaciÃ³n tÃ©cnica.
> 
> â†’ La personalidad adaptativa del agente y del Researcher es clave para que el sistema sea:
> 
> - Comprensible para el equipo.
> - Efectivo en la toma de decisiones.
> - Consistente en su gobernanza y evoluciÃ³n.

---

### **3.2.2 Personalidad en Fase 1: ExploraciÃ³n**

> Fase: ExploraciÃ³n
> 
> 
> **Personalidad del agente / Researcher:**
> 
> - ğŸ§­ Curioso, paciente, observador.
> - En busca de comprender, no de juzgar.
> - Abierto a descubrir lo real, no lo ideal.
> 
> **IntenciÃ³n guÃ­a:**
> 
> â€œMuÃ©strame lo real, no lo ideal.â€
> 
> **En esta fase:**
> 
> - El Researcher explora sin imponer estructuras.
> - La IA ayuda a organizar lo observado, pero no anticipa soluciones.

---

### **3.2.3 Personalidad en Fase 2: GeneraciÃ³n del Tablero**

> Fase: GeneraciÃ³n del Tablero
> 
> 
> **Personalidad del agente / Researcher:**
> 
> - ğŸ”§ Estructurado, claro, con visiÃ³n formativa.
> - Busca representar lo real de forma comprensible.
> 
> **IntenciÃ³n guÃ­a:**
> 
> â€œAsÃ­ se ve lo que hacemos. Â¿QuÃ© falta?â€
> 
> **En esta fase:**
> 
> - El Researcher empieza a construir estructura.
> - La IA propone patrones, detecta vacÃ­os, sugiere preguntas.

---

### **3.2.4 Personalidad en Fase 3: Liderazgo en el Kickoff (FacilitaciÃ³n y ConducciÃ³n)**

> Fase: Kickoff â†’ Liderazgo en dos planos.
> 
> 
> **Personalidad del agente / Researcher:**
> 
> - ğŸŸ¦ **En FacilitaciÃ³n:**
>     - ğŸƒ Abierto, afirmativo, con ritmo y escucha activa.
>     - Busca que el equipo participe, cuestione, se apropie del sistema.
> - ğŸŸ© **En ConducciÃ³n:**
>     - ğŸ¯ Preciso, orientado a la validaciÃ³n tÃ©cnica.
>     - Toma posiciÃ³n, dirige el proceso, asegura consistencia y calidad.
> 
> **IntenciÃ³n guÃ­a:**
> 
> - En FacilitaciÃ³n:
>     
>     â€œEsto es lo que recogimos. Â¿Lo validamos juntos?â€
>     
> - En ConducciÃ³n:
>     
>     â€œValidemos la estructura y aseguremos la calidad del sistema.â€
>     
> 
> **En esta fase:**
> 
> - El Researcher debe saber cuÃ¡ndo moverse en modo facilitador y cuÃ¡ndo en modo conductor, segÃºn:
>     - La madurez del sistema.
>     - El tipo de decisiones que se estÃ¡n trabajando.
>     - El nivel de preparaciÃ³n del equipo.

## ğŸ“˜ **3.3 âœ… Criterios de resultado esperado**

### **3.3.1 PropÃ³sito de los criterios de resultado**

> No se puede transformar un sistema si no se ha entendido bien su funcionamiento actual.
> 
> 
> Tampoco se debe cerrar un ciclo de trabajo de Research si no se han dejado resultados trazables y validados.
> 
> â†’ Estos criterios aseguran que cada mÃ³dulo trabajado:
> 
> - Aporte valor real.
> - Deje memoria viva.
> - EstÃ© listo para alimentar la evoluciÃ³n del sistema.

---

### **3.3.2 Criterios generales para cerrar un ciclo de Research**

> Al cerrar el ciclo (ExploraciÃ³n â†’ Tablero â†’ Kickoff), deben cumplirse:
> 
> - âœ… Un sÃ­ntoma claro, concreto y fundamentado:
>     - Validado por observaciÃ³n directa (en construcciÃ³n) o evidencia en datos (en maduro).
> - âœ… Un tablero estructurado y comprensible:
>     - Que represente fielmente el sistema actual.
>     - Validado con el equipo operativo.
> - âœ… Un Kickoff con liderazgo adecuado:
>     - Ejercido en el plano que corresponde (FacilitaciÃ³n y/o ConducciÃ³n).
>     - Con acuerdos claros.
>     - Con vacÃ­os y riesgos registrados.
> - âœ… Huella digital completa:
>     - SÃ­ntoma validado.
>     - Tablero final.
>     - Acuerdos de Kickoff.
>     - Aprendizajes metodolÃ³gicos.
> - âœ… ActualizaciÃ³n propuesta a la memoria viva:
>     - IdentificaciÃ³n de chunks que podrÃ­an requerir actualizaciÃ³n en Violet Studio.
>     - NotificaciÃ³n automÃ¡tica de la IA (cuando corresponda).
>     - Propuesta de actualizaciÃ³n validada por el Curador (lÃ­der de la tribu de Research).

---

### **3.3.3 Criterios especÃ­ficos segÃºn madurez del sistema***

> 
> 
> - ğŸŸ¦ **En servicios en construcciÃ³n**:
>     - El foco estÃ¡ en:
>         - Observar con profundidad.
>         - Construir lenguaje comÃºn.
>         - DiseÃ±ar la estructura inicial del sistema (Journey, triggers, Desk base).
>         - Dejar huella digital que fundamente las decisiones de diseÃ±o.
> - ğŸŸ© **En servicios maduros**:
>     - El foco estÃ¡ en:
>         - Validar y optimizar el sistema existente.
>         - Corregir desalineaciones detectadas en los dashboards.
>         - Ajustar automatizaciones y criterios de decisiÃ³n.
>         - Dejar trazabilidad de cambios para futuras iteraciones.
>         - Alimentar la memoria viva con patrones nuevos o aprendizajes emergentes.

# 4. ğŸ§© Repertorio de MÃ³dulos

*Cada mÃ³dulo ayuda a delimitar un sÃ­ntoma y preparar una entrega Ãºtil para rediseÃ±o o automatizaciÃ³n.*

## ğŸ“˜ **4.0 ğŸ§© Fundamentos del Repertorio de MÃ³dulos**

### **4.0.1 QuÃ© es un mÃ³dulo**

> Un mÃ³dulo es una unidad tÃ¡ctica autocontenida que se activa cuando el sistema muestra un sÃ­ntoma claro.
> 
> 
> Su funciÃ³n no es â€œresolver todoâ€, sino:
> 
> - Delimitar el sÃ­ntoma.
> - Organizar el sistema actual en torno a ese sÃ­ntoma.
> - Dejar trazabilidad para que otros equipos (DiseÃ±o, Producto, AutomatizaciÃ³n) puedan intervenir con base sÃ³lida.
> 
> â†’ Cada mÃ³dulo tiene su propia lÃ³gica de anÃ¡lisis, liderazgo y entrega.
> 

---

### **4.0.2 CuÃ¡ndo y por quÃ© se activa un mÃ³dulo**

> La activaciÃ³n de un mÃ³dulo sigue la MetodologÃ­a General (punto 2):
> 
> - No se activa por rutina, plan o preferencia.
> - Se activa cuando el sistema muestra un sÃ­ntoma que lo justifica.
> 
> â†’ El Researcher, en copiloto con la IA, valida el sÃ­ntoma antes de decidir la activaciÃ³n.
> 
> â†’ En sistemas maduros, la activaciÃ³n debe estar respaldada por:
> 
> - Evidencia en dashboards.
> - RetroalimentaciÃ³n estructurada.
> - Patrones emergentes en la memoria viva.

---

### **4.0.3 CÃ³mo evoluciona el trabajo en los mÃ³dulos segÃºn madurez del sistema**

> ğŸŸ¦ En servicios en construcciÃ³n:Los mÃ³dulos sirven para:Construir el sistema desde la observaciÃ³n directa.DiseÃ±ar el primer Desk.Definir automatizaciones iniciales.Generar lenguaje comÃºn en el equipo.ğŸŸ© En servicios maduros:Los mÃ³dulos sirven para:Optimizar y ajustar el sistema existente.Detectar y corregir desalineaciones.Mejorar la experiencia del usuario.Actualizar la memoria viva.
> 
> 
> â†’ La naturaleza del trabajo en los mÃ³dulos cambia con la madurez â†’ pero el marco metodolÃ³gico se mantiene.
> 

---

### **4.0.4 Liderazgo en el trabajo por mÃ³dulos**

> Cada mÃ³dulo requiere liderazgo consciente por parte del Researcher:
> 
> - ğŸŸ¦ **En servicios en construcciÃ³n**:
>     - El liderazgo se centra mÃ¡s en la **FacilitaciÃ³n**:
>         - ConstrucciÃ³n colectiva del sistema.
>         - FormaciÃ³n de lenguaje y comprensiÃ³n compartida.
> - ğŸŸ© **En servicios maduros**:
>     - El liderazgo se centra mÃ¡s en la **ConducciÃ³n**:
>         - ValidaciÃ³n tÃ©cnica.
>         - AlineaciÃ³n entre datos, sistema operativo y memoria viva.
>         - Toma de decisiones sobre ajustes o mejoras.
> 
> â†’ El Researcher debe saber adaptar su rol de liderazgo en funciÃ³n de la madurez de la etapa.
> 

---

### **4.0.5 QuÃ© debe dejar un mÃ³dulo como resultado**

> Todo mÃ³dulo debe dejar:
> 
> - âœ… Un sÃ­ntoma documentado y validado.
> - âœ… Un sistema organizado (Journey, triggers, automatizaciones, etc.) con trazabilidad.
> - âœ… Un registro claro de acuerdos y vacÃ­os.
> - âœ… Una huella digital completa para alimentar la memoria viva.
> - âœ… Una propuesta de actualizaciÃ³n (cuando corresponda) a la interfaz de Violet Studio:
>     - La IA notifica posibles chunks desalineados.
>     - El Curador valida las actualizaciones.
> 
> â†’ Sin estos resultados, el mÃ³dulo no se considera completo.
> 

---

## 4.1. 1ï¸âƒ£ ğŸ§© MÃ³dulo Triggers y Acciones AutomÃ¡ticas - Operaciones

### 4.1.1 ğŸ”§ Â¿QuÃ© sÃ­ntoma activa este mÃ³dulo?

### **4.1.1.1 PropÃ³sito de este punto**

> Este subchunk explica **para quÃ© sirve este punto en la Biblia**:
> 
> 
> El mÃ³dulo **Triggers y Acciones AutomÃ¡ticas** no se activa por preferencia, rutina ni moda.
> 
> Se activa Ãºnicamente cuando el sistema muestra un sÃ­ntoma claro de que la etapa **carece de un flujo operativo formalizado**.
> 
> El propÃ³sito de este punto es dejar claro **cuÃ¡ndo corresponde activar este mÃ³dulo y cuÃ¡ndo no**, para que el trabajo del Researcher sea oportuno, justificado y aporte valor real.
> 

---

### **4.1.1.2 CuÃ¡ndo corresponde activar este mÃ³dulo**

> El mÃ³dulo **Triggers y Acciones AutomÃ¡ticas** (tambiÃ©n llamado â€œCaso Journeyâ€) se activa cuando:
> 
> - La etapa actual **no cuenta con un flujo operativo formalizado**, es decir:
>     - No estÃ¡n **ordenadas ni digitalizadas** las tareas que deben realizarse.
>     - No estÃ¡n **previstos ni definidos** los eventos que deberÃ­an generar esas tareas (de forma automÃ¡tica o manual).
> 
> â†’ Como resultado de esta falta de estructura:
> 
> - El trabajo en la etapa depende de la **memoria individual o del criterio de cada operador**.
> - El flujo es inconsistente, variable e imposible de automatizar de forma fiable.
> - La experiencia del cliente es **heterogÃ©nea** y no controlada.

---

### **4.1.1.3 Ejemplos tÃ­picos de sÃ­ntomas**

> ğŸŸ¦ **En servicios en construcciÃ³n,** el mÃ³dulo se activa cuando la etapa no cuenta con un flujo operativo formalizado, es decir:
> 
> - **No estÃ¡n ordenadas ni digitalizadas las tareas que deben realizarse** en la etapa.
> - **No estÃ¡n previstos ni definidos los eventos que deberÃ­an generar tareas** (automÃ¡ticas o manuales).
> - El equipo avanza de forma **manual y basada en la memoria individual**.
> - No existe un Journey documentado que dÃ© soporte al flujo operativo.
> - No hay triggers definidos ni automatizaciones bÃ¡sicas.
> - No hay consistencia en cuÃ¡ndo ni cÃ³mo se realizan las acciones.
> - La experiencia del cliente es **altamente variable**, dependiendo de quiÃ©n ejecuta la etapa.
> 
> ğŸŸ© **En servicios maduros**:
> 
> - El Journey documentado ya no refleja la prÃ¡ctica real.
> - Los triggers existentes generan resultados inconsistentes.
> - Las automatizaciones actuales tienen fallos o gaps.
> - Los dashboards muestran patrones de abandono o demoras que indican desalineaciÃ³n del flujo.
> - El equipo ha incorporado nuevas prÃ¡cticas que no estÃ¡n reflejadas en la memoria viva.

---

### **4.1.1.4 CuÃ¡ndo NO corresponde activar este mÃ³dulo**

> No corresponde activar este mÃ³dulo si el sÃ­ntoma detectado no es la falta de un flujo operativo formalizado.
> 
> 
> Ejemplos de situaciones donde NO corresponde activar 4.1:
> 
> - **El flujo operativo ya estÃ¡ definido y digitalizado** (existe Journey, triggers y tareas en Desk), pero:
>     - Hay fricciones en automatizaciones puntuales â†’ corresponde trabajo de optimizaciÃ³n puntual, no rediseÃ±o completo.
>     - Hay una **tarea puntual no estructurada dentro del flujo** â†’ corresponde activar el mÃ³dulo **Big Task** (4.2), no rediseÃ±ar el Journey completo.
>     - El equipo tiene problemas de uso o adherencia al Desk â†’ corresponde trabajo de formaciÃ³n, no rediseÃ±o.
>     - El problema es exclusivamente de **UX/UI de la interfaz del Desk** â†’ corresponde trabajo conjunto con el equipo de **DiseÃ±o**; no corresponde activar mÃ³dulo de Research.
>     - El problema estÃ¡ en las comunicaciones (mensajes, secuencia) â†’ corresponde activar mÃ³dulo de **Consultas** o **Recordatorios**.
> - **No hay sÃ­ntoma real** â†’ por ejemplo:
>     - Se pide â€œhacer un Kickoffâ€ por rutina o preferencia.
>     - Se quiere â€œtener todo siempre en 4.1â€ sin un motivo justificado.
>     - Se busca documentar por completar la Biblia, no por resolver un sÃ­ntoma.
> 
> â†’ En todos estos casos, activar 4.1 **no es compatible con la MetodologÃ­a General** (punto 2) â†’ primero se debe validar si realmente falta un flujo operativo formalizado.
> 

---

### **4.1.1.5 CÃ³mo se valida la activaciÃ³n**

> La decisiÃ³n de activar este mÃ³dulo debe ser validada:
> 
> - Por el Researcher en copiloto con la IA.
> - En consulta con el Curador (lÃ­der de la tribu de Research), especialmente en sistemas maduros.
> - En servicios maduros, la validaciÃ³n debe incluir evidencia en dashboards y/o retroalimentaciÃ³n estructurada.
> 
> â†’ Activar sin sÃ­ntoma real **no es compatible con la MetodologÃ­a General** (punto 2).
> 

---

### 4.1.2 ğŸ¯ Resultado esperado del mÃ³dulo

### **4.1.2.1 PropÃ³sito de este punto**

> Este subchunk explica para quÃ© sirve definir el resultado esperado:
> 
> 
> El Researcher y el Curador deben tener claridad sobre **quÃ© entregables debe dejar un ciclo completo del mÃ³dulo 4.1**.
> 
> Sin este resultado, el sistema sigue operando de forma no trazable o inconsistente.
> 

---

### **4.1.2.2 QuÃ© se espera como resultado operativo**

> El resultado esperado de un ciclo completo del mÃ³dulo 4.1 es que la etapa quede con:
> 
> - âœ… Un **Journey documentado** y validado con el equipo.
> - âœ… Una lista de **eventos (triggers)** definidos, que activan:
>     - Tareas automÃ¡ticas.
>     - Tareas manuales digitalizadas en el Desk.
> - âœ… Una estructura de **tareas digitalizadas en el Desk**:
>     - QuÃ© tareas deben ejecutarse.
>     - En quÃ© momento (por quÃ© trigger).
>     - Por quÃ© rol (quiÃ©n).
> - âœ… Una experiencia de cliente coherente:
>     - Consistencia en el avance de los casos.
>     - Claridad en los puntos de contacto.
>     - EvitaciÃ³n de variabilidad entre operadores.

---

### **4.1.2.3 QuÃ© se espera como resultado editorial y de memoria viva**

> AdemÃ¡s de la estructura operativa, el mÃ³dulo 4.1 debe dejar:
> 
> - âœ… Una **huella digital completa**:
>     - DiagnÃ³stico que justificÃ³ la activaciÃ³n.
>     - Journey validado.
>     - Triggers y tareas.
>     - VacÃ­os detectados y plan de mejora (si quedÃ³ algo pendiente).
>     - Acuerdos validados en el Kickoff.
> - âœ… Un **informe editorial del mÃ³dulo** (ver 4.1.6), validado por el Curador.
> - âœ… ActualizaciÃ³n de la **memoria viva en Violet Studio**:
>     - Chunks actualizados segÃºn los acuerdos validados.
>     - NotificaciÃ³n generada por la IA cuando corresponda.

---

### **4.1.2.4 QuÃ© se espera como resultado en la Escuela de ConducciÃ³n y FacilitaciÃ³n**

> Como parte del proceso de mejora continua:
> 
> - âœ… La grabaciÃ³n del Kickoff debe ser revisada por los mentores.
> - âœ… El feedback del mentor debe alimentar:
>     - El aprendizaje del Researcher.
>     - La **mini Biblia de la Escuela de ConducciÃ³n y FacilitaciÃ³n**.
> - âœ… Cualquier aprendizaje metodolÃ³gico relevante debe ser incorporado a la memoria viva del rol Researcher.

---

### **4.1.2.5 Indicadores de un resultado de alta calidad**

> Un ciclo de mÃ³dulo 4.1 se considera de alta calidad cuando:
> 
> - El Journey y triggers quedan claros, comprensibles y usables por el equipo.
> - El Desk refleja la estructura de tareas de forma operable.
> - La experiencia del cliente mejora (flujo mÃ¡s claro, consistente).
> - El informe editorial estÃ¡ bien estructurado y alimenta correctamente la memoria viva.
> - El liderazgo del Kickoff (FacilitaciÃ³n y ConducciÃ³n) fue valorado positivamente por el feedback de la Escuela.
> - No quedan vacÃ­os operativos crÃ­ticos sin plan de mejora.

---

### 4.1.3 âœ¨ ExploraciÃ³n previa requerida

### **4.1.3.1 PropÃ³sito de la exploraciÃ³n previa**

> El objetivo de esta exploraciÃ³n no es solo detectar sÃ­ntomas, sino mapear el sistema real que actualmente hace avanzar los casos en esta etapa.
> 
> 
> Se busca entender:
> 
> - QuÃ© eventos hacen avanzar el sistema.
> - QuÃ© tareas deberÃ­an seguirse.
> - QuÃ© fricciones existen hoy.
> 
> No se parte de flujos ideales, sino **desde la prÃ¡ctica real**.
> 

---

### **4.1.3.2 ObservaciÃ³n directa con el equipo operativo**

> Hablar con al menos 1 o 2 personas que operen activamente la etapa.Observar cÃ³mo organizan su dÃ­a y cÃ³mo toman decisiones.Siempre que sea posible, incluir pantalla compartida o visualizaciÃ³n directa.
> 
> 
> Preguntas reveladoras:
> 
> - â€œÂ¿CÃ³mo sabes quÃ© te toca hacer hoy?â€
> - â€œÂ¿QuÃ© tareas haces en esta etapa?â€
> - â€œÂ¿QuÃ© te hace pasar de una tarea a otra?â€
> - â€œÂ¿Puedes mostrarme cÃ³mo ejecutas estas tareas?â€
> 
> > ğŸ§  Regla de calidad: La observaciÃ³n con pantalla compartida es esencial. Sin visualizar cÃ³mo el equipo trabaja realmente, el Researcher corre riesgo de subestimar el problema o activarlo prematuramente (Informe 001).
> > 

---

### **4.1.3.3 Trabajo individual del Researcher (con apoyo progresivo de la IA)**

> DespuÃ©s de la observaciÃ³n, el Researcher debe:
> 
> - Identificar momentos donde el sistema avanza o se estanca.
> - Reunir elementos visuales:
>     - Journey anterior (si existe).
>     - CRM.
>     - Flujos existentes.
> - Clasificar los posibles triggers:
>     - ğŸ”µ Eventos Externos.
>     - ğŸ”´ Decisiones.
>     - ğŸŸ  Tareas Internas.
> 
> â†’ Durante este proceso, la IA se usa **progresivamente**:
> 
> - Se alimenta con lo observado.
> - Propone posibles triggers y acciones.
> - El Researcher valida y corrige en vivo, refinando la comprensiÃ³n del sistema.

> â— Aprendizaje no generalizable: Esta exploraciÃ³n es mÃ¡s exigente porque su output se usa en Big Task, Consultas y Recordatorios. No es solo detectar sÃ­ntomas: es detectar la estructura operativa base.
> 

---

### **4.1.3.4 QuÃ© entregables debe dejar la exploraciÃ³n**

> La exploraciÃ³n previa debe dejar:
> 
> - âœ… Un **diagnÃ³stico claro**:
>     - QuÃ© tareas se hacen hoy y cÃ³mo.
>     - QuÃ© eventos generan esas tareas (o por quÃ© no hay eventos claros).
>     - QuÃ© fricciones o inconsistencias se observan.
>     - Si corresponde â†’ evidencia en dashboards (en servicios maduros).
> - âœ… Una **propuesta de activaciÃ³n del mÃ³dulo**:
>     - Resumen del sÃ­ntoma.
>     - JustificaciÃ³n de que corresponde activar 4.1.
>     - Propuesta de preparaciÃ³n para el Kickoff (quÃ© puntos clave trabajar).
> 
> â†’ Esta propuesta se valida con la IA y con el Curador antes de convocar el Kickoff.
> 

---

### **4.1.3.5 QuÃ© no es una exploraciÃ³n adecuada**

> No se considera una exploraciÃ³n adecuada:
> 
> - Hacer solo una entrevista informal sin observar el sistema real.
> - No observar pantallas ni ver cÃ³mo el equipo realmente opera.
> - Basarse solo en opiniones de jefaturas sin contrastar con el trabajo operativo.
> - No revisar la prÃ¡ctica real en el Desk (cuando ya existe).
> - No revisar dashboards en servicios maduros.
> - Convocar un Kickoff sin diagnÃ³stico previo documentado.

---

### 4.1.4 ğŸ›  DinÃ¡mica del mÃ³dulo

Este mÃ³dulo se ejecuta en dos fases: primero, un trabajo asincrÃ³nico de reflexiÃ³n individual; luego, un Kickoff sincrÃ³nico donde se valida el sistema con el equipo.

**Ambas fases son obligatorias**, salvo casos excepcionales donde el equipo estÃ© perfectamente alineado.

## 4.1.4.1 ğŸ§¾ Fase asincrÃ³nica (tablero + procesamiento)

### **4.1.4.1.1 ğŸŒŸ PropÃ³sito de la fase asincrÃ³nica**

### **4.1.4.1.1.1 PropÃ³sito central de la fase asincrÃ³nica**

> La fase asincrÃ³nica busca que cada persona del equipo aporte insumos clave para el trabajo colectivo que se realizarÃ¡ en el Kickoff.
> 
> 
> El objetivo concreto de **Research** en esta fase es:
> 
> âœ… Recolectar las principales frustraciones que vive hoy el equipo operativo en la etapa.
> 
> âœ… Recolectar las principales frustraciones o confusiones que vive el cliente en esta etapa, desde lo que el equipo observa en la prÃ¡ctica.
> 
> âœ… Recolectar las ideas brillantes que el equipo propone para mejorar la etapa.
> 
> âœ… Evaluar el nivel de claridad que tiene el equipo sobre el objetivo operativo de la etapa (por ejemplo: que el cliente rellene la ficha).
> 
> La funciÃ³n concreta para la **FacilitaciÃ³n** es ayudar al equipo a entrar con el **mindset correcto** para esta dinÃ¡mica:
> 
> âœ… Un mindset de **observaciÃ³n sistÃ©mica**.
> 
> âœ… No de diseÃ±o.
> 
> âœ… No de validaciÃ³n apresurada.
> 

---

### **4.1.4.1.1.2 Habilidades que se ejercitan en esta fase**

### **4.1.4.1.1.2.1 Habilidades que se ejercitan en el equipo operativo**

> **ğŸ† Lectura sistÃ©mica bÃ¡sica**
> 
> 
> Aprender a observar el flujo de la etapa, detectar sÃ­ntomas, distinguir triggers reales de tareas internas.
> 
> ğŸ† **AlineaciÃ³n operativa**
> 
> Clarificar quÃ© se espera lograr en esta etapa del sistema.
> 

---

### **4.1.4.1.1.2.2 Habilidades que se ejercitan en el Researcher**

> ğŸ† Lectura sistÃ©mica avanzada
> 
> 
> En esta fase (diseÃ±o del tablero), el Researcher trabaja la capacidad de **anticipar quÃ© aspectos del sistema actual son mÃ¡s crÃ­ticos de explorar**, en base a su observaciÃ³n operativa previa de la etapa.
> 
> Aunque la plantilla de tablero propuesta se aplica casi siempre, el Researcher debe tener criterio para identificar **si conviene proponer ajustes o Ã©nfasis especÃ­ficos**: por ejemplo, reforzar ciertas preguntas, agregar subpreguntas o modular el tono, segÃºn el contexto de la etapa y del equipo.
> 
> ğŸ† **FacilitaciÃ³n de la metodologÃ­a**
> 
> El diseÃ±o del tablero es un ejercicio de **traducciÃ³n de la metodologÃ­a al contexto concreto de la etapa**.
> 
> El Researcher debe asegurar que las instrucciones y preguntas:
> 
> - activen el mindset correcto en el equipo (diagnÃ³stico, no diseÃ±o),
> - y generen respuestas Ãºtiles para el trabajo colectivo posterior.
> 
> Por lo tanto, tambiÃ©n aquÃ­ se ejercita la capacidad de **proponer ajustes a la plantilla cuando el contexto lo requiere**, siempre en coherencia con la lÃ³gica del mÃ³dulo.
> 

---

### **4.1.4.1.1.2.3 Referencia cruzada a la Escuela de FacilitaciÃ³n**

> ğŸ“Œ Ver Mini Biblia de FacilitaciÃ³n v1.1
> 
> - **FacilitaciÃ³n de la metodologÃ­a** â†’ Mini Biblia 2.1.2
> - **Lectura sistÃ©mica** â†’ Mini Biblia 2.1.3
> 
> En esta fase, la **Lectura sistÃ©mica** se aplica en la observaciÃ³n previa y en el diseÃ±o del tablero (anticipaciÃ³n de focos relevantes).
> 
> La **FacilitaciÃ³n de la metodologÃ­a** se aplica en el diseÃ±o intencionado del tablero asincrÃ³nico, garantizando que la plantilla estÃ¡ndar se ajuste correctamente al contexto de la etapa y al nivel de madurez del equipo.
> 

---

### **4.1.4.1.1.3 ğŸš« Errores comunes a evitar (rol del Researcher)**

### **4.1.4.1.1.3.1 ğŸš« Tratar el tablero como una â€œtarea para completarâ€**

> El tablero no es una tarea con fecha de entrega ni un trÃ¡mite que el equipo deba â€œcumplirâ€.
> 
> 
> Es una **herramienta de exploraciÃ³n compartida**, que aporta insumos valiosos para el diagnÃ³stico colectivo.
> 
> Si el Researcher lo presenta como un simple ejercicio operativo o de cumplimiento, el equipo tenderÃ¡ a responder de forma superficial o desmotivada, debilitando la calidad del trabajo posterior.
> 

---

### **4.1.4.1.1.4.2 ğŸš« No explicar bien el propÃ³sito de la fase**

> Si el equipo no comprende que esta fase es un **diagnÃ³stico del sistema actual** â€”y no un ejercicio de diseÃ±o o validaciÃ³nâ€”, tenderÃ¡ a responder desde supuestos, expectativas ideales o propuestas prematuras.
> 
> 
> Sin un marco claro, es comÃºn que aparezcan respuestas que saltan a soluciones (â€œdeberÃ­amos cambiar la fichaâ€) o que describen un sistema ideal, en lugar de aportar insumos sobre cÃ³mo funciona hoy la etapa.
> 
> El propÃ³sito debe ser explicado con claridad en:
> 
> âœ… el **mensaje de entrega del tablero**,
> 
> âœ… el **hilo en Slack**,
> 
> âœ… y, si es necesario, reforzado en las conversaciones informales previas al Kickoff.
> 
> ğŸ‘‰ El Researcher es responsable de asegurar que este marco estÃ© presente y comprendido por todo el equipo.
> 

---

### **4.1.4.1.1.4.3 ğŸš«Tratar el mensaje de entrega y el hilo en Slack como un simple recordatorio tÃ©cnico**

> El **mensaje de entrega del tablero** y el **hilo en Slack** no son simples recordatorios operativos:
> 
> 
> son herramientas clave de **facilitaciÃ³n asincrÃ³nica** y cumplen un rol central en la activaciÃ³n del **mindset correcto** para la fase.
> 
> Es en estos espacios donde el Researcher debe:
> 
> âœ… modular el tono (ver Mini Biblia, manejo de tonos),
> 
> âœ… enmarcar claramente el propÃ³sito de la dinÃ¡mica,
> 
> âœ… anticipar posibles dudas o desviaciones en el foco,
> 
> âœ… reforzar que esta es una fase formativa, no un trÃ¡mite.
> 
> Si estos mensajes se envÃ­an como comunicados neutros o automÃ¡ticos, sin diseÃ±o intencionado, el equipo tenderÃ¡ a entrar a la fase con bajo nivel de foco y compromiso emocional.
> 
> ğŸ‘‰ DiseÃ±ar estos mensajes es parte integral de la **FacilitaciÃ³n de la metodologÃ­a** (Mini Biblia, 2.1.2) y debe ser tratado como tal.
> 

---

### **4.1.4.1.1.4.4 ğŸš«No reforzar que la fase sincrÃ³nica depende de la calidad de esta fase**

> El equipo debe comprender que el trabajo que realiza en la fase asincrÃ³nica **no es un trÃ¡mite previo**, sino un aporte clave que tendrÃ¡ consecuencias reales en la evoluciÃ³n del sistema.
> 
> 
> Los insumos que se recolectan en el tablero â€”frustraciones, ideas, diagnÃ³stico de cÃ³mo fluye hoy la etapaâ€” serÃ¡n la base sobre la cual el equipo de **DiseÃ±o y Desarrollo** trabajarÃ¡ en las semanas o meses siguientes.
> 
> En muchos casos, lo que se detecta en esta fase guÃ­a el desarrollo de:
> 
> - nuevas automatizaciones,
> - nuevos Desks,
> - cambios en el flujo operativo,
> 
> Si el equipo no percibe esta conexiÃ³n, tenderÃ¡ a ver el asincrÃ³nico como un ejercicio menor, lo que reduce la calidad de los insumos y el compromiso con la fase.
> 
> Este marco ayuda a activar un compromiso real con el trabajo asincrÃ³nico.
> 

---

### **4.1.4.1.1.5 Resultado esperado de la fase asincrÃ³nica**

### **4.1.4.1.1.5.1 En el equipo operativo**

> âœ… Que cada miembro del equipo operativo haya tenido un espacio real de protagonismo, donde su mirada sobre cÃ³mo fluye hoy la etapa y las principales frustraciones o confusiones que experimenta (propias o del cliente) sean visibles para los actores relevantes del sistema (Researcher, lÃ­deres tÃ¡cticos, mentores de la Escuela).
> 
> 
> âœ… Que el equipo haya desarrollado un **mindset de observaciÃ³n sistÃ©mica** y haya comenzado a ejercitar la **determinaciÃ³n de patrones bÃ¡sicos**, a partir de su experiencia en la etapa.
> 
> âœ… Que el equipo haya clarificado su comprensiÃ³n sobre el **objetivo operativo de la etapa**.
> 
> âœ… Que el equipo comprenda que su aporte en esta fase **tiene impacto real en la evoluciÃ³n futura del sistema**.
> 
> âœ… Que el equipo haya comenzado a activar su mirada propositiva, a travÃ©s de la pregunta de **idea mÃ¡s brillante**, como un primer paso para calentar motores hacia el trabajo de mejora que se realizarÃ¡ en etapas posteriores.
> 

---

### **4.1.4.1.1.5.2 En tÃ©rminos de insumos para el Kickoff**

> âœ… Que el Researcher cuente con **respuestas bien elaboradas de los operativos** respecto a:
> 
> - Principales **frustraciones que vive hoy el equipo** en la etapa.
> - Principales **frustraciones o confusiones que vive el cliente**, segÃºn lo que observa el equipo.
> - Nivel de **claridad del equipo sobre el objetivo operativo** de la etapa.
> - Propuestas surgidas **solo en la pregunta de idea brillante**, claramente separadas de las observaciones de diagnÃ³stico.
> 
> âœ… Que el Researcher disponga de **versiones individuales del Journey (bloque "AsÃ­ ocurre (segÃºn tÃº)")** bien trabajadas, que reflejen cÃ³mo fluye hoy la etapa desde la perspectiva del equipo, y que servirÃ¡n como base para la construcciÃ³n del primer borrador del Case Journey en la fase de revisiÃ³n.
> 

---

### **4.1.4.1.1.5.3 En tÃ©rminos de trazabilidad para el desarrollo posterior**

> âœ… Que los insumos generados en el asincrÃ³nico â€”y posteriormente validados en el Kickoffâ€” puedan servir como base documentada para el trabajo de los equipos de DiseÃ±o y Desarrollo en los ciclos siguientes.
> 
> 
> âœ… Que quede **trazabilidad clara y ordenada**, que alimente directamente la construcciÃ³n del **Case Journey** de la etapa:
> 
> - La **lÃ³gica de triggers y acciones** que emerge de esta fase: quÃ© activa el avance del sistema hoy, y quÃ© acciones estÃ¡n (o deberÃ­an estar) asociadas a cada trigger. â†’ Este es el insumo central que se plasmarÃ¡ en el **Case Journey**, y que guiarÃ¡ el trabajo de diseÃ±o y desarrollo.
> - El **â€œpor quÃ©â€ de esa lÃ³gica**: sÃ­ntomas detectados en la operaciÃ³n actual (frustraciones del equipo y del cliente), y las ideas mÃ¡s potentes surgidas en la pregunta de idea brillante. â†’ Estos elementos contextualizan y justifican las decisiones que se reflejarÃ¡n en el Case Journey.
> - Las **deudas tÃ©cnicas o vacÃ­os detectados**: aspectos de la lÃ³gica operativa que aÃºn no estÃ¡n resueltos o que requieren definiciÃ³n adicional en los prÃ³ximos ciclos de trabajo. â†’ Estas deudas deben quedar documentadas en el Case Journey para que el equipo de DiseÃ±o y Desarrollo tenga visibilidad completa del estado actual de la etapa.

---

### **4.1.4.1.1.6 Referencia cruzada a la Escuela de FacilitaciÃ³n**

> ğŸ“Œ Ver Mini Biblia de FacilitaciÃ³n v1.1
> 
> 
> Habilidades entrenadas en esta fase:
> 
> - FacilitaciÃ³n de la metodologÃ­a (ver Mini Biblia 2.1.2)
> - Lectura sistÃ©mica (ver Mini Biblia 2.1.3)

### **4.1.4.1.2 Bloque: ğŸŒ€ InstrucciÃ³n para la dinÃ¡mica asincrÃ³nica (a incluir en el tablero)**

> Esta parte del tablero es para prepararnos para la reuniÃ³n de Kickoff.
> 
> 
> El objetivo de este trabajo es **diagnosticar cÃ³mo estÃ¡ funcionando hoy esta etapa del sistema**:
> 
> - quÃ© la hace avanzar,
> - quÃ© la traba,
> - y cÃ³mo se vive esta experiencia tanto para el equipo como para el cliente.
> 
> â— **No estamos diseÃ±ando soluciones todavÃ­a.**
> 
> Toda la dinÃ¡mica â€”salvo la pregunta de **idea mÃ¡s brillante**â€” es para detectar:
> 
> - **triggers** actuales (quÃ© activa realmente el avance de la etapa),
> - **frustraciones** que dificultan ese avance o que afectan la experiencia del equipo o del cliente,
> - y el nivel de **claridad sobre el objetivo operativo** de esta etapa.
> 
> ğŸ‘‰ Recuerda: el trabajo que hacemos en este tablero serÃ¡ la base para construir el **Case Journey** de la etapa, que luego guiarÃ¡ el trabajo de nuestros equipos de DiseÃ±o y Desarrollo.
> 
> ğŸ‘‰ Es un espacio de protagonismo: tu mirada serÃ¡ visible para lÃ­deres, mentores y para quienes tomarÃ¡n decisiones sobre cÃ³mo mejorar el sistema.
> 
> ğŸ‘‰ Tu aporte aquÃ­ **tiene impacto real**: lo que identifiquemos en este trabajo serÃ¡ lo que se priorice para el desarrollo futuro.
> 

### **4.1.4.1.3 Bloque: ğŸ‘ï¸ Lo que ves y vives en esta etapa**

### **4.1.4.1.3.1 PropÃ³sito del bloque**

> Este bloque permite que cada miembro del equipo operativo aporte su mirada directa sobre cÃ³mo fluye hoy la etapa.
> 
> 
> AquÃ­ buscamos recolectar:
> 
> âœ… **frustraciones propias** que vive el operativo en la etapa,
> 
> âœ… **frustraciones o confusiones que observa en el cliente**,
> 
> âœ… nivel de **claridad sobre el objetivo operativo** de la etapa,
> 
> âœ… y **primeras ideas de mejora** (solo en la pregunta de idea mÃ¡s brillante).
> 
> Es un espacio de **protagonismo individual**: las respuestas serÃ¡n visibles para lÃ­deres, mentores y para quienes tomarÃ¡n decisiones sobre la evoluciÃ³n futura del sistema.
> 

---

### **4.1.4.1.3.2 InstrucciÃ³n para el bloque (texto a incluir en el tablero)**

> ğŸ¾ Busca a tu animal y usa el emoticon de tu animal elegido.
> 
> - ğŸ¤” **Responde las preguntas**:
>     
>     Reflexiona sobre esta etapa y responde cada pregunta de forma **breve y clara**, siguiendo la recomendaciÃ³n que viene debajo de cada una.
>     
>     Solo la Ãºltima pregunta es para propuestas de mejora.
>     
> - ğŸ™ **ExplicaciÃ³n en el Kickoff**:
>     
>     En la reuniÃ³n sincrÃ³nica vamos a trabajar los sÃ­ntomas reales que aparezcan en estas respuestas. Tu aporte aquÃ­ es clave para el diagnÃ³stico colectivo.
>     
> 
> ğŸ‘‰ No busques â€œresponder perfectoâ€: lo importante es que muestres **cÃ³mo ves tÃº hoy esta etapa**, incluso si tu mirada es distinta a la de otros.
> 

---

### **4.1.4.1.3.3 Estructura de las preguntas**

### **4.1.4.1.3.3.1 ğŸ¯ Â¿CuÃ¡l o cuÃ¡les son las condiciones que deben cumplirse para que el caso deje de ser â€œEtapa analizadaâ€ y pueda pasar a la â€œSiguiente etapaâ€?**

> RecomendaciÃ³n para el operativo:
> 
> 
> Esta pregunta no es un diagnÃ³stico: busca definir **quÃ© hecho concreto indica que esta etapa ya estÃ¡ cumplida**.
> 
> Ejemplo: â€œFicha enviadaâ€
> 
> No incluyas tareas internas o validaciones. EnfÃ³cate en **lo esencial**: lo que separa el â€œseguimos en esta etapaâ€ del â€œpodemos avanzarâ€.
> 

---

### **4.1.4.1.3.3.2 ğŸ˜– Â¿CuÃ¡l es la mayor frustraciÃ³n que vives tÃº en esta etapa?**

> RecomendaciÃ³n para el operativo:
> 
> 
> AquÃ­ buscamos **frustraciones reales y repetidas** que dificultan tu trabajo hoy.
> 
> Describe un sÃ­ntoma concreto que estÃ© relacionado con cÃ³mo funciona hoy el sistema (no una propuesta).
> 
> Ejemplo: â€œNo sÃ© si una urgencia es real o no, porque no viene marcada en el flujo.â€
> 

---

### **4.1.4.1.3.3.3 ğŸ§â€â™‚ï¸ Â¿QuÃ© crees que mÃ¡s frustra o confunde al cliente en esta etapa?**

> RecomendaciÃ³n para el operativo:
> 
> 
> Observa desde la experiencia del cliente: Â¿quÃ© cosas tienden a frustrarlo o confundirlo hoy?
> 
> Ejemplo: â€œEl cliente no sabe quiÃ©n lleva su caso y se frustra porque lo contactan varias personas distintas.â€
> 

---

### **4.1.4.1.3.3.4 ğŸ’¡ Â¿CuÃ¡l es tu idea mÃ¡s brillante para mejorar esta etapa?**

> RecomendaciÃ³n para el operativo:
> 
> 
> AquÃ­ sÃ­ queremos propuestas: cualquier idea que creas que podrÃ­a mejorar la etapa.
> 
> Recuerda que este es un primer espacio para **activar mirada de mejora** (calentar motores), no un diseÃ±o formal.
> 
> Ejemplo: â€œQue la ficha se convierta en un chatbot paso a paso desde el celular.â€
> 

---

### **4.1.4.1.4 Bloque:ğŸ§© AsÃ­ ocurre (segÃºn tÃº) â†’ Proto Caso Journey**

### **4.1.4.1.4.1 PropÃ³sito del bloque**

> Este bloque permite que cada miembro del equipo operativo registre su visiÃ³n personal de cÃ³mo avanza hoy un caso en esta etapa, desde su experiencia directa.
> 
> 
> AquÃ­ no buscamos clasificar ni filtrar: queremos que el equipo narre **todo el paso a paso que ocurre en la etapa**, tal como lo vive en la prÃ¡ctica.
> 
> Cuanto mÃ¡s completa y detallada sea esta mirada, mÃ¡s rico serÃ¡ el insumo para construir el **Case Journey**.
> 
> ğŸ‘‰ **MÃ¡s es mejor**: no limitar la cantidad de pasos. Lo importante es capturar la lÃ³gica real de la operaciÃ³n, con toda su complejidad.
> 

---

### **4.1.4.1.4.2 InstrucciÃ³n para el bloque (texto a incluir en el tablero)**

> ğŸ‘‰ No busques que sea perfecto ni igual al de otros: muestra cÃ³mo lo ves tÃº.
> 
> 
> ğŸ‘‰ Para ordenar tu relato, usa dos tipos de elementos:
> 
> - ğŸŸ  **Tareas internas** â†’ cosas que hace el equipo y que cambian el estado del caso.
> - ğŸ”µ **Eventos externos** â†’ cosas que ocurren fuera del equipo y que hacen avanzar (o frenar) el caso.
> 
> ğŸ‘‰ Incluye tanto:
> 
> - Lo que hace el cliente.
> - Lo que hace el equipo.
> - Lo que ocurre automÃ¡ticamente.
> - Lo que bloquea o frena.
> - Lo que depende de decisiones.
> 
> ğŸ‘‰ Entre mÃ¡s completa y detallada sea tu versiÃ³n, **mejor insumo tendremos para construir el Case Journey** de la etapa.
> 
> ğŸ‘‰ Este es un espacio de protagonismo: tu mirada aquÃ­ sÃ­ tiene impacto real en el desarrollo futuro del sistema.
> 

### **4.1.4.1.4 Bloque: ğŸ“¬ Feedback**

### **4.1.4.1.4.1 PropÃ³sito del bloque**

> Este bloque permite recolectar feedback cualitativo sobre la dinÃ¡mica asincrÃ³nica en sÃ­ misma.
> 
> 
> Su objetivo es doble:
> 
> âœ… identificar posibles **fricciones o confusiones** en el diseÃ±o de la dinÃ¡mica (para mejorarla en futuras iteraciones),
> 
> âœ… recoger percepciones del equipo sobre el valor de este espacio (para reforzar el marco de protagonismo en la cultura del sistema).
> 

---

### **4.1.4.1.4.2 Pregunta a incluir al final del tablero**

> ğŸ’¬ â€œÂ¿Te hizo sentido este tablero? Â¿QuÃ© mejorarÃ­as para hacerlo mÃ¡s claro o mÃ¡s Ãºtil?â€
> 

---

### **4.1.4.1.4.3 Uso del feedback**

> El feedback recolectado en esta pregunta debe ser revisado por el Researcher durante la fase de revisiÃ³n de resultados (4.1.4.2).
> 
> 
> Este insumo es clave para:
> 
> âœ… iterar y mejorar la plantilla del tablero,
> 
> âœ… ajustar el marco comunicacional en futuras activaciones del mÃ³dulo,
> 
> âœ… identificar patrones de percepciÃ³n que puedan ser trabajados en la Escuela de FacilitaciÃ³n (por ejemplo: si el equipo tiende a subvalorar la fase asincrÃ³nica, o si hay confusiÃ³n recurrente sobre los conceptos).
> 
> AdemÃ¡s, este feedback debe quedar documentado en el **Repertorio de MÃ³dulos** como parte de la trazabilidad de la mejora continua.
> 

### **4.1.4.1.5 ğŸš« Evitar adelantar la dinÃ¡mica sincrÃ³nica**

> ğŸ‘‰ Indicaciones para el Researcher:
> 
> 
> Para proteger la progresiÃ³n metodolÃ³gica del mÃ³dulo, es importante que el Researcher:
> 
> - No muestre el **Case Journey preliminar** antes del Kickoff.
> - No comparta el diseÃ±o de los bloques que se trabajarÃ¡n en la fase sincrÃ³nica.
> - No anticipe procesos de **validaciÃ³n**: en esta fase estamos en diagnÃ³stico.
> - No pida al equipo que priorice o seleccione soluciones: las ideas van solo en la **pregunta de idea brillante**, como calentamiento, sin jerarquizaciÃ³n ni validaciÃ³n.
> 
> ğŸ‘‰ Estas indicaciones garantizan que cada fase active su foco especÃ­fico y que el equipo llegue al Kickoff con una mirada fresca y no condicionada.
> 

### **4.1.4.1.6 ğŸ’¬ Mensaje de entrega de tablero (plantilla)**

### **4.1.4.1.6.1  Ejemplo de mensaje (Slack) (entrega del tablero)**

> ğŸ‘‹ Hola equipo,
> 
> 
> Esta semana iniciamos el Kickoff de la etapa **[Nombre de la etapa]**, trabajando el mÃ³dulo **â€œTriggers y Acciones AutomÃ¡ticasâ€**.
> 
> ğŸ‘‰ Este trabajo se hace en dos fases:
> 
> 1ï¸âƒ£ **Fase asincrÃ³nica** â†’ la que iniciamos ahora
> 
> 2ï¸âƒ£ **Fase sincrÃ³nica** â†’ la que haremos en reuniÃ³n en unos dÃ­as
> 
> ğŸš€ **PropÃ³sito de esta fase asincrÃ³nica**
> 
> El foco NO es diseÃ±ar ni validar. Es **observar con criterio**:
> 
> - CÃ³mo fluye hoy la etapa
> - QuÃ© la hace avanzar
> - QuÃ© la traba
> - QuÃ© vive el cliente
> - QuÃ© vive el equipo
> 
> Cada respuesta que aporten serÃ¡ insumo **real** para el diseÃ±o futuro del sistema.
> 
> ğŸ‘‰ No estamos rellenando un formulario: estamos construyendo juntos la mirada que luego guiarÃ¡ el trabajo de DiseÃ±o, AutomatizaciÃ³n y Producto.
> 
> ğŸ† **Tu protagonismo importa**
> 
> Este es un espacio de **protagonismo individual**:
> 
> ğŸ‘‰ Cada respuesta serÃ¡ leÃ­da por Research, lÃ­deres tÃ¡cticos y mentores.
> 
> ğŸ‘‰ Lo que aquÃ­ se levante **sÃ­ impacta** en cÃ³mo evolucionarÃ¡ el sistema.
> 
> El objetivo es que en la fase sincrÃ³nica emerjan:
> 
> âœ… sÃ­ntomas reales
> 
> âœ… patrones no vistos
> 
> âœ… vacÃ­os operativos
> 
> ğŸ“ **QuÃ© vas a hacer**
> 
> 1ï¸âƒ£ Responder el bloque de preguntas sobre cÃ³mo ves y vives hoy esta etapa
> 
> 2ï¸âƒ£ Completar tu versiÃ³n del flujo real ("AsÃ­ ocurre") â†’ cÃ³mo ves tÃº que avanza hoy un caso en esta etapa
> 
> ğŸ‘‰ No busques â€œla respuesta correctaâ€. No importa que veas cosas distintas que otros. Lo valioso es que quede trazada tu experiencia real.
> 
> â³ **Plazo para dejar tu trabajo:** **[Fecha y hora]**
> 
> ğŸ”— **AquÃ­ estÃ¡ el tablero editable:**
> 
> ğŸ‘‰ [Link al tablero]
> 
> Nos vemos en el Kickoff ğŸš€ Â¡Muchas gracias por el compromiso y la mirada que aporten en esta etapa! ğŸ™Œ
> 

---

### **4.1.4.1.7 ğŸ’¬ Mensaje en hilo (Slack) (marco conceptual)**

### **4.1.4.1.7.1 Ejemplo de mensaje en hilo (Slack)**

> ğŸ‘‹ Abrimos este hilo para el Kickoff de la etapa [Nombre de la etapa] ğŸš€
> 
> 
> Este mensaje es **igual de importante que la convocatoria principal**.
> 
> No es un recordatorio tÃ©cnico: es donde explicamos **el propÃ³sito del mÃ³dulo**, **quÃ© estamos entrenando como equipo**, y **cÃ³mo conectar eso con lo que hacemos todos los dÃ­as**.
> 
> ---
> 
> En este Kickoff trabajamos el mÃ³dulo **â€œTriggers y Automatizacionesâ€**, y no estamos aquÃ­ para diseÃ±ar.
> 
> **DiseÃ±ar (Design)** es proponer soluciones nuevas.
> 
> **Investigar (Research)** es entender problemas reales.
> 
> ğŸ‘‰ En esta dinÃ¡mica estamos en modo **Research**.
> 
> El foco no es imaginar cÃ³mo deberÃ­a ser el sistema, sino **entender cÃ³mo funciona hoy**:
> 
> ğŸ” ver quÃ© hace que el caso avance, quÃ© lo traba, y cÃ³mo lo vive el cliente o el equipo.
> 
> ---
> 
> ### ğŸ§© Â¿QuÃ© es un trigger?
> 
> Un **trigger** es algo que hace que el caso avance.
> 
> No es cualquier tarea: es un momento en que el sistema **cambia de estado**.
> 
> Hay dos tipos:
> 
> - ğŸ”µ **Evento externo**: algo que ocurre sin que lo activemos.
>     
>     *Ejemplo: el cliente envÃ­a la ficha, el tribunal publica una resoluciÃ³n.*
>     
> - ğŸŸ  **Tarea interna**: algo que hacemos y que genera un cambio real.
>     
>     *Ejemplo: marcar una urgencia, mover el caso a Para Estudio.*
>     
> 
> > No todo lo que hacemos es un trigger.
> > 
> > 
> > Lo importante es identificar **lo que realmente mueve el sistema** hacia adelante.
> > 

### **4.1.4.1.8 ğŸ¥ Recursos audiovisuales complementarios (pendientes)**

### **4.1.4.1.8.1 PropÃ³sito del bloque**

> Este bloque deja registrada una deuda pendiente: explorar el uso de recursos audiovisuales que acompaÃ±en la fase asincrÃ³nica del mÃ³dulo.
> 
> 
> La idea es que, en el futuro, el hilo de Slack pueda complementarse (o ser reemplazado) por un **video breve**, grabado por el Researcher, que facilite la entrega del **marco conceptual** del mÃ³dulo y la explicaciÃ³n de la **dinÃ¡mica asincrÃ³nica**.
> 
> El propÃ³sito serÃ­a reforzar el mindset correcto de la fase y facilitar la comprensiÃ³n por parte del equipo.
> 

---

## **4.1.4.2 ğŸ” Lectura de patrones y preparaciÃ³n de la dinÃ¡mica sincrÃ³nica**

### **4.1.4.2.1 PropÃ³sito del momento**

> Este momento del trabajo del Researcher ocurre despuÃ©s de la fase asincrÃ³nica y antes del Kickoff sincrÃ³nico.
> 
> 
> No es solo una revisiÃ³n de respuestas: es el momento en que el Researcher realiza una **lectura profunda de patrones** y **prepara con intenciÃ³n la dinÃ¡mica sincrÃ³nica**.
> 
> AquÃ­ se trabaja de forma explÃ­cita la habilidad de **Lectura SistÃ©mica avanzada** (ver Mini Biblia de FacilitaciÃ³n **2.1.3**):
> 
> ğŸ‘‰ aprender a leer un sistema real a partir de insumos fragmentados, detectar patrones relevantes y preparar la facilitaciÃ³n para que el equipo construya una comprensiÃ³n colectiva de la etapa.
> 
> En este momento se busca:
> 
> âœ… **Determinar patrones** emergentes en el bloque **ğŸ‘ï¸ Lo que ves y vives en esta etapa**
> 
> âœ… Construir (curar) el **Caso Journey** a partir de **ğŸ§© AsÃ­ ocurre (segÃºn tÃº) â†’ Proto Caso Journey**
> 
> âœ… **DiseÃ±ar la dinÃ¡mica del Kickoff**, eligiendo la dinÃ¡mica mÃ¡s adecuada desde el ğŸ“š **Banco de dinÃ¡micas** de las Mini Biblia de la Escuela de FacilitaciÃ³n, con foco en que los operativos puedan **detectar patrones en conjunto** en el sincrÃ³nico
> 
> âœ… Vincular el diseÃ±o del **Caso Journey** con los **dolores del sistema**, para que las **acciones automÃ¡ticas** respondan a la realidad de la etapa
> 
> Es un momento tÃ¡ctico clave: es lo que permite que el Kickoff sea **un espacio de aprendizaje colectivo** y no una simple â€œvalidaciÃ³n de tableroâ€.
> 

### **4.1.4.2.2 ğŸ” Lectura de patrones en ğŸ‘ï¸**

### **4.1.4.2.2.1 PropÃ³sito del momento**

> Este momento tiene como propÃ³sito que el Researcher realice una lectura de patrones profunda a partir de las respuestas del bloque ğŸ‘ï¸ Lo que ves y vives en esta etapa.
> 
> 
> No se trata de agrupar respuestas de forma superficial, sino de identificar:
> 
> âœ… **Patrones sistÃ©micos** en las frustraciones del equipo
> 
> âœ… **Patrones sistÃ©micos** en las frustraciones o confusiones del cliente
> 
> âœ… **Patrones de comprensiÃ³n (o falta de comprensiÃ³n)** sobre el objetivo operativo de la etapa
> 
> Es clave entender que **la ausencia de patrones claros** o la **gran dispersiÃ³n en las respuestas** tambiÃ©n es un dato del sistema:
> 
> ğŸ‘‰ Puede indicar que la dinÃ¡mica asincrÃ³nica estuvo mal planteada (preguntas poco claras, foco confuso)
> 
> ğŸ‘‰ Puede indicar que el equipo realmente no tiene claridad compartida sobre la etapa
> 
> ğŸ‘‰ Puede revelar una etapa del sistema que estÃ¡ en un estado de alta **desalineaciÃ³n operativa**
> 
> El Researcher no debe forzar patrones que no emergen naturalmente, sino **leer la calidad de la dispersiÃ³n** como parte del diagnÃ³stico.
> 
> Esta es una aplicaciÃ³n directa de la habilidad de **Lectura SistÃ©mica avanzada** (ver Mini Biblia de FacilitaciÃ³n **2.1.3**).
> 
> La meta NO es preparar un â€œresumen de respuestasâ€, sino llegar con una **sÃ­ntesis de patrones (o de ausencia de patrones)** que luego permita guiar el trabajo colectivo en el sincrÃ³nico:
> 
> ğŸ‘‰ que los operativos puedan **ver lo que el sistema muestra hoy**, sea claridad o dispersiÃ³n, y trabajar sobre esa base.
> 

### **4.1.4.2.2.2 ğŸ—‚ï¸ Carga y determinaciÃ³n de patrones por pregunta (ğŸ‘ï¸)**

> En esta fase, el Researcher debe trabajar la lectura de patrones de forma estructurada, pregunta por pregunta, en coherencia con el diseÃ±o original de cada pregunta del bloque ğŸ‘ï¸ Lo que ves y vives en esta etapa (ver 4.1.4.1.3.3.x).
> 
> 
> ğŸ‘‰ No se debe cargar al agente todo el bloque junto.
> 
> ğŸ‘‰ No se deben mezclar las dimensiones.
> 
> ğŸ‘‰ Cada pregunta tiene su propio propÃ³sito metodolÃ³gico y debe respetarse en la carga y en la lectura.
> 
> AdemÃ¡s:
> 
> ğŸ‘‰ En cada carga, el Researcher debe incluir la **RecomendaciÃ³n para el operativo** asociada a la pregunta, para que el agente mantenga el foco metodolÃ³gico correcto.
> 

---

### **4.1.4.2.2.2.1** ğŸ¯ **Pregunta 1: Â¿CuÃ¡l o cuÃ¡les son las condiciones que deben cumplirse para que el caso deje de ser â€œEtapa analizadaâ€ y pueda pasar a la â€œSiguiente etapaâ€?**

- Cargar la **RecomendaciÃ³n para el operativo** + respuestas.
- El agente debe ayudar a detectar:
    
    âœ… Si hay **consenso** en las condiciones de avance.
    
    âœ… Si aparecen **confusiones** o **dispersiÃ³n**.
    
    âœ… Si la dispersiÃ³n parece deberse a:
    
    - **Problema en la dinÃ¡mica** (pregunta mal planteada, foco confuso).
    - **Falta de claridad real** en el equipo sobre las condiciones de avance.
- No se busca determinar patrones en esta pregunta â†’ se busca evaluar el nivel de **claridad compartida**.

---

### **4.1.4.2.2.2.2** ğŸ˜– **Pregunta 2: Â¿CuÃ¡l es la mayor frustraciÃ³n que vives tÃº en esta etapa?**

- El agente debe ayudar a:
    
    âœ… Detectar **patrones de frustraciones recurrentes** del equipo.
    
    âœ… **Ordenar los patrones por nivel de impacto en la calidad del servicio.**
    
    âœ… Evaluar si actualmente contamos con **capacidad real para resolverlos** (con procesos, automatizaciones, cambios en la estructura, etc.).
    
    âœ… Sugerir **cÃ³mo podrÃ­a resolverse cada patrÃ³n** (visiÃ³n desde el agente).
    
    âœ… Asociar cada frustraciÃ³n detectada a uno o mÃ¡s **triggers del Journey** (dÃ³nde se expresa en el flujo actual).
    
    âœ… Comenzar a proyectar el diseÃ±o de:
    
    - **Acciones automÃ¡ticas** que ayuden a reducir ese dolor.
    - **Campos o pasos en un Desk** que ayuden a abordarlo.
- ğŸ‘‰ Esta es una aplicaciÃ³n avanzada de **Lectura SistÃ©mica**: el foco no es solo â€œleer sÃ­ntomasâ€, sino comenzar a construir el puente hacia el diseÃ±o futuro del sistema.

---

### **4.1.4.2.2.2.3**ğŸ§â€â™‚ï¸ **Pregunta 3: Â¿QuÃ© crees que mÃ¡s frustra o confunde al cliente en esta etapa?**

- Cargar la **RecomendaciÃ³n para el operativo** + respuestas.
- El agente debe ayudar a:
    
    âœ… Detectar **patrones de frustraciÃ³n/confusiÃ³n del cliente**.
    
    âœ… **Ordenar los patrones** por nivel de impacto en la experiencia del cliente y en el avance del sistema.
    
    âœ… Evaluar si actualmente contamos con **capacidad real para resolver esos dolores** (procesos, automatizaciones, rediseÃ±o de comunicaciones, cambios de flujo, etc.).
    
    âœ… Sugerir **cÃ³mo podrÃ­a resolverse cada patrÃ³n** (visiÃ³n desde el agente).
    
    âœ… Asociar cada dolor detectado a uno o mÃ¡s **triggers del Journey** (dÃ³nde se expresa en el flujo actual).
    
    âœ… Comenzar a proyectar el diseÃ±o de:
    
    - **Acciones automÃ¡ticas** o rediseÃ±os de comunicaciÃ³n para mejorar la experiencia del cliente.
    - **Campos o pasos en un Desk** que ayuden a reducir esa frustraciÃ³n.
        
        âœ… Evaluar si los sÃ­ntomas observados requieren ser **complementados con mÃ¡s informaciÃ³n directa**:
        
    - Proponer si es necesario realizar **conversaciones cualitativas con clientes** para profundizar.
    - Proponer si es necesario revisar el **NPS en esa etapa** u otros datos de experiencia para validar y enriquecer la lectura.
- ğŸ‘‰ El Researcher debe leer tambiÃ©n si el equipo operativo tiene suficiente **empatÃ­a y visiÃ³n compartida** sobre la experiencia del cliente â€” o si el patrÃ³n de respuestas refleja una falta de conexiÃ³n que deba ser trabajada.

---

### **4.1.4.2.2.2.4:** ğŸ’¡ **Pregunta 4: Â¿CuÃ¡l es tu idea mÃ¡s brillante para mejorar esta etapa?**

- Cargar la **RecomendaciÃ³n para el operativo** + respuestas.
- El agente debe ayudar a:
    
    âœ… Agrupar las ideas por **tipo de soluciÃ³n** (automatizaciÃ³n, proceso humano, comunicaciÃ³n, estructura).
    
    âœ… Evaluar **a quÃ© patrones de mayor impacto** aporta cada idea (conexiÃ³n con lo detectado en las preguntas 2 y 3).
    
    âœ… **Rescatar** las ideas que tienen mayor potencial de **atacar los patrones mÃ¡s relevantes**.
    
    âœ… Distinguir entre ideas que son:
    
    - **Accionables en el corto plazo**
    - **Ideas que requieren rediseÃ±o profundo**
    - **Ideas que aÃºn son conceptuales y necesitan maduraciÃ³n**
        
        âœ… Evitar que la lectura se vuelva un â€œcatÃ¡logo de propuestas creativas sin focoâ€: el criterio es **conexiÃ³n con patrones y capacidad de impacto**.
        
- ğŸ‘‰ Esta lectura es clave para preparar el puente hacia el trabajo tÃ¡ctico en etapas siguientes (por ejemplo, diseÃ±o de Desk o automatizaciones).

### **4.1.4.2.2.3 ğŸ­ ElecciÃ³n de dinÃ¡mica de facilitaciÃ³n para el sincrÃ³nico**

> ğŸ‘‰ Al finalizar la lectura de patrones de ğŸ‘ï¸, el Researcher debe elegir quÃ© dinÃ¡mica de facilitaciÃ³n usarÃ¡ en el sincrÃ³nico para que el equipo pueda:
> 
> 
> âœ… **Detectar patrones en conjunto**
> 
> âœ… Construir una comprensiÃ³n compartida de los dolores y oportunidades de la etapa
> 
> âœ… Generar protagonismo y apropiaciÃ³n de los patrones emergentes
> 
> ğŸ‘‰ La dinÃ¡mica se elige desde el **Banco de DinÃ¡micas** de la **Mini Biblia de FacilitaciÃ³n**.
> 
> ğŸ‘‰ Recomendaciones clave:
> 
> âœ… Si el grupo es grande â†’ dividir en subgrupos para agilizar la detecciÃ³n de patrones
> 
> âœ… En la dinÃ¡mica, cada operativo puede deterctar en el tablero los patrones que quiera. 
> Sin embargo, al momento de dar palabras si alguien detecto un patron y lo comunico no repetirlo.â†’ no se repiten patrones en voz
> 
> âœ… El tablero puede contener patrones similares, pero en la conversaciÃ³n se busca **evitar repeticiones verbales** â†’ se avanza hasta que no aparezcan mÃ¡s patrones
> 
> âœ… El Researcher debe **celebrar los patrones** cuando son dichos por el equipo â†’ reforzar el protagonismo del grupo
> 
> ğŸ‘‰ El Researcher debe documentar en el tablero:
> 
> - QuÃ© dinÃ¡mica eligiÃ³
> - Por quÃ© la eligiÃ³ (breve justificaciÃ³n)

### **4.1.4.2.3 ğŸ§© CuraciÃ³n del Caso Journey**

### **4.1.4.2.3.1 PropÃ³sito del momento**

> Este momento tiene como propÃ³sito que el Researcher construya un **nuevo Caso Journey base** directamente en el **tablero de Lucid**, a partir de:
> 
> 
> âœ… Las versiones de los Journeys individuales completados por los operativos (**ğŸ§© AsÃ­ ocurre (segÃºn tÃº)**)
> 
> âœ… Los **patrones y dolores** detectados en la lectura de ğŸ‘ï¸
> 
> âœ… Su propia visiÃ³n tÃ¡ctica del sistema
> 
> âœ… Las propuestas de **automatizaciones** conversadas con la IA
> 
> ğŸ‘‰ En esta etapa el Researcher **no estÃ¡ dejando el sistema como es hoy**:
> 
> ğŸ‘‰ EstÃ¡ **proponiendo ya un diseÃ±o base** para el **nuevo Journey** de la etapa â†’ que luego serÃ¡ validado y ajustado en el Kickoff sincrÃ³nico.
> 
> ğŸ‘‰ Por lo tanto, este es un momento de **diseÃ±o inicial**:
> 
> âœ… Se integran los aprendizajes de la fase asincrÃ³nica
> 
> âœ… Se propone una estructura de triggers y tareas que pueda:
> 
> - Atender los dolores detectados
> - Aprovechar las capacidades actuales del sistema
> - Servir de base para el diseÃ±o futuro de automatizaciones y Desks
> 
> ğŸ‘‰ La conversaciÃ³n con la IA se usa especÃ­ficamente para:
> 
> âœ… Pensar en **acciones automÃ¡ticas asociadas a cada evento**
> 
> âœ… Evaluar el sentido y factibilidad de esas automatizaciones
> 
> âœ… Documentar esas ideas como **notas en los componentes de Lucid** correspondientes a cada trigger.
> 

---

### **4.1.4.2.3.2 Proceso de DiseÃ±o del Caso Journey**

> ğŸ‘‰ En este momento, el Researcher trabaja directamente en el tablero de Lucid para proponer el nuevo diseÃ±o del Caso Journey.
> 
> 
> ğŸ‘‰ El diseÃ±o se construye a partir de:
> 
> âœ… Los **Journeys de los operativos** (ğŸ§© AsÃ­ ocurre)
> 
> âœ… Los **patrones y dolores detectados** en ğŸ‘ï¸
> 
> âœ… La reflexiÃ³n propia del Researcher
> 
> ğŸ‘‰ El Researcher diseÃ±a en el tablero:
> 
> - ğŸ”µ **Eventos externos**
> - ğŸŸ  **Tareas internas**
> 
> ğŸ‘‰ En paralelo, conversa con la IA para:
> 
> âœ… Proponer **acciones automÃ¡ticas** asociadas a los eventos.
> 
> âœ… Por cada acciÃ³n automÃ¡tica propuesta, anotar en el componente de Lucid:
> 
> - **QuÃ© dolor resuelve**.
> 
> ğŸ‘‰ El foco no es describir cÃ³mo es hoy â†’ es proponer un **nuevo Journey base**, mejor alineado con los dolores y oportunidades detectadas.
> 
> ğŸ‘‰ Este diseÃ±o quedarÃ¡ listo para ser trabajado y validado con el equipo en el sincrÃ³nico.
> 

### **4.1.4.2.3.3 Resultado esperado**

> Al finalizar este momento, el tablero debe contener:
> 
> 
> âœ… Un **Caso Journey curado** en Lucid, con:
> 
> - ğŸ”µ Eventos externos
> - ğŸŸ  Tareas internas
> 
> âœ… Anotaciones claras en el tablero que indiquen:
> 
> - DÃ³nde se expresan los **patrones/dolores** del sistema
> - QuÃ© variantes existen
> - QuÃ© vacÃ­os han sido detectados
> 
> âœ… **Notas en los componentes de triggers** con las **acciones automÃ¡ticas** propuestas (basadas en la conversaciÃ³n con la IA).
> 
> ğŸ‘‰ El tablero debe quedar listo para ser trabajado colectivamente en el sincrÃ³nico:
> 
> âœ… Para que el equipo valide el flujo actual
> 
> âœ… Para que el equipo comprenda cÃ³mo los dolores estÃ¡n reflejados en el flujo
> 
> âœ… Para que el equipo pueda discutir sobre el diseÃ±o futuro de automatizaciones y Desks.
> 

# ğŸ“— 4.1.4.3 ğŸˆ ConducciÃ³n del Kickoff SincrÃ³nico

---

## 4.1.4.3.1 ğŸª„ Fase de Apertura (referencia Mini Biblia 3.2.1, 3.2.2, 3.2.3)

4.1.4.3.1.1 ğŸ™ Bienvenida Showcera

> Link: ver Mini Biblia 3.2.1
> 

4.1.4.3.1.2 ğŸ­ DinÃ¡mica de Rompehielo

> Link: ver Mini Biblia 3.2.2
> 

4.1.4.3.1.3 ğŸŒ€ DinÃ¡mica de Precalentamiento

> Link: ver Mini Biblia 3.2.3
> 

---

## 4.1.4.3.2 ğŸ‘ï¸ Fase de DiagnÃ³stico Colectivo â†’ "Lo que ves y vives en esta etapa"

(referencia Mini Biblia 3.2.4)

4.1.4.3.2.1 ğŸ“Š ExposiciÃ³n de patrones y sÃ­ntesis colectiva

4.1.4.3.2.2 FacilitaciÃ³n de la reflexiÃ³n â†’ dinÃ¡mica guiada sobre el tablero

> Link: ver Mini Biblia 3.2.4
> 

---

- **4.1.4.1 ğŸ§¾ Tablero asincrÃ³nico**
    
    ---
    
    ---
    
    - **4.1.4.1.2** ğŸ’¬ **Mensaje de entrega de tablero**
        
        Este mensaje es una plantilla referencial.
        
        Puede adaptarse segÃºn el servicio o etapa, pero debe dejar claro quÃ© se va a trabajar, cÃ³mo, y para quÃ© sirve, en un lenguaje simple y directo.
        
        ---
        
        ### Ejemplo de mensaje de convocatoria
        
        > ğŸ‘‹ Hola equipo,
        > 
        > 
        > Esta semana comenzamos el Kickoff de la etapa [Nombre de la etapa], donde vamos a trabajar el mÃ³dulo â€œTriggers y Acciones AutomÃ¡ticasâ€.
        > 
        > El objetivo es entender cÃ³mo avanza hoy un caso en esta etapa: quÃ© lo activa, quÃ© lo traba, y quÃ© vive el cliente en ese proceso.
        > 
        > El Kickoff tiene dos fases:
        > 
        > **Fase asincrÃ³nica (ahora):**
        > 
        > 1. Cada persona responde un tablero con 4 preguntas.
        >     
        >     Solo la Ãºltima es para propuestas. Las otras son para observar con criterio.
        >     
        > 2. Luego, completan el Journey base con su versiÃ³n del flujo real: quÃ© pasos hacen avanzar el caso.
        > 
        > **Fase sincrÃ³nica (despuÃ©s):**
        > 
        > Compartiremos nuestras respuestas, compararemos los flujos y discutiremos los puntos clave que aparecieron.
        > 
        > Lo importante no es que todos veamos lo mismo, sino que aparezca lo que nadie estaba viendo.
        > 
        > ğŸ‘‰ Entra al tablero editable y sigue las instrucciones:
        > 
        > ğŸ”— [Lucid Kickoff â€“ Etapa Nuevo Caso]
        > 
        > ğŸ• Tienes hasta el (fecha y hora) para dejar tus respuestas.
        > 
    - **4.1.4.1.3** ğŸ’¬ **Mensaje en hilo (Slack)**
        
        Este mensaje es **igual de importante que la convocatoria principal**.
        
        No es un recordatorio tÃ©cnico: es donde **explicamos el propÃ³sito del mÃ³dulo**, **quÃ© estamos entrenando como equipo**, y **cÃ³mo conectar eso con lo que hacemos todos los dÃ­as**.
        
        AcÃ¡ bajamos el marco conceptual a tierra:
        
        Â¿Por quÃ© trabajamos â€œTriggers y Automatizacionesâ€? Â¿QuÃ© significa diagnosticar en este contexto? Â¿Y cÃ³mo se diferencia eso de proponer soluciones?
        
        El fodo de la instacia **no es para imaginar cÃ³mo deberÃ­a ser, sino para entender cÃ³mo es hoy**.
        
        ### Ejemplo de mensaje en hilo
        
        En este Kickoff trabajamos el mÃ³dulo **â€œTriggers y Automatizacionesâ€**, y no estamos aquÃ­ para diseÃ±ar.
        
        **DiseÃ±ar (Design)** es proponer soluciones nuevas.
        
        **Investigar (Research)** es entender problemas reales.
        
        ğŸ‘‰ En esta dinÃ¡mica estamos en modo **Research**.
        
        El foco no es imaginar cÃ³mo deberÃ­a ser el sistema, sino **entender cÃ³mo funciona hoy**:
        
        ver quÃ© hace que el caso avance, quÃ© lo traba, y cÃ³mo lo vive el cliente o el equipo.
        
        ---
        
        Para eso, necesitamos identificar los **triggers**:
        
        las cosas que **activan un cambio real** en el sistema.
        
        ---
        
        ### ğŸ§© Â¿QuÃ© es un trigger?
        
        Un **trigger** es algo que hace que el caso avance.
        
        No es cualquier tarea: es un momento en que el sistema cambia de estado.
        
        Hay dos tipos:
        
        - ğŸ”µ **Evento externo**: algo que ocurre sin que lo activemos.
            
            *Ejemplo: el cliente envÃ­a la ficha, el tribunal publica una resoluciÃ³n.*
            
        - ğŸŸ  **Tarea interna**: algo que hacemos y que genera un cambio real.
            
            *Ejemplo: marcar una urgencia, mover el caso a Para Estudio.*
            
        
        > No todo lo que hacemos es un trigger.
        > 
        > 
        > Lo importante es identificar **lo que realmente mueve el sistema** hacia adelante.
        > 
        
        ---
        
        ### âœï¸ Â¿QuÃ© te pedimos ahora?
        
        1. Contesta el tablero desde tu experiencia real.
        2. Edita el Journey con lo que tÃº crees que hace avanzar el caso.
        3. Las propuestas de mejora van solo en la Ãºltima pregunta.
        
        ---
        
        **Este Kickoff es para mirar el sistema como es, no como deberÃ­a ser.**
        
        Diagnosticar con criterio es el primer paso para despuÃ©s diseÃ±ar algo que funcione de verdad.
        
        ---
        
        - **ğŸ”— Recursos audiovisuales complementarios (pendientes)**
            
            Para que el mensaje en el hilo cumpla su propÃ³sito de formar y motivar al equipo, se recomienda adjuntar (o preparar) los siguientes videos:
            
            **ğŸ¥ Video 1: CÃ³mo usar Lucid para editar el Journey**
            
            - **Objetivo:** enseÃ±ar a los participantes cÃ³mo editar correctamente su copia del Journey base.
            - **Incluye:**
                - CÃ³mo agregar triggers entre bloques.
                - CÃ³mo usar colores, emojis y comentarios.
                - CÃ³mo identificar tareas internas, decisiones y eventos.
            
            **ğŸ¥ Video 2: AutomatizaciÃ³n por tareas y eventos**
            
            - **Objetivo:** acompaÃ±ar el mensaje del hilo con una explicaciÃ³n clara del concepto de triggers, su utilidad y cÃ³mo se representan en el Caso Journey.
            - **Incluye:**
                - ExplicaciÃ³n de la diferencia entre eventos externos (hechos jurÃ­dicos) y tareas internas (actos jurÃ­dicos).
                - Ejemplos concretos de triggers reales y sus acciones asociadas.
                - IntroducciÃ³n al Caso Journey como herramienta para mapear lÃ³gica operativa.
                - Uso de la IA para apoyar la clasificaciÃ³n y validaciÃ³n de estos elementos.
            
            ğŸ“Œ **Nota:** Si el equipo es nuevo o el mÃ³dulo se activa por primera vez en una etapa, estos videos deben estar disponibles y enlazados desde el mensaje de hilo o la instrucciÃ³n general del tablero.
            
        
        ---
        
- **4.1.4.2 ğŸ” RevisiÃ³n de resultados (fase asincronica)**
    
    Una vez que el equipo ha respondido su tablero individual, el Researcher debe generar una **sÃ­ntesis clara y Ãºtil** para preparar la fase sincrÃ³nica.
    
    El objetivo no es evaluar personas, sino **diagnosticar el sistema actual** a partir de la experiencia del equipo:
    
    quÃ© sÃ­ntomas aparecen, quÃ© se repite, quÃ© estÃ¡ ausente y cÃ³mo se vive el proceso.
    
    ---
    
    ### ğŸ—‚ Carga de respuestas
    
    El Researcher recopila todas las respuestas del tablero en una tabla editable con el siguiente formato:
    
    | Participante | Pregunta 1 | Pregunta 2 | Pregunta 3 | Pregunta 4 | EvaluaciÃ³n de la dinÃ¡mica |
    | --- | --- | --- | --- | --- | --- |
    
    > El campo â€œÂ¿Te hizo sentido este tablero? Â¿QuÃ© mejorarÃ­as para hacerlo mÃ¡s claro o mÃ¡s Ãºtil?â€ debe agregarse en todas las dinÃ¡micas.
    > 
    > 
    > Esta retroalimentaciÃ³n serÃ¡ parte de la conversaciÃ³n con el agente IA.
    > 
    
    ---
    
    ### ğŸ¤– RevisiÃ³n con el agente IA (Preguntas 2, 3, 4 y feedback)
    
    El anÃ¡lisis se realiza **pregunta por pregunta** (excepto Pregunta 1), en conjunto con el agente IA. Para cada una:
    
    1. **Lectura de respuestas individuales mÃ¡s relevantes**
        
        El agente IA presenta directamente las respuestas desde la tabla, seÃ±alando:
        
        - QuÃ© se repite.
        - QuÃ© estÃ¡ claro, confuso o fuera de foco.
        - QuÃ© vale la pena citar textual.
    2. **Propuesta de sÃ­ntesis del agente**
        
        Una lectura general organizada que identifica:
        
        - Fricciones o sÃ­ntomas comunes.
        - Contradicciones o tensiones.
        - VacÃ­os importantes.
        - ConexiÃ³n (o no) con los sÃ­ntomas detectados.
    3. **Ajuste conjunto con el Researcher**
        
        El Researcher valida o corrige la sÃ­ntesis. Esta versiÃ³n curada serÃ¡ la base para el tablero sincrÃ³nico.
        
    4. **RevisiÃ³n de la evaluaciÃ³n de la dinÃ¡mica**
        
        El agente IA muestra las respuestas a la pregunta â€œÂ¿Te hizo sentido este tablero?â€, para que el Researcher:
        
        - Detecte puntos de confusiÃ³n o malentendidos en la estructura.
        - Mejore el diseÃ±o futuro de la dinÃ¡mica.
        - Ajuste el mensaje o la facilitaciÃ³n si hay patrones de insatisfacciÃ³n.
    
    ---
    
    ### ğŸš« Sobre el Bloque 3: ğŸ§© AsÃ­ ocurre (segÃºn tÃº)
    
    Este bloque **no se revisa con el agente IA**.
    
    Es un trabajo **exploratorio y libre del Researcher**, que debe:
    
    - Revisar los journeys propuestos por el equipo.
    - Extraer hipÃ³tesis, pasos crÃ­ticos y posibles puntos de automatizaciÃ³n.
    - DiseÃ±ar un primer borrador del **Case Journey**, a trabajar en la jornada sincrÃ³nica.
    
    > Este diseÃ±o debe ser revisado por el LÃ­der Researcher, para alinear criterios de calidad metodolÃ³gica.
    > 
    
    > Deuda tÃ©cnica pendiente: formalizar orientaciones para construir un Case Journey desde el anÃ¡lisis del Bloque 3.
    > 
    
    ---
    
    ### âœ… Resultado final
    
    - Una **sÃ­ntesis por pregunta** (2, 3, 4) lista para facilitar la conversaciÃ³n del Kickoff sincrÃ³nico.
    - Un primer diseÃ±o del **Case Journey**, basado en la experiencia real.
    - Un levantamiento cualitativo sobre **cÃ³mo se viviÃ³ la dinÃ¡mica**, Ãºtil para iterar el mÃ³dulo.

---

- **4.1.4.3 ğŸ§­ ConducciÃ³n del Kickoff SincrÃ³nico â€“ Esquema Base**
    
    El Kickoff debe desarrollarse con claridad, ritmo emocional y sentido tÃ©cnico. La dinÃ¡mica se estructura en cinco momentos discursivos, cada uno con un objetivo especÃ­fico y con responsabilidades claras entre el **LÃ­der** (voz de la visiÃ³n) y la **Facilitadora** (energÃ­a y cuidado del grupo).
    
    ---
    
    ### 4.1.4.2.1 ğŸª„ Apertura â€“ Reir, Alinear, Disparar
    
    ## 4.1.4.2.1.1ğŸª„Fase 1: Reir
    
    ## 4.1.4.2.1.1.1ğŸ™ Paso 1: **Bienvenida Showcera**
    
    ğŸ‘‰ *Â¿QuiÃ©n la hace?*
    
    **La persona con mÃ¡s habilidades para â€œpegarse el showâ€** â€” no importa si es el LÃ­der o el Facilitador. Lo importante es **romper el hielo con estilo, humor y calidez**.
    
    ---
    
    ### ğŸŒŸ Â¿QuÃ© buscamos?
    
    Que el equipo **sienta que estÃ¡ entrando a una conversaciÃ³n distinta**, cercana, entretenida y con sentido. Una bienvenida emocional bien hecha:
    
    - **Desarma la tensiÃ³n** tÃ­pica de las reuniones formales.
    - **Activa emocionalmente** al equipo.
    - **Crea confianza** para hablar con honestidad.
    - Marca un tono de **alegrÃ­a, colaboraciÃ³n y protagonismo**.
    
    ---
    
    ### ğŸ¤ EstÃ¡ndar aspiracional:
    
    > El equipo tiene tanta confianza que quien hace la bienvenida puede entrar cantando, rapeando o inventando un narrativa ficticia. No se trata de ser artista, sino de atreverse a hacer el ridiculo.
    > 
    
    ---
    
    ### ğŸ”‘ Recomendaciones prÃ¡cticas:
    
    - Usa un recurso inesperado: **mÃºsica, una frase con humor, un objeto simbÃ³lico, una referencia pop**.
    - Incluye al equipo: menciÃ³nales, haz una broma interna, conÃ©ctalos con algo que compartieron recientemente.
    - Evita lecturas, formalidades o frases genÃ©ricas.
    - Muestra emociÃ³n: **si tÃº no te diviertes al iniciar, nadie mÃ¡s lo harÃ¡.**
    
    ## **4.1.4.2.1.1.2 ğŸ­ Paso 2: DinÃ¡mica de Rompehielo (con Humor)**
    
    ---
    
    ### ğŸ§  Â¿Para quÃ© sirve este momento?
    
    La dinÃ¡mica de rompehielo **no es solo para que hablen todos**: es una herramienta para **generar complicidad, risa compartida y desdramatizar** lo que viene. Tiene que mover emociones, **no parecer una encuesta grupal**.
    
    Este es el segundo disparo emocional de la apertura: ya hubo show, ahora toca **hacer reÃ­r al grupo desde lo cotidiano y lo absurdo**.
    
    ---
    
    ### ğŸ’¡ Â¿QuÃ© buscamos?
    
    - Que **todos participen sin presiÃ³n**, incluso los mÃ¡s tÃ­midos.
    - Que el grupo **suelte una risa genuina o al menos una sonrisa**.
    - Que el equipo se escuche de forma horizontal y divertida.
    - Que la reuniÃ³n **no arranque en modo oficina**, sino en modo juego + colaboraciÃ³n.
    
    ---
    
    ### ğŸ“Œ Orientaciones para una buena dinÃ¡mica:
    
    - **Evita preguntas serias o profundas**: la profundidad vendrÃ¡ despuÃ©s.
    - Elige preguntas **ligeras, absurdas o que despierten imÃ¡genes graciosas**.
    - Prefiere formatos donde **las respuestas sean breves y todos pasen rÃ¡pido**.
    - **Fomenta lo inesperado**: que el equipo se sorprenda y se rÃ­a de sus propias ocurrencias.
    - **No la alargues demasiado**: una buena ronda de 3-5 minutos es suficiente para prender motores.
    
    ---
    
    ### ğŸš« QuÃ© evitar:
    
    - Preguntas tipo â€œÂ¿quÃ© esperas del Kickoff?â€ (muy racional).
    - DinÃ¡micas competitivas o que generen incomodidad.
    - Falta de ritmo: si la energÃ­a cae, el rompehielo no sirviÃ³.
    
    Paso 2: Rompejielo y rompehielo
    
    **Responsable:** Facilitadora
    
    1. Da la bienvenida en tono cÃ¡lido y cercano.
    2. Refuerza que este espacio **no es para evaluar personas**, sino para **mejorar el sistema juntos**.
    3. Lanza un rompehielo simple, pero emocional:
        - â€œEn una palabra, Â¿quÃ© emociÃ³n te genera esta etapa hoy?â€
        - â€œSi esta etapa fuera un paisaje, Â¿cÃ³mo se verÃ­a?â€
        - â€œÂ¿QuÃ© te gustarÃ­a que cambiara mÃ¡gicamente en esta etapa?â€
    4. Anima a todos a participar. **Si alguien no habla, invÃ­talo directamente con suavidad.**
    5. Reacciona con expresividad: â€œÂ¡QuÃ© buena imagen!â€, â€œUff, entiendo esa emociÃ³nâ€, etc.
    
    ## 4.1.4.2.1.2 ğŸ§­ Fase 2: Alinear
    
    ## **4.1.4.2.1.3 ğŸ¯ Fase 3: Disparar**
    
    ---
    
    ---
    
    ### 4.1.4.2.2 **ğŸ‘ï¸ Lo que ves y vives en esta etapa**
    
    - **Objetivo:** Presentar las ideas centrales del diagnÃ³stico asincrÃ³nico: sÃ­ntomas detectados, patrones relevantes y fricciones destacadas.
    - **Responsable:** LÃ­der.
    - **DinÃ¡mica:**
        - El LÃ­der expone sÃ­ntesis por pregunta, sin leer respuestas una por una.
        - Lanza preguntas detonadoras para abrir el debate.
        - La Facilitadora asegura que todos participen, reconoce aportes y cuida el tiempo.
    
    ---
    
    ### 4.1.4.2.3 â¸ï¸ Pausa y T**ransiciÃ³n**
    
    - **Objetivo:** Marcar el cambio de mentalidad: pasamos de â€œcÃ³mo se viveâ€ a â€œcÃ³mo deberÃ­a gestionarseâ€.
    - **Responsable:** LÃ­der, con apoyo emocional de la Facilitadora.
    - **Mensaje clave:** Este segundo bloque es una propuesta inicial de diseÃ±o, paso a paso. Se puede intervenir libremente, pero respetando el orden para no perder foco.
    
    ---
    
    ### 4.1.4.2.4 ğŸ§© **ExposiciÃ³n del Journey**
    
    - **Objetivo:** Presentar el flujo propuesto por el equipo Research, paso a paso, para que el equipo lo contraste con su experiencia real.
    - **Responsable:** LÃ­der.
    - **DinÃ¡mica:**
        - Se explica cada paso brevemente.
        - Se abren intervenciones inmediatas con preguntas como:
            - â€œÂ¿Este paso refleja la prÃ¡ctica real?â€
            - â€œÂ¿Se entiende su lÃ³gica?â€
        - Se recogen ideas antes de pasar al siguiente paso. **No es un espacio de decisiones, sino de contraste y propuesta.**
    
    ---
    
    ### 4.1.4.2.5ğŸ **Palabra de cierre**
    
    - **Objetivo:** Dar sentido al trabajo realizado, resumir hallazgos clave y proyectar los prÃ³ximos pasos (ej. diseÃ±o del Desk, automatizaciones, formaciÃ³n).
    - **Responsables:**
        - **LÃ­der**: entrega direcciÃ³n y claridad tÃ©cnica.
        - **Facilitadora**: cierra con reconocimiento humano y emocional al equipo.
    
    Esta fase es de convergencia. Se valida lo propuesto, se cierran ambigÃ¼edades y se deja trazabilidad clara de cÃ³mo esta etapa empieza a convertirse en sistema.
    
    > Esta reuniÃ³n se realiza exclusivamente con el Team Ops (ejecutivos/as legales y abogados/as que operan esta etapa), no con el Consejo.
    > 
    
    ---
    

---

### 4.1.5 ğŸƒ Notas metodolÃ³gicas especÃ­ficas

**ğŸ”§ 1. No se parte desde automatizaciones**

El foco no es diseÃ±ar tareas para bots ni montar flujos ideales.

El foco es detectar **quÃ© eventos hacen avanzar el caso**, y **quÃ© acciones deberÃ­an seguirse naturalmente.**

**ğŸ¤– 2. La IA no inventa el Journey: lo ordena con el Researcher**

El Journey base no se genera por sÃ­ solo.

Se construye **desde lo observado, lo que se repite en la operaciÃ³n y lo que frustra al cliente.**

La IA asiste para ordenar, **pero no reemplaza la agudeza ni el criterio del Researcher.**

**ğŸ§  3. El tablero es una herramienta pedagÃ³gica**

No es solo una visual bonita.

Es la forma que tiene el Researcher de **llevar al equipo a pensar como sistema**, haciendo visible lo que antes era tÃ¡cito.

Bien usado, el tablero permite que el equipo **se exprese, se ordene y se alinee.**

**ğŸ§© 4. La validaciÃ³n no es solo confirmaciÃ³n: es alineaciÃ³n mental**

El Kickoff no es para decir â€œsÃ­ o noâ€ al Journey.

Es para que el equipo **se escuche mutuamente, se entienda, y se alinee con una mirada comÃºn de la etapa.**

**âš™ï¸ 5. Las acciones automÃ¡ticas no replican lo que el equipo hace hoy**

No se trata de copiar el trabajo humano.

Se trata de **detectar lo que el sistema puede ejecutar solo, sin juicio, de forma confiable.**

**ğŸ•³ 6. Si no hay claridad sobre las acciones, se marca vacÃ­o**

No se fuerza la resoluciÃ³n.

Los vacÃ­os son trazables y se trabajan despuÃ©s.

Si un trigger no tiene acciÃ³n clara, se marca como: **ğŸ•³ VacÃ­o tÃ©cnico**, derivable a Big Task, Consultas o Recordatorios.

**ğŸ§± 7. El foco es dejar un sistema mÃ­nimo funcional**

No se busca perfecciÃ³n.

Si el Journey estÃ¡ bien clasificado y las acciones tienen sentido, ya existe una **base replicable para escalar o rediseÃ±ar.**

**ğŸ§‘â€ğŸ¤â€ğŸ§‘ 8. Esta etapa es operativa, no estratÃ©gica**

El mÃ³dulo se trabaja con el equipo operativo, **no con el Consejo.**

Su objetivo es ver quÃ© ocurre hoy, **no modelar soluciones futuras.**

ğŸ” Si el objetivo es entender, se explora con el equipo.

ğŸ§­ Si el objetivo es rediseÃ±ar, se trabaja con el Consejo.

---

### 4.1.6 ğŸ“¤ **Paso a paso posterior al Kickoff**

Una vez finalizado el Kickoff y validado el Journey, el mÃ³dulo no se considera completo hasta que el Researcher haya dejado trazado todo el sistema en formato Ãºtil y vectorizable.

---

**âœ… 1. Marcaje final del Journey**

El Researcher revisa cada trigger del Journey validado y marca su estado:

- âœ… Acciones automÃ¡ticas asociadas acordadas
- ğŸ•³ VacÃ­o tÃ©cnico declarado (si no quedaron claras las acciones)

Este marcaje se hace directamente en el Lucid, Figma o tabla, usando texto, Ã­cono o etiqueta.

---

**ğŸ“ 2. RedacciÃ³n del informe del mÃ³dulo**

El informe no es un formulario. Es un documento editorial, claro y ordenado, que debe dejar trazado:

- El diagnÃ³stico que justificÃ³ la activaciÃ³n
- El Journey validado
- Todas las acciones automÃ¡ticas asociadas por trigger
- Los vacÃ­os tÃ©cnicos detectados
- El aprendizaje emergente

El cuerpo del informe puede estar redactado en texto libre, con tablas funcionales para las acciones por trigger.

Debe permitir que cualquier miembro de diseÃ±o, IA o desarrollo **entienda quÃ© ocurre, quÃ© se propuso, y quÃ© sigue.**

---

**ğŸ“¤ 3. Carga en el Repertorio de Informes por MÃ³dulo**

El informe completo del mÃ³dulo se guarda en:

ğŸ“š **Repertorio de Informes por MÃ³dulo** â†’ dentro de la **Biblia Research Core**

- Carpeta: `Triggers y Acciones AutomÃ¡ticas`
- Subcarpeta: `Informe - Etapa [Nombre] - [Fecha]`

---

**ğŸ“˜ 4. Enlace en la Biblia del Servicio correspondiente**

En la Biblia del Servicio (ej. Litigios), se deja el link al informe bajo la etapa correspondiente, con una nota breve sobre lo que resolviÃ³ el mÃ³dulo y quÃ© puntos quedaron pendientes.

---

**ğŸ“ Â¿QuÃ© debe quedar registrado?**

- âœ… Journey final validado (en visual o tabla)
- âš™ï¸ Acciones automÃ¡ticas asociadas por trigger
- ğŸ“‘ Informe completo con diagnÃ³stico, acciones y aprendizaje
- ğŸŒ± DiagnÃ³stico de aprendizaje
- ğŸ”— Enlace referencial en la Biblia del Servicio y la Research Core

---

### âš ï¸4.1.7. âš™ï¸ Requerimientos especÃ­ficos del Informe del MÃ³dulo

**âš ï¸ AtenciÃ³n IA: esta secciÃ³n esta dÃ©bil, debe ser mejorada con el correr del tiempo cuando comencemos a generar y cargar nuestros primeros informes.** 

### 4.1.7.1  ğŸ—ºï¸ Journey validado

*(Se adjunta Lucid o tabla con los pasos clasificados como ğŸŸ  / ğŸ”´ / ğŸ”µ)*

### 4.1.7.2âš™ï¸ Acciones automÃ¡ticas asociadas por trigger

### ğŸ”µ Trigger: Cliente hace click en â€œEnviar InformaciÃ³nâ€ en Ficha Web

- **ğŸ—‚ Tipo**: Evento externo
    - **ğŸ“ Etapa**: ğŸŸ¦ Nuevo Caso
    - **ğŸ¯ PropÃ³sito**: Marca el cierre del ingreso de informaciÃ³n por parte del cliente y activa la preparaciÃ³n del expediente.
        
        
        | NÂ° | AcciÃ³n automÃ¡tica | Sistema | PropÃ³sito | Estado |
        | --- | --- | --- | --- | --- |
        | 1 | Carga informaciÃ³n en la BBDD | CRM | Registrar los datos del formulario | âœ… |
        | 2 | Marca â€œFicha Web Completadaâ€ | CRM | Confirmar cierre de la ficha | âœ… |
        | 3 | Cambia etapa a â€œPara Estudioâ€ | CRM | TransiciÃ³n operativa al siguiente tramo | âœ… |
        | 4 | Crea tarea â€œObtener Docs Nuestrosâ€ | CRM / Task | Inicia el trabajo del ejecutivo | âœ… |
        | 5 | Completa campo â€œPendienteâ€ | CRM | Deja la tarea en estado inicial | âœ… |
        | 6 | Completa campo â€œRecomendaciÃ³nâ€ con â€œ.â€ | CRM | Marcador para observaciÃ³n futura | âœ… |
        | 7 | Crea carpeta del cliente (en mayÃºsculas) | Drive | Organiza el expediente | âœ… |
        | 8 | Crea subcarpetas estÃ¡ndar | Drive | ACREEDORES, ACTIVOS, etc. | âœ… |
        | 9 | Pega el link en campo [ğŸ—’ï¸Drive] | CRM | Acceso directo desde CRM | âœ… |
        | 10 | Genera PDF de la ficha y lo guarda | Drive | Archivo de respaldo | âœ… |
        | 11 | Mueve contacto en embudo â€œPara Estudioâ€ | Vambe | SincronizaciÃ³n CRMâ€“comercial | âœ… |
        | 12 | Detona plantilla automÃ¡tica [nombre pendiente] | Vambe | ComunicaciÃ³n inicial al cliente | ğŸ•³ |
    
    ---
    
    **ğŸ§  Notas internas:**
    
    - La acciÃ³n 12 quedÃ³ como vacÃ­o tÃ©cnico. Se derivarÃ¡ al mÃ³dulo de Consultas o Recordatorios.
    - Las demÃ¡s acciones fueron validadas con el equipo operativo durante la sesiÃ³n.

---

---

## **4.2. 2ï¸âƒ£ğŸ§© MÃ³dulo Big Task**

---

### **4.2.1 ğŸ”§ Â¿QuÃ© sÃ­ntoma activa este mÃ³dulo?**

Este mÃ³dulo se activa cuando una tarea crÃ­tica del sistema no estÃ¡ clara, bien ejecutada o lista para ser diseÃ±ada. Los sÃ­ntomas mÃ¡s comunes son:

---

### âš ï¸ Problemas operativos

1. **EstÃ¡ mal ejecutada**

> Se cometen errores, cada persona la hace distinto o los resultados no son confiables.
> 
1. **Genera confusiÃ³n operativa**

> No hay acuerdo de quÃ© pasos incluye, quÃ© orden tienen o cuÃ¡ndo se considera bien hecha.
> 
1. **No tiene trazabilidad**

> La tarea se hace, pero no queda claro quiÃ©n la hizo, cÃ³mo se hizo o si fue bien realizada.
> 

---

### **4.2.2 ğŸ¯ Resultado esperado del mÃ³dulo**

Este mÃ³dulo no busca observar quÃ© hace avanzar el sistema (como en el MÃ³dulo 1 â€“ Triggers), sino **diseccionar y estructurar en profundidad una tarea crÃ­tica completa**, paso por paso, desde lo operativo hasta lo cognitivo.

El foco es construir un flujo **ejecutable**, no idealizado; **estructurado**, no difuso; y que permita **automatizar lo que se pueda**, y **acompaÃ±ar lo que se debe**.

---

Al finalizar este mÃ³dulo, el equipo debe contar con:

---

### **1. Un flujo paso a paso curado**

> Redactado con claridad, en orden real de ejecuciÃ³n.
> 
> 
> No se trata de procesos ideales, sino de cÃ³mo ocurre realmente la tarea en terreno.
> 

---

### **2. ClasificaciÃ³n de cada paso por tipo de acciÃ³n**

> Cada paso debe estar clasificado como:
> 
- ğŸª¨ **Roca**: acciÃ³n estructurable, precisa, repetitiva, automatizable
- ğŸŒ¬ï¸ **Viento**: acciÃ³n que requiere criterio, interpretaciÃ³n o acompaÃ±amiento
- ğŸŒ€ **Mixto**: combina ambos tipos de acciÃ³n

---

### **3. DiagnÃ³stico y recursos por paso**

- Para los pasos ğŸª¨ Roca: se propone una posible **automatizaciÃ³n, validaciÃ³n o prellenado**.
- Para los pasos ğŸŒ¬ï¸ Viento: se sugiere al menos **un recurso de apoyo**, como guÃ­a, formaciÃ³n, IA o mentorÃ­a.

> Estos recursos no se implementan en este mÃ³dulo, pero se trazan como insumos para Producto, Personas, DiseÃ±o o IA.
> 

---

### **4. Propuesta inicial de campos por paso y agrupaciÃ³n por bloques**

> Por cada paso se sugieren los campos funcionales necesarios, clasificados como:
> 
- ğŸŒ¬ï¸ Viento: campos que requieren apoyo cognitivo (comentario, juicio, justificaciÃ³n)
- ğŸª¨ Roca: campos de digitaciÃ³n, selecciÃ³n o confirmaciÃ³n tÃ©cnica

> Luego se agrupan en bloques funcionales (futuras pestaÃ±as), organizados por tipo de acciÃ³n o intenciÃ³n del usuario
> 

---

### **5. Narrativa breve de la Big Task**

> Una frase concreta que exprese, desde el punto de vista del usuario, quÃ© se espera lograr con esta tarea.
> 

---

### **6. Tablero trazado, compartido y listo para diagnÃ³stico**

> El tablero contiene:
> 
- El flujo curado
- Los campos propuestos
- Las agrupaciones por bloque
- La carga cognitiva
- Las etiquetas ğŸª¨/ğŸŒ¬ï¸ por paso

> Este tablero es la entrada directa para:
> 
- DiseÃ±o del prototipo (Desk en Vercel)
- ValidaciÃ³n con usuarios reales
- PresentaciÃ³n en el Consejo (paso 4.2.5)
- ImplementaciÃ³n futura

---

### ğŸ§  Sobre la complejidad del mÃ³dulo

Este mÃ³dulo requiere trabajo en equipo.

Si bien parte desde la observaciÃ³n operativa, su potencia estÃ¡ en la **discusiÃ³n tÃ¡ctica posterior y la capacidad de estructurar lo observado**.

---

### ğŸ‘¥ Roles que participan activamente:

| Fase | Rol protagonista |
| --- | --- |
| 4.2.3 | Legal Researcher (estructuraciÃ³n inicial) |
| 4.2.4 | Legal Designer (traducciÃ³n a campos e interfaz) |
| 4.2.5 | Legal Designer + Consejo (diagnÃ³stico por paso) |
| 4.2.6 | Product Manager (planificaciÃ³n tÃ¡ctica y deuda) |

> Solo con esta coordinaciÃ³n por capas se puede convertir una tarea compleja en un sistema que funcione bien, escale y acompaÃ±e sin fricciÃ³n.
> 

---

### **4.2.3 âœ¨ ExploraciÃ³n previa requerida**

Este mÃ³dulo parte desde la observaciÃ³n directa de quienes ejecutan la tarea crÃ­tica. No se trata de preguntar quÃ© creen que hacen, sino de **ver cÃ³mo realmente la ejecutan**.

La exploraciÃ³n no busca eficiencia ni rapidez: busca fidelidad, comprensiÃ³n compartida y trazabilidad para construir desde lo real.

---

### **4.2.3.1 ObservaciÃ³n directa a todo el equipo operativo**

El Researcher y el Designer se reÃºnen con **todas las personas que ejecutan la Big Task**.

Cada integrante del equipo operativo muestra **cÃ³mo realiza la tarea en vivo**, compartiendo pantalla o relatando su flujo real.

- Las sesiones pueden ser individuales o grupales.
- El **Researcher guÃ­a la conversaciÃ³n y hace las preguntas**, enfocÃ¡ndose en entender los pasos reales, variaciones y criterios usados.
- El **Designer observa y registra todo directamente en el chat con la IA**, dejando trazabilidad paso a paso de lo observado:
    - Acciones concretas
    - Fricciones detectadas
    - TÃ©rminos usados por los operativos
- No se interrumpe ni se optimiza el flujo: se documenta tal como ocurre.

> Si hay diferencias entre personas, se registran como variantes o flujos paralelos.
> 
> 
> **No se busca consenso**, se busca **entender la diversidad real del proceso**.
> 

---

### **4.2.3.2 Estructura y jerarquÃ­a del Desk (curadurÃ­a con IA)**

Una vez finalizadas las sesiones de levantamiento, el **Legal Designer toma el liderazgo del proceso de estructuraciÃ³n**, trabajando directamente con la IA para convertir lo observado en una propuesta clara de Desk: pasos ordenados, campos sugeridos y bloques funcionales preliminares.

El Researcher acompaÃ±a este proceso como segunda opiniÃ³n, validando que la propuesta mantenga fidelidad a lo observado y no introduzca distorsiones ni supuestos nuevos.

Se recomienda que el Researcher active el siguiente modulo, mientras deja al Designer trabajar. 

### ğŸ¯ Objetivo

Transformar el flujo observado en una estructura lÃ³gica, priorizada y comprensible para el usuario final.

Esta curadurÃ­a servirÃ¡ como **base trazable para el prototipado en Vercel** o para ser enviada directamente a Stitch.

---

### ğŸ§© Fase 1: Validar y acordar el orden de los pasos

- El Designer presenta a la IA los pasos observados (segÃºn el levantamiento del mÃ³dulo anterior).
- Se **acuerda el orden natural y funcional** de ejecuciÃ³n, evitando interpretaciones o reorganizaciones externas.
- Se corrigen redundancias, divisiones innecesarias o pasos ambiguos.
- Cada paso queda numerado y titulado con una acciÃ³n clara.

ğŸ’¬ *Ejemplo de trazado en chat:*

```yaml
Paso 1: Revisar documentos entregados
Paso 2: Indicar si estÃ¡n correctos
Paso 3: Comentar en caso de error
```

---

### ğŸ§© Fase 2: GeneraciÃ³n de campos sugeridos

En esta fase, el Designer trabaja con la IA para **crear los campos funcionales** que formarÃ¡n parte del futuro Desk, a partir de los pasos observados en terreno.

---

### 1ï¸âƒ£ Crear campos por paso

Por cada paso del flujo operativo, el Designer define **quÃ© se le va a pedir hacer al usuario**, en forma de uno o mÃ¡s campos.

ğŸ’¬ *Ejemplo:*

```yaml
yaml
Paso 2: Indicar si el documento es correcto
â†’ Campo 1: SelecciÃ³n â€œCorrecto / Incorrectoâ€
â†’ Campo 2: Comentario (si es â€œIncorrectoâ€)

```

---

### 2ï¸âƒ£ Clasificar el tipo de esfuerzo: Roca / Viento

Cada campo creado se clasifica segÃºn el tipo de esfuerzo que exige del usuario:

- ğŸª¨ **Roca** â†’ AcciÃ³n precisa y concentrada.
    
    El usuario debe ingresar o confirmar informaciÃ³n sin margen de error.
    
- ğŸŒ¬ï¸ **Viento** â†’ AcciÃ³n exploradora.
    
    El usuario necesita revisar, buscar o interpretar informaciÃ³n antes de responder.
    

---

### 3ï¸âƒ£ Marcar atributos adicionales (si aplica)

- **Condicional**: el campo aparece solo en ciertas situaciones.
- **Automatizable**: no requiere intervenciÃ³n humana.

---

### ğŸ” ValidaciÃ³n con el Researcher

Una vez terminado el listado de campos por paso, el Designer presenta su propuesta al Researcher **antes de agrupar**.

El rol del Researcher es validar fidelidad con lo observado:

- Que no falte nada relevante.
- Que no haya campos agregados por deducciÃ³n.
- Que el orden y contenido respeten la experiencia real.

ğŸ’¬ *Ejemplo trazado en chat:*

```yaml
Paso 2: Indicar si el documento es correcto
â†’ Campo 1: SelecciÃ³n â€œCorrecto / Incorrectoâ€ (ğŸŒ¬ï¸ Viento)
â†’ Campo 2: Comentario (solo si es â€œIncorrectoâ€) (ğŸª¨ Roca â€“ condicional)
â†’ Campo 3: Fecha del documento (ğŸª¨ Roca)

```

---

### ğŸ§© Fase 3: AgrupaciÃ³n preliminar en bloques funcionales

Con los campos ya validados y clasificados (en Fase 2), el Designer trabaja con la IA para agruparlos en **bloques funcionales**. Cada bloque serÃ¡ una pestaÃ±a del futuro Desk y debe contener campos relacionados por tema o tipo de informaciÃ³n.

---

### ğŸ“¦ Cada bloque debe incluir:

1. **ğŸ·ï¸ Nombre del bloque**
    - Una categorÃ­a clara que agrupe los campos.
        
        Ej: *Documentos pendientes*, *Datos personales*, *Patrimonio*, *Acreedores*, *Deudas*.
        
2. **ğŸ¯ AcciÃ³n principal esperada en el bloque**
    - Â¿QuÃ© debe lograr el usuario en esta secciÃ³n?
        
        Ej: â€œRevisar si los documentos entregados son correctos y dejar comentarios si hay errores.â€
        
3. **ğŸ“‹ Lista de pasos y campos incluidos**
    - Escribe los campos de cada paso en el bloque que corresponda.
    - Si un mismo paso tiene campos en mÃ¡s de un bloque, indÃ­calo como **(parcial)**.
    - ğŸ’¬ *Ejemplo:*
        
        ```yaml
        Paso 2: Indicar si el documento es correcto
        â†’ Campo 1: SelecciÃ³n â€œCorrecto / Incorrectoâ€ (ğŸŒ¬ï¸ Viento)
        â†’ Campo 2: Comentario (solo si es â€œIncorrectoâ€) (ğŸª¨ Roca â€“ condicional)
        â†’ Campo 3: Fecha del documento (ğŸª¨ Roca)
        ```
        
    - ğŸ’¬ *Ejemplo si el paso se divide entre bloques:*
        
        **Bloque A â€“ RevisiÃ³n inicial**
        
        ```yaml
        Paso 2 (parcial): Indicar si el documento es correcto
        â†’ Campo 1: SelecciÃ³n â€œCorrecto / Incorrectoâ€ (ğŸŒ¬ï¸ Viento)
        
        ```
        
        **Bloque B â€“ Observaciones**
        
        ```yaml
        Paso 2 (parcial): Indicar si el documento es correcto
        â†’ Campo 2: Comentario (solo si es â€œIncorrectoâ€) (ğŸª¨ Roca â€“ condicional)
        â†’ Campo 3: Fecha del documento (ğŸª¨ Roca)
        
        ```
        

---

### ğŸ§  Â¿QuÃ© hace el Researcher?

- Revisa si algÃºn agrupamiento **rompe con lo observado en terreno** o pierde sentido funcional.
- No interviene en decisiones visuales o de diseÃ±o, solo en **fidelidad operativa**.

---

### 4.2.3.3 JSON de bloques y campos

Este documento resume la informaciÃ³n trazada por la IA durante la Fase 2 (creaciÃ³n de campos por paso) y la Fase 3 (agrupaciÃ³n en bloques), en un formato estandarizado y legible tanto para humanos como para sistemas automatizados.

### ğŸ“Œ Objetivo del documento:

- Servir como insumo directo para construir el Desk en Vercel o Stitch.
- Reflejar con fidelidad la lÃ³gica operativa y visual del flujo.
- Evitar reprocesos innecesarios o dependencias del Designer para estructurar lo ya definido.

---

### ğŸ“„ Estructura del documento:

```json

{
  "desk": {
    "nombre_desk": "Validar DocumentaciÃ³n",
    "accion_central": "Confirmar si los documentos entregados estÃ¡n correctos",
    "generado_por": "IA asistida por Designer",
    "validado_por": "Researcher"
  },
  "bloques": [
    {
      "nombre_bloque": "Documentos pendientes",
      "accion_esperada": "Revisar cada documento entregado y marcar si estÃ¡ correcto o incorrecto",
      "campos": [
        {
          "paso": "Paso 2",
          "campo": "SelecciÃ³n 'Correcto / Incorrecto'",
          "tipo": "ğŸŒ¬ï¸ Viento",
          "condicional": false}
      ]
    },
    {
      "nombre_bloque": "Observaciones",
      "accion_esperada": "Dejar comentarios sobre documentos incorrectos y registrar fecha de emisiÃ³n",
      "campos": [
        {
          "paso": "Paso 2",
          "campo": "Comentario (solo si es Incorrecto)",
          "tipo": "ğŸª¨ Roca",
          "condicional": true},
        {
          "paso": "Paso 2",
          "campo": "Fecha del documento",
          "tipo": "ğŸª¨ Roca",
          "condicional": false}
      ]
    }
  ],
  "meta": {
    "chat_origen": "chat-lexy://modulo-4.2.3.2",
    "designer": "Nombre del Designer",
    "researcher": "Nombre del Researcher",
    "fecha": "2025-05-XX"
  }
}

```

---

### âœ… Consideraciones clave para la IA

- Cada **campo debe quedar vinculado a su paso original**.
- Los bloques deben incluir:
    - nombre funcional
    - una acciÃ³n clara que se espera del usuario
    - los campos ordenados
    - su tipo (Roca/Viento)
    - si son condicionales
- La IA debe poder generar este documento **con solo haber completado correctamente las fases anteriores** (pasos, campos y agrupaciÃ³n), sin requerir reexplicaciÃ³n.

---

### **4.2.4 ğŸ›  Prototipado**

Una vez generado el **JSON de bloques y campos** (con pasos, acciones, campos y tipo de esfuerzo), el Legal Designer guÃ­a la construcciÃ³n del Desk **directamente desde el chat con el Agente Designer Lexy**.

Este agente estÃ¡ conectado a **Vercel vÃ­a API**, lo que permite construir y editar cada bloque de forma automÃ¡tica, sin tener que copiar cÃ³digo manualmente.

---

### 4.2.4.1 ğŸ§­ Objetivo

Construir el Desk en Vercel de forma **iterativa y trazable**, asegurando que:

- Cada bloque funcional se construya de forma independiente.
- Los campos ya definidos se traduzcan en una interfaz funcional.
- Se apliquen las mejores prÃ¡cticas del **Lexy UI System**.

### 4.2.4.2ğŸ”¹ **Paso 1 â€“ Solicitar el prototipo de un bloque con estÃ¡ndar Lexy**

ğŸ§  **Desde ChatGPT (Agente Designer Lexy)**

ğŸ¯ **Objetivo:** Activar la construcciÃ³n del primer prototipo de un bloque del Desk en Vercel, con la mejor calidad posible desde el inicio.

---

ğŸ’¬ **Prompt estÃ¡ndar:**

> â€œPrototipemos en Vercel el bloque â€˜Documentos pendientesâ€™ del Desk â€˜Validar documentosâ€™.
> 
> 
> Usa el **JSON de bloques y campos** ya trazado en este chat (o disponible por ID).
> 
> Quiero que me entregues una **versiÃ³n inicial de alta calidad**, como si ya hubiera pasado por testeo con usuarios:
> 
> - DiseÃ±o basado en la acciÃ³n que el usuario debe ejecutar.
> - Campos ordenados y jerarquizados segÃºn su tipo (ğŸª¨ Roca / ğŸŒ¬ï¸ Viento).
> - Condicionalidad correctamente aplicada.
> - Ayudas visuales cuando corresponda.
> - Texto y botones con lenguaje humano.
> - Sin sobrecarga ni elementos innecesarios.
> 
> Aplica desde el inicio el **Lexy UI System**, incluyendo jerarquÃ­a visual, espaciado limpio, accesibilidad y tono claro.
> 
> Si algÃºn campo no puede representarse correctamente, **explÃ­camelo antes de mostrar el prototipo.**
> 
> Quiero una versiÃ³n que me sorprenda:
> 
> *â€œEsto estÃ¡ tan bien resuelto que apenas necesito ajustar.â€*
> 

---

ğŸ“¤ **Lo que el Agente IA debe devolver:**

- ğŸ§± Estructura completa del bloque
- âœ… Campos con clasificaciÃ³n (ğŸª¨ / ğŸŒ¬ï¸) y condicionalidad
- ğŸ”— Link al proyecto en Vercel (preview funcional)
- ğŸ“˜ Breve explicaciÃ³n de decisiones tomadas por la IA

---

ğŸ“Œ **Notas para asegurar calidad:**

- El Agente debe aplicar directamente las guÃ­as del **Lexy UI System**, entendiendo que:
    - ğŸª¨ Roca â†’ requiere concentraciÃ³n â†’ Ã©nfasis, ayudas, claridad visual.
    - ğŸŒ¬ï¸ Viento â†’ requiere exploraciÃ³n â†’ espacio, contexto, orientaciÃ³n.
- Si hay ambigÃ¼edad, el agente pregunta antes de avanzar.
- Toda la conversaciÃ³n y decisiones quedan trazadas en el chat

### 4.2.4.3ğŸ”¹ **Paso 2 â€“ Revisar y comentar el bloque generado (en ChatGPT)**

ğŸ§  **Lugar:** ChatGPT (Agente Designer Lexy)

ğŸ’» **Referencia visual:** Link en Vercel

ğŸ¯ **Objetivo:** Evaluar la interfaz generada y dejar trazado el feedback, campo por campo, directamente en el chat.

---

### ğŸ” Â¿CÃ³mo se realiza?

1. El Designer accede al **link de Vercel** generado por el agente.
2. Recorre visualmente el bloque como si fuera el usuario final.
3. Vuelve al chat con el Agente y da feedback libremente pero siendo meticuloso

---

### ğŸ§  Promptear bien es parte del trabajo

El trabajo de revisar y pedir mejoras no es solo una correcciÃ³n, **es una habilidad estratÃ©gica**.

**Saber expresar con claridad lo que debe cambiar es parte clave del rol de Legal Designer.**

Si el Designer tiene dudas sobre cÃ³mo expresarse o quÃ© pedir, **puede preguntarle al propio agente**, quien estÃ¡ capacitado para:

- EnseÃ±arle a dar feedback efectivo.
- Explicar buenas prÃ¡cticas de diseÃ±o en Lexy.
- Simular ejemplos de prompts bien construidos.

ğŸ’¬ *Ejemplo de consulta del Designer al agente:*

> â€œQuiero que este campo se vea mÃ¡s importante, como si estuviera envuelto o separado del resto.
> 
> 
> No sÃ© bien cÃ³mo decirlo... Â¿me enseÃ±as cÃ³mo se pide eso en diseÃ±o UI?â€
> 

---

ğŸ“š **FormaciÃ³n continua**

Todas las preguntas y dudas que los Designers expresan en el chat con el Agente quedan registradas en la meta data del Agente.

Esta informaciÃ³n es revisada por el **LÃ­der del equipo de Legal Designers**, quien:

- Detecta necesidades formativas comunes.
- Asegura acompaÃ±amiento personalizado.
- Construye mejores prÃ¡cticas para el equipo.

---

ğŸ“Œ **Este paso no solo produce una interfaz mejor**, tambiÃ©n mejora las habilidades del equipo y retroalimenta el sistema de aprendizaje continuo de Lexy.

### 4.2.4.4ğŸ”¹ **Paso 3 â€“ Conversar y ejecutar los ajustes solicitados (Agente IA)**

ğŸ§  **Lugar:** ChatGPT (Agente Designer Lexy)

ğŸ¯ **Objetivo:** Aplicar los cambios pedidos por el Designer, conversando primero sobre cualquier complicaciÃ³n, y devolviendo el resultado con explicaciones claras.

---

ğŸ“¤ **Lo que el Agente IA debe hacer antes de ejecutar:**

- Leer el feedback completo del Designer.
- Comentar el feedback e identificar posibles complicaciones tÃ©cnicas o ambigÃ¼edades.

Solo despuÃ©s de esta conversaciÃ³n, se realizan los cambios.

---

ğŸ“¤ **Lo que el Agente IA debe devolver tras ejecutar:**

- ğŸ§± **Bloque actualizado** con los cambios solicitados.
- ğŸ”— **Link al proyecto en Vercel** (preview funcional actualizado).
- ğŸ“˜ **Breve explicaciÃ³n de decisiones tomadas por la IA**, incluyendo:
    - QuÃ© se cambiÃ³.
    - QuÃ© se negociÃ³.
    - QuÃ© se mantuvo o adaptÃ³ y por quÃ©.

---

ğŸ“Œ **Notas para asegurar calidad:**

- El Agente debe aplicar directamente las guÃ­as del **Lexy UI System**, entendiendo que:
    - ğŸª¨ Roca â†’ requiere concentraciÃ³n â†’ Ã©nfasis, ayudas, claridad visual.
    - ğŸŒ¬ï¸ Viento â†’ requiere exploraciÃ³n â†’ espacio, contexto, orientaciÃ³n.
- Si hay ambigÃ¼edad, el Agente **debe conversar antes de ejecutar**.
- Toda la conversaciÃ³n y decisiones quedan trazadas en el chat, formando parte del historial del diseÃ±o.

### 4.2.4.5ğŸ”¹ **Paso 4 â€“ Aplicar el estilo del Lexy UI System (bloque por bloque)**

ğŸ§  **Lugar:** ChatGPT (Agente Designer Lexy)

ğŸ¯ **Objetivo:** Aplicar el estilo visual y la experiencia Lexy al bloque, dejando la versiÃ³n lista para ser presentada a usuarios reales o al Consejo.

---

ğŸ“Œ **Este paso se activa una vez que el Designer ha cerrado su revisiÃ³n funcional.**

El foco es estilizar el bloque para que **se sienta claro, usable y humano**, antes de su validaciÃ³n externa.

> En Lexy, se estiliza bloque por bloque. Cada unidad debe reflejar el estÃ¡ndar visual y emocional Lexy antes de pasar al siguiente.
> 

---

ğŸ“¤ **El Agente IA aplica:**

- ğŸª¨ Roca â†’ Ã©nfasis visual, ayudas visibles, ejemplos si es necesario
- ğŸŒ¬ï¸ Viento â†’ aire, contexto, instrucciones claras
- Microcopy Ãºtil, accesibilidad visual y botones con intenciÃ³n
- Espaciado limpio, jerarquÃ­a visual y diseÃ±o sin fricciÃ³n

---

ğŸ“¤ **El Agente IA devuelve:**

- ğŸ”— Link del bloque en Vercel (con estilo aplicado)
- ğŸ“˜ **Breve explicaciÃ³n de decisiones visuales tomadas**, por ejemplo:
    
    > â€œSe aplicÃ³ estilo tarjeta al campo Roca.
    > 
    > 
    > BotÃ³n actualizado con lenguaje humano.
    > 
    > Espaciado ajustado para legibilidad entre secciones.â€
    > 

---

âœ… **El Designer puede responder con:**

1. **â€œAceptadoâ€**
    
    â†’ El bloque queda **preparado para presentaciÃ³n externa**
    
    â†’ Se avanza al siguiente bloque
    
2. **â€œAjustes menoresâ€**
    
    â†’ El Agente los aplica y vuelve a mostrar el bloque
    
    â†’ El ciclo se repite hasta aceptaciÃ³n
    
3. **â€œRechazadoâ€**
    
    â†’ El Agente pide explicaciÃ³n breve y propone nueva soluciÃ³n
    
    â†’ Si no se resuelve, el bloque puede marcarse como â€œen pausaâ€ para revisiÃ³n posterior
    

---

ğŸ“Œ **Este paso no cierra el bloque para siempre.**

Solo lo deja en estado **â€œListo para validaciÃ³n externaâ€**, sea por usuario o Consejo.

La trazabilidad definitiva ocurre despuÃ©s de esa instancia.

### 4.2.4.6ğŸ”¹ **Paso 5 â€“ ValidaciÃ³n integral del prototipo con usuarios clave, Researcher y Product Manager**

ğŸ§  **Lugar:** Espacio compartido (videollamada + Vercel)

ğŸ¯ **Objetivo:** Presentar el **Desk completo** a usuarios reales, al Researcher y al Product Manager, observar su experiencia de principio a fin, y dejar trazadas todas las **deudas tÃ©cnicas, funcionales o de experiencia** que emerjan antes del Consejo.

### ğŸ‘¥ Participantes recomendados:

- ğŸ§‘â€ğŸ’¼ Usuarios reales que ejecutan esta Big Task.
- ğŸ” Researcher del flujo.
- ğŸ§­ Product Manager del servicio.
- ğŸ¨ Designer como facilitador

---

### ğŸ–¥ï¸ DinÃ¡mica sugerida para la sesiÃ³n:

ğŸ“Œ **Deuda tÃ©cnica**

Esta secciÃ³n queda pendiente para ser desarrollada por el prÃ³ximo curador de la Biblia.

Debe definir con claridad el formato, las preguntas detonadoras y las herramientas colaborativas que se usarÃ¡n para facilitar la conversaciÃ³n y documentar la validaciÃ³n del prototipo completo.

---

ğŸ““ **Lo que sÃ­ debe ocurrir al menos:**

- El prototipo completo se recorre en conjunto.
- Se escuchan reacciones, dudas y observaciones.
- Se anota en el chat del agente todo lo relevante, por bloque.

ğŸ’¬ *Ejemplo de trazado:*

> â€œUsuario no entendiÃ³ cuÃ¡ndo usar â€˜Documento complementarioâ€™ â†’ posible fusiÃ³n con otro bloque.â€
> 
> 
> â€œProduct Manager indica que falta lÃ³gica de integraciÃ³n con plataforma X â†’ deuda tÃ©cnica anotada.â€
> 
> â€œResearcher propone eliminar paso 6: ya no ocurre en la prÃ¡ctica.â€
> 

---

ğŸ“Œ **Resultado del Paso 5:**

- ValidaciÃ³n real del Desk completo.
- Comentarios de usuarios y expertos operativos.
- Deudas trazadas por tipo: UX, funcional, tÃ©cnica.
- Desk queda listo para presentaciÃ³n estratÃ©gica ante el Consejo.

---

## **4.2.5 ğŸ§™â€â™‚ï¸Consejo del Servicio**

ğŸ¯ *DiagnÃ³stico tÃ¡ctico para hacer mÃ¡s eficiente y efectivo cada paso operativo*

---

### ğŸ§­ Objetivo del paso

Revisar el **Desk completo**, paso por paso, con el Consejo del servicio y los equipos tÃ¡cticos, para **mejorar la ejecuciÃ³n futura** de cada acciÃ³n mediante automatizaciÃ³n, formaciÃ³n o soporte.

ğŸ“Œ **No se discute el diseÃ±o del Desk ni el orden de los pasos.**

Todo lo mostrado ya fue validado operativamente.

El Ãºnico foco es:

> â€œÂ¿CÃ³mo ejecutamos este paso de la mejor forma posible?â€
> 

---

### ğŸ‘¥ Participantes

- ğŸ§  **Researcher**: presenta los pasos operativos (flujo levantado)
- ğŸ§‘â€ğŸ¨ **Legal Designer**: muestra cÃ³mo se tradujeron en Vercel
- ğŸ§­ **Product Manager**: toma nota de deuda, decisiones y prÃ³ximos pasos
- âš™ï¸ **TI**: analiza posibles automatizaciones
- ğŸ§‘â€ğŸ« **Personas**: identifica oportunidades de formaciÃ³n, acompaÃ±amiento o documentaciÃ³n
- ğŸ§© **Miembros del Consejo del Servicio**

---

### ğŸ§ƒ Estructura de la sesiÃ³n

1. **PresentaciÃ³n del flujo (Researcher)**
    - Se muestran los pasos levantados, sin abrir a discusiÃ³n.
    - Cada paso viene **etiquetado como**:
        - ğŸª¨ **Roca** (estructurable, automatizable)
        - ğŸŒ¬ï¸ **Viento** (requiere criterio)
        - ğŸŒ€ **Mixto** (elementos de ambos)
2. **Recorrido rÃ¡pido del Desk en Vercel (Designer)**
    - Solo para visualizar cÃ³mo cada paso se traduce en interfaz.
    - No se edita ni rediseÃ±a.
3. **Receso de 5 minutos**
    - Espacio para preparar ideas y pensar con foco.
4. **DiagnÃ³stico paso por paso (moderado por Designer)**
    - Se discute cÃ³mo hacer **mÃ¡s eficiente** cada paso (automatizaciÃ³n, simplificaciÃ³n)
    - Y cÃ³mo hacerlo **mÃ¡s efectivo** (formaciÃ³n, acompaÃ±amiento, claridad)
    - Se anotan propuestas, recursos necesarios y responsables

---

### ğŸ““ Resultado esperado

- Se identifican acciones para mejorar la ejecuciÃ³n de cada paso:
    - Automatizar (TI)
    - Formar o acompaÃ±ar (Personas)
    - Redefinir lÃ³gica operativa (Producto)
    - Trazar deuda pendiente (si no se puede resolver aÃºn)
- El Product Manager deja todo documentado y prepara la priorizaciÃ³n para la etapa siguiente (4.2.6)

---

### ğŸ§¾ Notas metodolÃ³gicas

- Esta sesiÃ³n **no evalÃºa el diseÃ±o visual ni el orden de los pasos.**
- Las preguntas clave no son â€œÂ¿Esto estÃ¡ bien diseÃ±ado?â€, sino:
    
    > â€œÂ¿QuÃ© necesitamos para que este paso no falle?â€
    > 
    > 
    > â€œÂ¿QuÃ© harÃ­a este paso mÃ¡s simple, rÃ¡pido o claro para quien lo ejecuta?â€
    > 
- El protagonismo tÃ¡ctico se activa:
    - **TI automatiza**
    - **Personas forma o acompaÃ±a**
    - **Producto anota deuda o prioriza soluciones**

---

---

### **4.2.6 ğŸƒ Notas metodolÃ³gicas**

---

### **4.2.7 ğŸ” Paso a paso posterior al Kickoff**

### **4.2.6.1 ğŸ“¥ RevisiÃ³n manual y marcaje del flujo**

### **4.2.6.2 ğŸ“¤ Carga inicial al agente IA Researcher**

### **4.2.6.3 ğŸ¤– AnÃ¡lisis inicial del agente IA**

### **4.2.6.4 âœ… ValidaciÃ³n guiada por parte del Researcher**

### **4.2.6.5 ğŸ“˜ DiagnÃ³stico de aprendizaje emergente**

### **4.2.6.6 ğŸ“ GeneraciÃ³n del informe modular**

### **4.2.6.7 ğŸ“š Carga final al repositorio y la Biblia del Servicio**

---

## 4.3 3ï¸âƒ£**ğŸ§©** MÃ³dulo Recordatorios Inteligentes

**(PreparaciÃ³n de Trinity: Biblia + Protocolo + Dataset por etapa)**

---

### 4.3.1 ğŸ”§ Â¿QuÃ© sÃ­ntoma activa este mÃ³dulo?

Una etapa del servicio tiene comunicaciones poco claras, fricciones frecuentes o baja tasa de cumplimiento ante tareas solicitadas.

AdemÃ¡s, no existe una estructura vectorizable de interacciones, excusas ni respuestas.

---

### 4.3.2 ğŸ¯ Resultado esperado

- ğŸ“˜ Una **Biblia Trinity por etapa**, con:
    - Interacciones informativas + plantillas + consultas frecuentes
    - Interacciones colaborativas + excusas + protocolos adaptativos
- ğŸ“‚ Estructura de campos base para la **BBDD Trinity por cliente**
- ğŸ§  Reglas de respuesta IA segÃºn tipo de interacciÃ³n, canal y comportamiento del cliente
- ğŸ“ Insumos trazables para diseÃ±o posterior del Desk Trinity

---

### 4.3.3 ğŸ›  DinÃ¡mica del mÃ³dulo

| Fase | AcciÃ³n |
| --- | --- |
| ğŸŒŸ ExploraciÃ³n | RevisiÃ³n de correos reales, mensajes, fricciones, feedbacks |
| ğŸ”§ GeneraciÃ³n del tablero | Mapeo de interacciones (colaborativas / informativas) |
| ğŸƒ FacilitaciÃ³n | DiscusiÃ³n con CX o legales para tipificar excusas y validar protocolos |
| ğŸ§¾ CuradurÃ­a | RedacciÃ³n de la Biblia CX por etapa |
| ğŸ“Œ Registro | Guardado vectorial para IA y activaciÃ³n de tickets de diseÃ±o |

---

### 4.3.4 ğŸ“ Trazabilidad final

- ğŸ§© Tabla o visual curado por etapa
- âœ… Plantillas validadas
- ğŸ§  Reglas por excusa
- ğŸ“‚ Campos propuestos para dataset por cliente
- ğŸ”— Enlace a la fase de diseÃ±o (Desk Trinity)

---

### 4.3.XğŸ§© ImplementaciÃ³n tÃ©cnica posterior a la Biblia (para desarrollo)

Una vez construida y validada la **Biblia CX de la etapa**, el equipo de desarrollo debe implementar la infraestructura que permita que la IA:

---

### âš™ï¸ 1. Proponga borradores de correo

- Basados en las plantillas curadas por etapa y tipo de interacciÃ³n.
- Personalizados segÃºn la metadata del cliente (estado, excusa, canal, historial).
- Integrados con Gmail o herramientas externas mediante **Google Apps Script** si aplica.

---

### ğŸ’¬ 2. Gestione conversaciones en WhatsApp a travÃ©s de Vambe

- La IA debe poder:
    - Leer y comprender el historial conversacional del cliente.
    - Proponer la prÃ³xima respuesta (modo supervisado).
    - Enviar directamente (modo autÃ³nomo, si estÃ¡ autorizado).
    - Registrar automÃ¡ticamente: excusa detectada, tiempo de respuesta, resultado de la interacciÃ³n.

### 4.3.X ğŸ¤– Proyecto Trinity â€“ IA Omnicanal de Experiencia Cliente

**DuraciÃ³n estimada:** 2 meses

### ğŸ¯ Objetivo Final

Desarrollar un sistema de **interfaz Humanoâ€“IA** que gestione todas las comunicaciones con clientes en Lexy â€”por **correo, WhatsApp, Meta (Messenger/Instagram)** y otros canales futurosâ€” con criterios de supervisiÃ³n, aprendizaje continuo y trazabilidad.

Este sistema no es solo una IA que responde automÃ¡ticamente, sino una **plataforma de conversaciÃ³n viva** donde:

- La IA **propone mensajes** segÃºn el contexto, el canal y el historial del cliente.
- Los humanos **supervisan, editan o aprueban** cuando es necesario.
- El sistema **aprende de las excusas, respuestas y resultados**, mejorando su criterio con cada interacciÃ³n.
- Se establece una **base de datos por cliente** que permite personalizar cada mensaje y registrar decisiones clave.
- La experiencia conversacional es **orquestada desde una interfaz Ãºnica (Trinity Desk)**, que integra todos los canales y niveles de autonomÃ­a IA.

En resumen, **Trinity es la interfaz donde vive, evoluciona y se curan todas las conversaciones con clientes en Lexy.**

---

## ğŸ§  Fundamento del Proyecto

El proyecto **Trinity** se basa en cuatro componentes conectados que permiten diseÃ±ar, entrenar y operar una IA que gestiona las interacciones con clientes, con criterio humano, trazabilidad y aprendizaje continuo.

### ğŸ”© Componentes estructurales

1. **ğŸ“˜ Biblia CX por servicio**
    
    Define todas las interacciones con clientes, sus plantillas, excusas frecuentes y protocolos.
    
    EstÃ¡n **agrupadas por etapa** del servicio y sirven como referencia principal para el entrenamiento y operaciÃ³n de Trinity.
    
2. **ğŸ§  Agente IA de Research CX**
    
    Asiste a los Researchers en la construcciÃ³n estructurada de las Biblias CX, recopilando interacciones reales, clasificando excusas y proponiendo protocolos.
    
3. **ğŸ“‚ Base de datos por cliente (BBDD Trinity)**
    
    Registra el historial de conversaciÃ³n, excusas, respuestas, etapa y nivel de autonomÃ­a de IA por cliente.
    
4. **ğŸ–¥ Trinity â€“ Desk Omnichannel**
    
    Interfaz tipo Kanban donde se supervisan, editan, entrenan y escalan todas las comunicaciones con clientes, desde el modo IA supervisada hasta su operaciÃ³n autÃ³noma.
    

---

## ğŸŸ¢ Fases de implementaciÃ³n

| Fase | AcciÃ³n |
| --- | --- |
| 1ï¸âƒ£ | Construir la **Biblia CX por servicio** con el apoyo del **Agente IA de Research CX**. |
| 2ï¸âƒ£ | Levantar la **BBDD por cliente**, conectada al CRM y al historial de interacciones. |
| 3ï¸âƒ£ | Activar el **Desk Trinity â€“ Omnichannel** como espacio de supervisiÃ³n, entrenamiento y operaciÃ³n. |

---

## ğŸ“˜ Componente 1: Biblia CX por Servicio

Organizada por etapa, incluye dos grandes tipos de interacciÃ³n:

---

### ğŸ§© A. Interacciones Informativas

> El cliente no debe hacer nada, solo entender lo que se le comunica.
> 

| Campo | Contenido |
| --- | --- |
| ğŸ’¬ Plantilla de mensaje | Correo / WhatsApp |
| ğŸ§­ Evento que lo detona | Cambio de etapa, resoluciÃ³n, ingreso |
| â“ Consultas frecuentes | Preguntas tÃ­picas y respuestas sugeridas |
| ğŸ›  Protocolo de respuesta | Â¿Responde IA? Â¿Escala a humano? |
| ğŸš¨ Umbral de fricciÃ³n | CuÃ¡ndo se desactiva la IA |

---

### ğŸ§© B. Interacciones Colaborativas

> El cliente debe realizar una acciÃ³n concreta para que el caso avance.
> 

### 1. DefiniciÃ³n de la interacciÃ³n

| Campo | Contenido |
| --- | --- |
| ğŸ“¥ Input requerido | Ficha, documento, firma, etc. |
| ğŸ“¬ Plantilla inicial |  |
| Canal | Por correo y whatsapp |
| â° Deadline  | Tiempo antes de dar de baja al cliente |
| ğŸ” Secuencia de recordatorios | Frecuencia y duraciÃ³n mÃ¡xima |
| ğŸ¯ PropÃ³sito operativo | QuÃ© permite avanzar o resolver |
| ğŸ§‘â€âš–ï¸ Escalamiento a humano | Â¿Cuando? |

---

### 2. Excusas frecuentes + Protocolo asociado

| Campo | Contenido |
| --- | --- |
| ğŸ’¬ Excusa textual | Lo que dice el cliente |
| ğŸ—‚ CategorÃ­a | Salud, tiempo, frustraciÃ³n, tÃ©cnica, emocional |
| ğŸ“¬ Plantilla  |  |
| â° Nuevo Deadline  |  |
| ğŸ” Nueva Secuencia de recordatorios | Â¿SÃ­/No? Â¿CuÃ¡ntos dÃ­as? |
| ğŸ§  AdaptaciÃ³n del tono | Cambio de tono o contenido |
| ğŸ§‘â€âš–ï¸ Escalamiento a humano | Â¿Cuando? |
| Canal | Por el cual el cliente envio su ultima comunicaciÃ³n |

---

## ğŸ§  Componente 2: Agente IA de Research CX

### ğŸ¯ FunciÃ³n

Guiar a los Researchers CX para estructurar las interacciones en cada etapa y servicio.

| AcciÃ³n | Resultado |
| --- | --- |
| Detectar interacciones clave | Informativas y colaborativas |
| Recoger mensajes reales | Desde CRM, WhatsApp, Email |
| Clasificar excusas | Categorizar y agrupar |
| Definir protocolos | De pausa, adaptaciÃ³n o escalamiento |
| Proponer plantillas | Segmentadas por canal y tono |
| Identificar fricciones | Mejorar la Biblia |

---

## ğŸ“‚ Componente 3: Base de Datos por Cliente (BBDD Trinity)

### ğŸ¯ PropÃ³sito

Alimentar a la IA con contexto real y actualizado por cliente.

| Campo | DescripciÃ³n |
| --- | --- |
| ğŸ“Œ ID y etapa actual | Vinculado a CRM |
| ğŸ’¬ Historial de mensajes | Correo y WhatsApp |
| ğŸ˜– Excusas registradas | Texto y categorÃ­a |
| ğŸ¤– Nivel de autonomÃ­a IA | Supervisada / Parcial / Total |
| Otros |  |

---

## ğŸ–¥ Componente 4: Trinity â€“ Desk Omnichannel

### ğŸ¯ PropÃ³sito

Gestionar la operaciÃ³n y evoluciÃ³n del sistema conversacional IA.

Supervisa, entrena, y permite escalar las respuestas de Trinity.

---

### ğŸ“Œ Vista principal: tablero Kanban

| Columna | FunciÃ³n |
| --- | --- |
| ğŸ§‘ SupervisiÃ³n Humana | IA propone â†’ humano valida |
| ğŸ¤– AutonomÃ­a Parcial | IA responde â†’ humano observa |
| âš  FricciÃ³n Detectada | Feedback negativo / NPS bajo / ticket |
| âœ… IA Autorizada | IA responde sola, revisiÃ³n por muestra |

---

### ğŸ“‚ Detalle de tarjeta (cliente)

- Historial completo de conversaciÃ³n (correo + WhatsApp)
- Propuesta IA editable
- Feedback estilo ChatGPT (â€œfrÃ­oâ€, â€œconfusoâ€, â€œrepetidoâ€)
- BotÃ³n "Asignar excusa" â†’ conecta con protocolo en la Biblia CX
- Acceso directo a la ficha del cliente en la BBDD Trinity

---

## ğŸ“ˆ Ciclo de Escalamiento de AutonomÃ­a IA

| Fase | DescripciÃ³n |
| --- | --- |
| 1ï¸âƒ£ SupervisiÃ³n total | IA propone, humano valida |
| 2ï¸âƒ£ SupervisiÃ³n parcial | IA responde, humano observa |
| 3ï¸âƒ£ AutonomÃ­a total | IA responde sola |
| 4ï¸âƒ£ RevisiÃ³n por fricciÃ³n | Si hay error, vuelve a supervisiÃ³n |

---

# 5. ğŸ“š Memoria Curada de los MÃ³dulos

## **5.1 Contexto y propÃ³sito**

La Memoria Curada por MÃ³dulo es el sistema que usamos para dejar registro de cada mÃ³dulo cerrado, no solo como un informe tÃ©cnico, sino como una fuente Ãºtil, reflexiva y vectorizable. Esta memoria permite:

- Revisar cÃ³mo se aplicÃ³ la metodologÃ­a en distintos contextos.
- Detectar patrones repetidos entre etapas o servicios.
- Documentar ajustes metodolÃ³gicos para futuras referencias.
- Entrenar al asistente IA con experiencias comparables y reales.
- Entregar insumos al design o product owner para la elaboraciÃ³n de maquetas o prototipos.

No reemplaza al Journey ni al informe final. Su valor estÃ¡ en dejar huella del proceso vivido: quÃ© se intentÃ³, quÃ© funcionÃ³, quÃ© se adaptÃ³ y quÃ© se aprendiÃ³. La memoria es una herramienta tÃ¡ctica para construir una cultura de diseÃ±o reflexiva, trazable y compartida.

---

## **5.2 Â¿QuÃ© se registra?**

Por cada mÃ³dulo cerrado, se completa una ficha estructurada con:

- Contexto de la etapa
- SÃ­ntoma que justificÃ³ el mÃ³dulo
- Aprendizajes por fase (exploraciÃ³n, tablero, facilitaciÃ³n)
- Enlaces al Journey y al informe
- Un resumen vectorizable que permite que la IA sugiera comparables

---

## **5.3 Â¿Para quÃ© sirve?**

- Detectar patrones funcionales entre etapas de distintos servicios
- Comparar cÃ³mo se han resuelto sÃ­ntomas similares en otros contextos
- Documentar decisiones metodolÃ³gicas que funcionaron (o no)
- Entrenar al asistente IA para ofrecer referencias Ãºtiles y precisas

---

## **5.4 Columnas de la Base de Datos para la trazabilidad semÃ¡ntica y comparativa**

### 5.4.1 ğŸ“‚ Datos generales (contexto base)

**Etapa** *(texto)*

> Permite identificar en quÃ© punto del proceso se aplicÃ³ el mÃ³dulo.
> 
> 
> Ayuda a comparar entre etapas equivalentes o con similar funciÃ³n operativa.
> 

**Servicio** *(selecciÃ³n)*

> Ubica el informe en un universo operativo (Salud, Litigios, RenegociaciÃ³n, etc.)
> 
> 
> Es Ãºtil para buscar comparables dentro del mismo servicio o para detectar diferencias entre servicios.
> 

**DescripciÃ³n breve de la etapa** *(texto corto)*

> Condensa quÃ© ocurre realmente en la etapa, mÃ¡s allÃ¡ de su nombre.
> 
> 
> Este campo es clave para que la IA encuentre similitudes funcionales aunque la etapa tenga otro nombre.
> 

**Fecha de cierre** *(fecha)*

> Permite organizar cronolÃ³gicamente los mÃ³dulos y ver evoluciÃ³n de criterios.
> 
> 
> TambiÃ©n ayuda a comparar versiones antiguas vs. actuales.
> 

**Researcher responsable** *(texto)*

> Ubica la autorÃ­a y estilo de ejecuciÃ³n.
> 
> 
> Puede ayudar a detectar estilos personales o aprendizajes repetidos entre Researcher.
> 

**SÃ­ntoma que activÃ³ el mÃ³dulo** *(texto largo)*

> Es la huella mÃ¡s importante para comparar casos.
> 
> 
> Muestra el dolor real que llevÃ³ a activar el mÃ³dulo, lo que permite agrupar por problemas comunes.
> 

---

### 5.4.2 ğŸ§  Aprendizaje por fase (base para comprensiÃ³n metodolÃ³gica)

**Aprendizaje en la exploraciÃ³n** *(texto medio)*

> Deja registro de lo que se detectÃ³ en terreno.
> 
> 
> Clave para saber cÃ³mo se observan las tareas de los usuarios.  
> 

**Ajustes realizados al tablero y por quÃ©** *(texto medio)*

> Muestra quÃ© se adaptÃ³ al Journey base.
> 
> 
> Ãštil para ver quÃ© estructuras resisten cambios y cuÃ¡les se modifican segÃºn la etapa.
> 

**Aprendizaje en la facilitaciÃ³n del Kickoff** *(texto medio)*

> Refleja la calidad del cierre con el equipo.
> 
> 
> Detecta si hubo participaciÃ³n real, validaciÃ³n efectiva o barreras metodolÃ³gicas.
> 

---

### 5.4.3ğŸ“ Enlaces y cierre (referenciabilidad)

**Link al informe completo (PDF/Markdown)** *(enlace)*

> DocumentaciÃ³n integral de todo el proceso.
> 
> 
> Clave para trazabilidad documental, formaciÃ³n de nuevos Researcher y lectura curatorial.
> 

**Â¿Fue cargado en la Biblia del Servicio?** *(checkbox)*

> Marca si ese caso estÃ¡ disponible como ejemplo dentro del sistema de conocimiento.
> 
> 
> Ayuda a mantener actualizada la curadurÃ­a.
> 

---

### 5.4.4ğŸ§  CURADORâ€“ Para trazabilidad vectorial

1. **Resumen vectorizable (IA only)** *(texto oculto o tÃ©cnico)*

> Texto estructurado y sintÃ©tico que condensa la naturaleza funcional de la etapa, sÃ­ntomas, estructura del Journey y ajustes.
> 
> 
> Permite a la IA comparar etapas aunque tengan distinto nombre, servicio o Journey.
> 
> Ejemplo:
> 
> `Etapa sin decisiones humanas. Trigger principal: cliente envÃ­a ficha. SÃ­ntoma: no hay reacciÃ³n clara posterior. Journey simplificado. Comparable a Onboarding de RenegociaciÃ³n.`
> 

---

## 5.5 Base de Datos

[Informes por Modulos - Research](%F0%9F%93%97%20%F0%9F%94%8E%20Biblia%20Research%20Core%20v%202%205%201fa2f9107409803890def9c4bb9bc362/Informes%20por%20Modulos%20-%20Research%201fc2f9107409801291c5f4eac18214bf.csv)

---