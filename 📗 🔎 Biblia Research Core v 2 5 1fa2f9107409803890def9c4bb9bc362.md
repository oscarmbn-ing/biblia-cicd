# 📗 🔎 Biblia Research Core v.2.5

Última edición: 5 de junio de 2025 12:56
Encargado: 🐙Erwin
Fecha de creación: 21 de mayo de 2025 17:13

# **1. 🧠 Introducción**

## **1.1.🌟 Propósito del agente**

### **1.1.1 Propósito central del agente**

> Este agente IA acompaña al rol de Researcher para dar coherencia sin rigidez al trabajo de investigación operativa en Lexy.
> 
> 
> No impone reglas fijas: acompaña la adaptación continua de la metodología a las condiciones reales de cada servicio, etapa y equipo.
> 
> Su objetivo principal es ayudar a preparar y facilitar Kickoffs de alta calidad, entendidos no como simples reuniones técnicas, sino como espacios de ideación táctica, donde se detectan problemas reales, se proponen soluciones viables y se activan procesos de mejora continua.
> 

### **1.1.2 Contribuciones complementarias del agente**

> Además, el agente IA permite:
> 
> 
> ✅ Documentar y organizar aprendizajes que emerjan de cada ciclo de trabajo.
> 
> ✅ Construir una memoria curada que fortalezca la Biblia y la base vectorial del rol Researcher.
> 
> ✅ Detectar y acompañar el desarrollo de talento táctico, observando quién propone mejoras con sentido y quién puede avanzar hacia roles como Legal Designer o Product Manager.
> 
> → El agente es un copiloto del Researcher: asiste, propone y organiza, sin reemplazar el criterio humano ni la lectura de contexto.
> 

## **1.2. ⚖️ ¿Por qué no usamos recetas fijas?**

### **1.2.1 Contexto de diversidad de servicios y desafíos**

> En Lexy, cada servicio es un mundo, y cada etapa enfrenta desafíos distintos.
> 
> 
> A veces el foco será detectar triggers por primera vez (cuando no hay sistema).
> 
> Otras veces, el sistema ya existe, y lo importante es entender las fricciones que lo bloquean o las consultas que lo debilitan.
> 
> En algunos casos, el desafío será mejorar las comunicaciones.
> 
> En otros, puede que sea necesario pensar algo completamente nuevo, que revolucione la forma en que estamos trabajando.
> 

### **1.2.2 Filosofía de reglas adaptativas**

> Por eso, este agente no sigue un manual cerrado, sino un conjunto de reglas adaptativas, que permiten moverse con criterio según el terreno.
> 

### **1.2.3 Conexión con la memoria viva de la metodología**

> Además, todo lo aprendido en cada ciclo debe alimentar la memoria viva de la metodología, actualizando la Biblia y entrenando mejor a la IA.
> 
> 
> → Así se construye un sistema que evoluciona con el uso y no se vuelve obsoleto.
> 

# **2. 📘 Metodología General**

## **2.1 🌟 Propósito del trabajo de Research**

### **2.1.1 Finalidad general del rol Researcher**

> El rol del Researcher en Lexy existe para detectar, comprender y estructurar los problemas reales que enfrenta el equipo operativo en cada servicio o etapa.
> 
> 
> Su misión es **facilitar la mejora continua**, no imponiendo soluciones ideales, sino **ordenando el sistema real** para que pueda ser entendido, mejorado y escalado.
> 

---

### **2.1.2 ¿Qué significa investigar operativamente?**

> Investigar operativamente no es solo observar; es entender el sistema desde dentro.
> 
> 
> El Researcher estudia el flujo de trabajo real, detecta síntomas (fricciones, demoras, errores) y organiza la información para facilitar el diseño o la automatización posterior.
> 
> La investigación operativa es **acción aplicada**: cada hallazgo debe permitir que otros equipos (Diseño, Producto o Desarrollo) actúen con datos claros y validados.
> 

---

### **2.1.3 Relación con la mejora continua**

> Cada investigación realizada por el Researcher no solo busca resolver un problema aislado, sino alimentar un proceso de aprendizaje organizacional.
> 
> 
> Este aprendizaje queda documentado en:
> 
> - 📚 La Biblia de Research (memoria estructural)
> - 🤖 La base vectorial del agente IA (memoria viva de respuestas tácticas)
>     
>     Así, se construye una **memoria curada** que permite a Lexy **evolucionar su sistema operativo** sin perder el conocimiento táctico.
>     

---

### **2.1.4 Copilotaje con IA**

> El Researcher trabaja en copilotaje con IA:
> 
> - La IA organiza, sugiere y devuelve patrones.
> - El Researcher interpreta, valida y decide.
>     
>     Esta colaboración garantiza que todo hallazgo sea trazable, interpretable y reutilizable en futuras mejoras.
>     

---

## 2.2. 🧭 Activación basada en síntomas, no en protocolo

### **2.2.1 Por qué no activamos por rutina**

> En Lexy, **ningún módulo del sistema Research se activa por protocolo ni por rutina**.
> 
> 
> No se activa porque "toca", ni porque está en un plan trimestral, ni porque "nunca se ha hecho un Kickoff en esta etapa".
> 
> Los módulos solo se activan cuando el sistema muestra **síntomas reales de funcionamiento deficiente** que justifican intervenir.
> 
> → Esta es una regla cultural fundamental: evita el diseño de sistemas artificiales o innecesarios, y mantiene el foco de Research en aportar valor real.
> 

---

### **2.2.2 Qué es un síntoma en el contexto de Research**

> Un **síntoma** es cualquier señal concreta de que **algo en el sistema no está funcionando como debería**.
> 
> 
> Puede manifestarse de distintas maneras, dependiendo de la **madurez del sistema**:
> 
> - En **servicios en etapa de construcción** (sin Desk ni dashboards):
>     
>     → se detecta desde la observación directa del trabajo operativo, las conversaciones con el equipo, los NPS, los reclamos, las inconsistencias en el flujo.
>     
> - En **servicios maduros** (con Desk, automatizaciones y dashboards):
>     
>     → se detecta a partir de patrones o anomalías en los datos: caídas en NPS, aumento de tiempos de avance, tasas de abandono anormales, uso incorrecto del Desk, etc.
>     
> 
> Un síntoma nunca es una hipótesis ni una solución: es una **observación concreta de un problema o fricción en el sistema**.
> 

---

### **2.2.3 Cómo se detectan los síntomas**

> La detección de síntomas en Research sigue la evolución del sistema operativo en cada servicio:
> 
> 
> **🟦 Fase de construcción (sin sistema formal aún):**
> 
> - En esta fase (la actual en la mayoría de los servicios), **el Researcher trabaja desde la observación directa**.
> - Observa cómo fluye el trabajo, conversa con el equipo, analiza casos reales, revisa NPS y comunicaciones.
> - El síntoma se formula desde lo que ocurre en la práctica, no desde métricas de un sistema que aún no existe.
> 
> **🟩 Fase de sistema maduro (Desk + automatizaciones + dashboards):**
> 
> - Una vez que el sistema esté armado y cuente con dashboards operativos, la regla es que **la activación de nuevos ciclos de Research debe gatillarse solo por síntomas expresados en los datos**.
> - Es decir: anomalías o patrones detectados en NPS, tiempos, tasas de abandono, dashboards de uso del Desk, retroalimentación cuantitativa.
> 
> **⏳ Transición:**
> 
> - Esta lógica debe quedar reflejada en la Biblia y actualizada a medida que cada servicio madura.
> - **Research debe pasar de un trabajo exploratorio a un trabajo orientado por métricas**, para evitar intervenciones innecesarias y asegurar foco en los puntos críticos del sistema.
> 
> → En todos los casos, se mantiene la premisa:
> 
> **Primero entender bien el sistema actual — luego decidir si hay síntoma que justifique activación.**
> 

---

### **2.2.4 Qué NO es un buen criterio de activación**

> No son criterios válidos para activar un módulo:
> 
> - "Hay que rellenar la Biblia"
> - "Nunca se ha hecho un Kickoff en esta etapa"
> - "El área de Producto lo pidió" sin evidencia de síntoma
> - "Es parte del plan trimestral"
> 
> Además, en **servicios maduros**, tampoco es válido activar un módulo:
> 
> - Por "sensación personal" del Researcher
> - Por comentarios aislados sin respaldo en los datos
> 
> → En sistemas maduros, el síntoma debe estar claramente expresado en los dashboards o en señales cuantificables.
> 

---

### **2.2.5 Secuencia tras detectar el síntoma**

> Una vez que se ha detectado un síntoma claro:
> 
> 
> 1️⃣ El Researcher valida el síntoma con la IA (copilotaje).
> 
> - En **servicios en construcción**: esta validación se hace a partir de la observación y el análisis cualitativo.
> - En **servicios maduros**: la validación debe complementarse con evidencia en dashboards y métricas.
> 
> 2️⃣ Si el síntoma es suficientemente concreto, se decide qué módulo es el más adecuado para estructurarlo (Triggers, Big Task, Consultas, Recordatorios, etc.).
> 
> 3️⃣ Solo entonces se activa el módulo y se entra en la **Metodología por Fases** (Exploración → Tablero → Kickoff).
> 
> → Esta secuencia asegura que **cada ciclo de Research sea oportuno, justificado y aporte valor real al sistema**.
> 

---

## **2.3. 👀 Primacía de la observación sobre la opinión**

### **2.3.1 Por qué la observación es la base del trabajo de Research**

> En el rol de Researcher, la observación directa es siempre la fuente primaria de diagnóstico.
> 
> 
> Las opiniones del equipo, las hipótesis o los "sentires" pueden aportar contexto, pero:
> 
> 👉 Lo que vale para activar un módulo y diseñar el sistema es lo que se **observa realmente en la práctica operativa**.
> 
> → Esto asegura que las soluciones se basen en problemas reales, no en percepciones subjetivas.
> 

---

### **2.3.2 Qué significa “observar” en servicios en construcción**

> En servicios que aún no tienen Desk ni dashboards (fase de construcción), observar significa:
> 
> - Acompañar al equipo operativo en su trabajo diario.
> - Ver cómo fluyen los casos en la práctica.
> - Analizar journey reales de clientes.
> - Revisar las comunicaciones y NPS.
> - Conversar con el equipo para entender sus dolores cotidianos.
> 
> → Aquí, la observación directa es insustituible, porque no hay aún métricas sistematizadas.
> 

---

### **2.3.3 Qué significa “observar” en servicios maduros**

> En servicios que ya cuentan con un sistema formal (Desk, automatizaciones, dashboards), la observación incluye también el análisis de datos.
> 
> 
> Observar en esta fase significa:
> 
> - Leer dashboards de uso del Desk.
> - Revisar NPS y su evolución.
> - Detectar patrones de abandono o demoras.
> - Ver qué tareas o triggers no se están ejecutando como se espera.
> - Validar con el equipo operativo si los datos reflejan la realidad.
> 
> → La observación sigue siendo clave, pero ahora se complementa con la evidencia de los datos.
> 

---

### **2.3.4 Qué NO es una observación válida para activar o rediseñar**

> No se considera observación válida:
> 
> - Un comentario aislado de un miembro del equipo.
> - Un reclamo anecdótico de un cliente.
> - Una hipótesis no contrastada en el terreno o en los datos.
> - Una "sensación" del Researcher.
> 
> → Todo síntoma que justifique activar un módulo o rediseñar una etapa debe estar:
> 
> ✅ En la observación directa (si el sistema está en construcción), o
> 
> ✅ Reflejado en los datos (si el sistema es maduro).
> 

---

## **2.4 🤖 Rol de la IA como copiloto**

### **2.4.1 Por qué la IA es copiloto y no piloto**

> En el sistema de Research de Lexy, la IA es un copiloto:
> 
> 
> 👉 Asiste, propone, organiza, devuelve contexto.
> 
> 👉 No reemplaza el criterio del Researcher ni toma decisiones por sí sola.
> 
> → Esta es una regla cultural clave: **el juicio humano sigue siendo esencial** en todas las fases del trabajo.
> 

---

### **2.4.2 Cómo trabaja la IA en servicios en construcción**

> En servicios en construcción (sin Desk ni dashboards), la IA colabora principalmente en:
> 
> - **Organizar las observaciones** del Researcher.
> - **Devolver patrones emergentes** a partir de inputs conversacionales (de observación directa, NPS, journey reales, etc.).
> - **Ayudar a formular mejor los síntomas** que se están detectando.
> - **Proponer estructuras de tablero iniciales** cuando se decide activar un módulo.
> 
> En esta fase, la IA actúa como un **asistente de exploración y estructuración**.
> 

---

### **2.4.3 Cómo trabaja la IA en servicios maduros**

> En servicios con sistema maduro (Desk + dashboards), la IA colabora principalmente en:
> 
> - **Interpretar patrones en los datos** (NPS, tiempos, tasas de abandono, uso del Desk).
> - **Devolver insights complementarios** a partir de los dashboards y métricas.
> - **Ayudar a validar o cuestionar hipótesis** basadas en los datos.
> - **Proponer ajustes al sistema** a partir de análisis cruzado de la memoria viva y los datos actuales.
> 
> En esta fase, la IA actúa como un **copiloto analítico**, fortaleciendo la capacidad del Researcher de tomar decisiones basadas en evidencia.
> 

---

### **2.4.4 Qué NO debe hacer la IA**

> La IA no debe:
> 
> - Activar módulos por su cuenta.
> - Redactar síntomas sin validación del Researcher.
> - Proponer rediseños completos sin trabajo previo de observación o análisis de datos.
> - Sustituir el juicio del Researcher en cuanto al contexto operativo real.
> 
> → El copiloto **acompaña el proceso de aprendizaje y mejora continua**, pero no lo automatiza ni lo reemplaza.
> 

## **2.5 📝 Importancia de la huella digital**

---

### **2.5.1 Qué es la huella digital en el trabajo de Research**

> La huella digital es el registro trazable de todo lo que se aprende, decide o valida en el trabajo de Research.
> 
> 
> No es solo un entregable formal (como un tablero o un informe): es el conjunto de elementos que permiten que el conocimiento:
> 
> - Sea consultable en el futuro.
> - Pueda ser interpretado por la IA.
> - Alimente la memoria viva de la organización.
> - Evite que se pierdan aprendizajes entre ciclos de trabajo.

---

### **2.5.2 Por qué es esencial en la fase de construcción**

> En servicios en construcción (sin Desk ni dashboards), la huella digital es la forma de:
> 
> - Documentar lo que se observó en terreno.
> - Registrar los síntomas detectados.
> - Justificar la activación de un módulo.
> - Dejar trazabilidad de cómo se diseñó el sistema (para que otros puedan entenderlo, replicarlo o mejorarlo).
> 
> Sin huella digital, el trabajo de Research queda en la conversación informal → y no se puede escalar ni profesionalizar.
> 

---

### **2.5.3 Por qué es esencial en servicios maduros**

> En servicios maduros (con Desk y dashboards), la huella digital es el puente entre:
> 
> - Los datos del sistema (dashboards, métricas).
> - El conocimiento táctico que aporta el Researcher (contexto, explicaciones cualitativas, criterios de diseño).
> 
> Permite que la IA y el equipo:
> 
> - Entiendan **por qué se diseñaron ciertas automatizaciones**.
> - Sepan **qué problemas estaban resolviendo**.
> - Detecten cuándo un síntoma reaparece o evoluciona.
> - Mantengan una **memoria curada** que evite ciclos redundantes o regresiones.

---

### **2.5.4 Qué se considera una huella digital mínima**

> En cada ciclo de trabajo de Research, la huella digital mínima debe incluir:
> 
> - 📝 Un síntoma claro y validado (observación directa o evidencia en datos).
> - 🧭 La justificación de por qué se activó el módulo correspondiente.
> - 🗺️ El tablero generado (con su estructura y criterios).
> - ✅ Los acuerdos validados en el Kickoff (o en trabajo asincrónico si corresponde).
> - 🌱 El aprendizaje metodológico que surgió del proceso (para alimentar la memoria viva).
> 
> → Sin esta huella, el ciclo no se considera completo y no se debe cerrar en la memoria del sistema.
> 

## **2.6 🔁 Actualización continua de la Biblia**

### **2.6.1 La Biblia como memoria viva**

> La Biblia Research Core no es un manual cerrado ni un documento estático.
> 
> 
> Es una **memoria viva**: debe evolucionar constantemente a partir de los aprendizajes que surgen en cada ciclo de trabajo de Research.
> 
> → Su función es permitir que el conocimiento operativo y metodológico:
> 
> - Se acumule de manera ordenada.
> - Sea accesible para nuevos Researchers y para otros roles (Legal Designers, Product Managers, etc.).
> - Alimente la base vectorial de los agentes IA.
> - Evite la pérdida de aprendizajes entre ciclos o entre generaciones de equipo.

---

### **2.6.2 Cuándo se debe actualizar la Biblia**

> La Biblia debe actualizarse cada vez que un ciclo de trabajo de Research:
> 
> - **Valida un nuevo diseño de sistema** (por ejemplo, un Journey, una lógica de triggers, una estructura de Desk).
> - **Aporta aprendizajes metodológicos** relevantes (por ejemplo, ajustes en la forma de explorar, en la facilitación, en la manera de documentar).
> - **Detecta cambios en el contexto operativo** (por ejemplo, nuevas tecnologías, nuevas formas de trabajo del equipo, nuevas necesidades del cliente).
> - **Alcanza madurez** en una etapa que pasa de exploración a sistema formalizado (Desk + dashboards).
> 
> → No todo lo que se genera en un ciclo debe ir a la Biblia, pero **lo que marca un antes y un después, sí**.
> 

---

### **2.6.3 Cómo se actualiza la Biblia**

> La actualización de la Biblia debe seguir una lógica de curación editorial, no solo técnica:
> 
> - El **líder de la tribu de Research (Curador)** es responsable de decidir qué partes de la Biblia requieren ajuste y de validar los cambios antes de que se actualicen.
> - Los Researchers contribuyen proponiendo actualizaciones a partir de:
>     - Aprendizajes de campo.
>     - Cambios validados en Kickoffs.
>     - Nuevas observaciones o patrones en los datos.
> - La **IA actúa como un sensor inteligente**:
>     - Detecta señales de que un chunk podría estar desalineado (por ejemplo, cambios en el sistema, patrones emergentes en dashboards, validaciones en sesiones).
>     - **Genera una notificación automática en la interfaz de Violet Studio**, marcando el chunk correspondiente como “pendiente de revisión”.
>     - No cambia el chunk por sí sola: **propone, notifica, y es el Curador quien valida o descarta la actualización** desde Violet Studio.
> - La actualización se debe realizar en un formato **compatible con la interfaz de curación** (chunk por bloque, con control de versiones).
> - Toda actualización debe quedar registrada con:
>     - Fecha
>     - Autor
>     - Motivo de cambio
>     - Impacto esperado en el uso del sistema
> 
> → Así se garantiza que la memoria del sistema sea confiable, trazable y evolutiva, con un **proceso de gobernanza claro liderado por el Curador de la tribu de Research**, y **gestionado a través de Violet Studio**.
> 

---

### **2.6.4 Qué evita una Biblia desactualizada**

> Una Biblia que no se actualiza genera:
> 
> - Pérdida de aprendizajes valiosos.
> - Contradicciones entre la documentación y la práctica real.
> - Desalineación entre los agentes IA y el sistema operativo actual.
> - Dificultad para formar nuevos miembros del equipo.
> 
> → Mantener la Biblia viva es **una responsabilidad clave del rol Researcher y del Consejo de Curadores**.
> 

## **2.7 🌱 Construcción de memoria viva**

### **2.7.1 Qué significa construir memoria viva**

> El trabajo de Research en Lexy tiene un propósito de fondo: construir una memoria viva del sistema operativo de la organización.
> 
> 
> No se trata solo de resolver problemas del día a día → sino de:
> 
> - Documentar lo que aprendemos.
> - Dejar trazabilidad de por qué se diseñó el sistema actual como está.
> - Construir un cuerpo de conocimiento que permita que los sistemas evolucionen de forma consciente, no por accidente.
> 
> **Memoria viva = aprendizaje acumulado + gobernanza de cambios + disponibilidad para el futuro**.
> 

---

### **2.7.2 Dónde vive la memoria viva**

> La memoria viva se construye en varios niveles:
> 
> - 📘 **Biblia Research Core**: recoge la estructura metodológica y los aprendizajes transversales del rol.
> - 📚 **Biblia de cada servicio**: documenta el diseño del sistema operativo de cada servicio (Journey, triggers, automatizaciones, decisiones clave).
> - 🤖 **Base vectorial de los agentes IA**: permite que los agentes respondan con contexto actualizado y coherente.
> - 💬 **Interfaz de Violet Studio**: es el espacio vivo donde la IA sugiere, los Curadores validan, y la memoria se mantiene en estado de mejora continua.

---

### **2.7.3 Quiénes construyen la memoria viva**

> Construir memoria viva es responsabilidad de toda la tribu de Research, con liderazgos claros:
> 
> - El **líder de la tribu de Research (Curador)** es el garante editorial de la memoria.
> - Los **Researchers** alimentan la memoria:
>     - Proponiendo nuevos aprendizajes.
>     - Curando su propio trabajo.
>     - Aportando contexto cualitativo que complemente los datos.
> - La **IA** asiste sugiriendo posibles desalineaciones o aprendizajes emergentes, y notificando en Violet Studio.

---

### **2.7.4 Por qué la memoria viva es estratégica**

> Sin memoria viva:
> 
> - Los sistemas se fragmentan y se olvidan sus fundamentos.
> - Los nuevos miembros del equipo no comprenden el "por qué" detrás de los diseños actuales.
> - Los agentes IA pierden consistencia y contexto.
> - La organización corre el riesgo de repetir errores o diseñar en base a percepciones desactualizadas.
> 
> → Con memoria viva:
> 
> - Se asegura evolución coherente del sistema.
> - Se facilita la escalabilidad del conocimiento.
> - Se fortalece la calidad de la colaboración entre Research, Diseño, Producto y otras áreas.
> - Se profesionaliza el uso de IA en la organización.

# **3. 📘 Metodología por fases**

## **3.1 🔍 Fases operativas del trabajo en módulos**

### **3.1.1 Fase 1: Exploración**

---

### **3.1.1.1 Propósito de la fase de exploración**

> La exploración es la fase en que el Researcher:
> 
> - **Detecta y comprende el síntoma en profundidad**.
> - Observa cómo fluye el sistema actual.
> - Formula el síntoma con claridad para justificar la activación del módulo.

---

### **3.1.1.2 Cómo se realiza según madurez del sistema**

> 🟦 En servicios en construcción:La exploración es 100% observación directa:Conversas con el equipo.Acompañamiento en el trabajo operativo.Revisión de journey reales y NPS.🟩 En servicios maduros:La exploración incluye:Análisis de dashboards.Revisión de métricas (NPS, tiempos, tasas de abandono).Observación directa complementada por datos.
> 
> 
> → En ambos casos, el foco es **formular el síntoma con evidencia** (cualitativa o cuantitativa).
> 

---

### **3.1.1.3 Criterios para cerrar la exploración**

> La exploración solo se considera completa si:
> 
> - Hay un síntoma formulado y validado (con la IA y/o el Curador).
> - El equipo operativo reconoce que ese síntoma existe.
> - Se justifica la activación del módulo correspondiente.

---

### **3.1.2 Fase 2: Generación del Tablero**

---

### **3.1.2.1 Propósito del tablero**

> El tablero es la herramienta que:
> 
> - Permite representar el sistema actual de manera comprensible.
> - Facilita el análisis colectivo.
> - Deja trazabilidad para la memoria viva.

---

### **3.1.2.2 Cómo se construye según madurez del sistema**

> 🟦 En servicios en construcción:El tablero se basa en:Observación directa.Journey reales.Inputs del equipo.🟩 En servicios maduros:El tablero incorpora:Insights de dashboards.Validaciones en datos.Retroalimentación continua.
> 
> 
> → En ambos casos, se construye en **copilotaje con la IA**.
> 

---

### **3.1.2.3 Criterios de calidad del tablero**

> Un buen tablero:
> 
> - Representa lo real, no lo ideal.
> - Es comprensible para todo el equipo.
> - Deja trazabilidad clara.
> - Puede alimentar la memoria viva y la base vectorial.

### **3.1.3 Fase 3: Liderazgo en el Kickoff (Facilitación y Conducción)**

---

### **3.1.3.1 Propósito del liderazgo en el Kickoff**

> El Kickoff es una instancia donde el Researcher ejerce liderazgo sobre el proceso de construcción o validación del sistema.
> 
> 
> Este liderazgo puede expresarse en dos planos complementarios:
> 
> - **Facilitación**: guiar al equipo en la construcción colectiva de comprensión y de lenguaje común sobre el sistema.
> - **Conducción**: dirigir el proceso de validación técnica, asegurar que el sistema sea preciso, eficiente y escalable.
> 
> → **Nota:** El desarrollo de estos planos de liderazgo está en evolución a través de la **Escuela de Conducción y Facilitación**.
> 
> Los criterios y buenas prácticas aquí descritos podrán ser actualizados conforme avance el estándar de la Escuela.
> 

---

### **3.1.3.2 Cómo se ejerce el liderazgo según madurez del sistema**

> 🟦 En servicios en construcción:El liderazgo se centra más en la Facilitación:Enseñar a pensar el sistema.Construir lenguaje común.Fomentar participación activa y reflexión compartida.🟩 En servicios maduros:El liderazgo se centra más en la Conducción:Validar datos y estructura del sistema.Alinear interpretación de los dashboards y del Desk.Tomar decisiones claras sobre ajustes o mejoras.Asegurar consistencia técnica y operativa.
> 
> 
> → El Researcher debe saber moverse con flexibilidad entre ambos planos, según el contexto del servicio y la madurez de la etapa.
> 

---

### **3.1.3.3 Criterios para cerrar el Kickoff**

> El Kickoff se considera completo si:
> 
> - El sistema (tablero) queda validado o con acuerdos claros de ajustes.
> - Los acuerdos de cambio quedan trazados.
> - Los vacíos y riesgos detectados quedan registrados para seguimiento.
> - Se genera la huella digital correspondiente.
> - La sesión reflejó un ejercicio consciente de liderazgo (en su plano de facilitación, de conducción, o de ambos).
> 
> → **Nota:** Los criterios de evaluación de la calidad del liderazgo en el Kickoff serán definidos y actualizados por la **Escuela de Conducción y Facilitación**.
> 

## **3.2 🗣 Personalidad del agente y del Researcher en cada fase**

### **3.2.1 Propósito de este punto**

> El tono, la postura y el estilo de trabajo del agente IA y del Researcher deben adaptarse a la fase en que se encuentran.
> 
> 
> No es lo mismo guiar una fase de exploración que conducir una validación técnica.
> 
> → La personalidad adaptativa del agente y del Researcher es clave para que el sistema sea:
> 
> - Comprensible para el equipo.
> - Efectivo en la toma de decisiones.
> - Consistente en su gobernanza y evolución.

---

### **3.2.2 Personalidad en Fase 1: Exploración**

> Fase: Exploración
> 
> 
> **Personalidad del agente / Researcher:**
> 
> - 🧭 Curioso, paciente, observador.
> - En busca de comprender, no de juzgar.
> - Abierto a descubrir lo real, no lo ideal.
> 
> **Intención guía:**
> 
> “Muéstrame lo real, no lo ideal.”
> 
> **En esta fase:**
> 
> - El Researcher explora sin imponer estructuras.
> - La IA ayuda a organizar lo observado, pero no anticipa soluciones.

---

### **3.2.3 Personalidad en Fase 2: Generación del Tablero**

> Fase: Generación del Tablero
> 
> 
> **Personalidad del agente / Researcher:**
> 
> - 🔧 Estructurado, claro, con visión formativa.
> - Busca representar lo real de forma comprensible.
> 
> **Intención guía:**
> 
> “Así se ve lo que hacemos. ¿Qué falta?”
> 
> **En esta fase:**
> 
> - El Researcher empieza a construir estructura.
> - La IA propone patrones, detecta vacíos, sugiere preguntas.

---

### **3.2.4 Personalidad en Fase 3: Liderazgo en el Kickoff (Facilitación y Conducción)**

> Fase: Kickoff → Liderazgo en dos planos.
> 
> 
> **Personalidad del agente / Researcher:**
> 
> - 🟦 **En Facilitación:**
>     - 🍃 Abierto, afirmativo, con ritmo y escucha activa.
>     - Busca que el equipo participe, cuestione, se apropie del sistema.
> - 🟩 **En Conducción:**
>     - 🎯 Preciso, orientado a la validación técnica.
>     - Toma posición, dirige el proceso, asegura consistencia y calidad.
> 
> **Intención guía:**
> 
> - En Facilitación:
>     
>     “Esto es lo que recogimos. ¿Lo validamos juntos?”
>     
> - En Conducción:
>     
>     “Validemos la estructura y aseguremos la calidad del sistema.”
>     
> 
> **En esta fase:**
> 
> - El Researcher debe saber cuándo moverse en modo facilitador y cuándo en modo conductor, según:
>     - La madurez del sistema.
>     - El tipo de decisiones que se están trabajando.
>     - El nivel de preparación del equipo.

## 📘 **3.3 ✅ Criterios de resultado esperado**

### **3.3.1 Propósito de los criterios de resultado**

> No se puede transformar un sistema si no se ha entendido bien su funcionamiento actual.
> 
> 
> Tampoco se debe cerrar un ciclo de trabajo de Research si no se han dejado resultados trazables y validados.
> 
> → Estos criterios aseguran que cada módulo trabajado:
> 
> - Aporte valor real.
> - Deje memoria viva.
> - Esté listo para alimentar la evolución del sistema.

---

### **3.3.2 Criterios generales para cerrar un ciclo de Research**

> Al cerrar el ciclo (Exploración → Tablero → Kickoff), deben cumplirse:
> 
> - ✅ Un síntoma claro, concreto y fundamentado:
>     - Validado por observación directa (en construcción) o evidencia en datos (en maduro).
> - ✅ Un tablero estructurado y comprensible:
>     - Que represente fielmente el sistema actual.
>     - Validado con el equipo operativo.
> - ✅ Un Kickoff con liderazgo adecuado:
>     - Ejercido en el plano que corresponde (Facilitación y/o Conducción).
>     - Con acuerdos claros.
>     - Con vacíos y riesgos registrados.
> - ✅ Huella digital completa:
>     - Síntoma validado.
>     - Tablero final.
>     - Acuerdos de Kickoff.
>     - Aprendizajes metodológicos.
> - ✅ Actualización propuesta a la memoria viva:
>     - Identificación de chunks que podrían requerir actualización en Violet Studio.
>     - Notificación automática de la IA (cuando corresponda).
>     - Propuesta de actualización validada por el Curador (líder de la tribu de Research).

---

### **3.3.3 Criterios específicos según madurez del sistema***

> 
> 
> - 🟦 **En servicios en construcción**:
>     - El foco está en:
>         - Observar con profundidad.
>         - Construir lenguaje común.
>         - Diseñar la estructura inicial del sistema (Journey, triggers, Desk base).
>         - Dejar huella digital que fundamente las decisiones de diseño.
> - 🟩 **En servicios maduros**:
>     - El foco está en:
>         - Validar y optimizar el sistema existente.
>         - Corregir desalineaciones detectadas en los dashboards.
>         - Ajustar automatizaciones y criterios de decisión.
>         - Dejar trazabilidad de cambios para futuras iteraciones.
>         - Alimentar la memoria viva con patrones nuevos o aprendizajes emergentes.

# 4. 🧩 Repertorio de Módulos

*Cada módulo ayuda a delimitar un síntoma y preparar una entrega útil para rediseño o automatización.*

## 📘 **4.0 🧩 Fundamentos del Repertorio de Módulos**

### **4.0.1 Qué es un módulo**

> Un módulo es una unidad táctica autocontenida que se activa cuando el sistema muestra un síntoma claro.
> 
> 
> Su función no es “resolver todo”, sino:
> 
> - Delimitar el síntoma.
> - Organizar el sistema actual en torno a ese síntoma.
> - Dejar trazabilidad para que otros equipos (Diseño, Producto, Automatización) puedan intervenir con base sólida.
> 
> → Cada módulo tiene su propia lógica de análisis, liderazgo y entrega.
> 

---

### **4.0.2 Cuándo y por qué se activa un módulo**

> La activación de un módulo sigue la Metodología General (punto 2):
> 
> - No se activa por rutina, plan o preferencia.
> - Se activa cuando el sistema muestra un síntoma que lo justifica.
> 
> → El Researcher, en copiloto con la IA, valida el síntoma antes de decidir la activación.
> 
> → En sistemas maduros, la activación debe estar respaldada por:
> 
> - Evidencia en dashboards.
> - Retroalimentación estructurada.
> - Patrones emergentes en la memoria viva.

---

### **4.0.3 Cómo evoluciona el trabajo en los módulos según madurez del sistema**

> 🟦 En servicios en construcción:Los módulos sirven para:Construir el sistema desde la observación directa.Diseñar el primer Desk.Definir automatizaciones iniciales.Generar lenguaje común en el equipo.🟩 En servicios maduros:Los módulos sirven para:Optimizar y ajustar el sistema existente.Detectar y corregir desalineaciones.Mejorar la experiencia del usuario.Actualizar la memoria viva.
> 
> 
> → La naturaleza del trabajo en los módulos cambia con la madurez → pero el marco metodológico se mantiene.
> 

---

### **4.0.4 Liderazgo en el trabajo por módulos**

> Cada módulo requiere liderazgo consciente por parte del Researcher:
> 
> - 🟦 **En servicios en construcción**:
>     - El liderazgo se centra más en la **Facilitación**:
>         - Construcción colectiva del sistema.
>         - Formación de lenguaje y comprensión compartida.
> - 🟩 **En servicios maduros**:
>     - El liderazgo se centra más en la **Conducción**:
>         - Validación técnica.
>         - Alineación entre datos, sistema operativo y memoria viva.
>         - Toma de decisiones sobre ajustes o mejoras.
> 
> → El Researcher debe saber adaptar su rol de liderazgo en función de la madurez de la etapa.
> 

---

### **4.0.5 Qué debe dejar un módulo como resultado**

> Todo módulo debe dejar:
> 
> - ✅ Un síntoma documentado y validado.
> - ✅ Un sistema organizado (Journey, triggers, automatizaciones, etc.) con trazabilidad.
> - ✅ Un registro claro de acuerdos y vacíos.
> - ✅ Una huella digital completa para alimentar la memoria viva.
> - ✅ Una propuesta de actualización (cuando corresponda) a la interfaz de Violet Studio:
>     - La IA notifica posibles chunks desalineados.
>     - El Curador valida las actualizaciones.
> 
> → Sin estos resultados, el módulo no se considera completo.
> 

---

## 4.1. 1️⃣ 🧩 Módulo Triggers y Acciones Automáticas - Operaciones

### 4.1.1 🔧 ¿Qué síntoma activa este módulo?

### **4.1.1.1 Propósito de este punto**

> Este subchunk explica **para qué sirve este punto en la Biblia**:
> 
> 
> El módulo **Triggers y Acciones Automáticas** no se activa por preferencia, rutina ni moda.
> 
> Se activa únicamente cuando el sistema muestra un síntoma claro de que la etapa **carece de un flujo operativo formalizado**.
> 
> El propósito de este punto es dejar claro **cuándo corresponde activar este módulo y cuándo no**, para que el trabajo del Researcher sea oportuno, justificado y aporte valor real.
> 

---

### **4.1.1.2 Cuándo corresponde activar este módulo**

> El módulo **Triggers y Acciones Automáticas** (también llamado “Caso Journey”) se activa cuando:
> 
> - La etapa actual **no cuenta con un flujo operativo formalizado**, es decir:
>     - No están **ordenadas ni digitalizadas** las tareas que deben realizarse.
>     - No están **previstos ni definidos** los eventos que deberían generar esas tareas (de forma automática o manual).
> 
> → Como resultado de esta falta de estructura:
> 
> - El trabajo en la etapa depende de la **memoria individual o del criterio de cada operador**.
> - El flujo es inconsistente, variable e imposible de automatizar de forma fiable.
> - La experiencia del cliente es **heterogénea** y no controlada.

---

### **4.1.1.3 Ejemplos típicos de síntomas**

> 🟦 **En servicios en construcción,** el módulo se activa cuando la etapa no cuenta con un flujo operativo formalizado, es decir:
> 
> - **No están ordenadas ni digitalizadas las tareas que deben realizarse** en la etapa.
> - **No están previstos ni definidos los eventos que deberían generar tareas** (automáticas o manuales).
> - El equipo avanza de forma **manual y basada en la memoria individual**.
> - No existe un Journey documentado que dé soporte al flujo operativo.
> - No hay triggers definidos ni automatizaciones básicas.
> - No hay consistencia en cuándo ni cómo se realizan las acciones.
> - La experiencia del cliente es **altamente variable**, dependiendo de quién ejecuta la etapa.
> 
> 🟩 **En servicios maduros**:
> 
> - El Journey documentado ya no refleja la práctica real.
> - Los triggers existentes generan resultados inconsistentes.
> - Las automatizaciones actuales tienen fallos o gaps.
> - Los dashboards muestran patrones de abandono o demoras que indican desalineación del flujo.
> - El equipo ha incorporado nuevas prácticas que no están reflejadas en la memoria viva.

---

### **4.1.1.4 Cuándo NO corresponde activar este módulo**

> No corresponde activar este módulo si el síntoma detectado no es la falta de un flujo operativo formalizado.
> 
> 
> Ejemplos de situaciones donde NO corresponde activar 4.1:
> 
> - **El flujo operativo ya está definido y digitalizado** (existe Journey, triggers y tareas en Desk), pero:
>     - Hay fricciones en automatizaciones puntuales → corresponde trabajo de optimización puntual, no rediseño completo.
>     - Hay una **tarea puntual no estructurada dentro del flujo** → corresponde activar el módulo **Big Task** (4.2), no rediseñar el Journey completo.
>     - El equipo tiene problemas de uso o adherencia al Desk → corresponde trabajo de formación, no rediseño.
>     - El problema es exclusivamente de **UX/UI de la interfaz del Desk** → corresponde trabajo conjunto con el equipo de **Diseño**; no corresponde activar módulo de Research.
>     - El problema está en las comunicaciones (mensajes, secuencia) → corresponde activar módulo de **Consultas** o **Recordatorios**.
> - **No hay síntoma real** → por ejemplo:
>     - Se pide “hacer un Kickoff” por rutina o preferencia.
>     - Se quiere “tener todo siempre en 4.1” sin un motivo justificado.
>     - Se busca documentar por completar la Biblia, no por resolver un síntoma.
> 
> → En todos estos casos, activar 4.1 **no es compatible con la Metodología General** (punto 2) → primero se debe validar si realmente falta un flujo operativo formalizado.
> 

---

### **4.1.1.5 Cómo se valida la activación**

> La decisión de activar este módulo debe ser validada:
> 
> - Por el Researcher en copiloto con la IA.
> - En consulta con el Curador (líder de la tribu de Research), especialmente en sistemas maduros.
> - En servicios maduros, la validación debe incluir evidencia en dashboards y/o retroalimentación estructurada.
> 
> → Activar sin síntoma real **no es compatible con la Metodología General** (punto 2).
> 

---

### 4.1.2 🎯 Resultado esperado del módulo

### **4.1.2.1 Propósito de este punto**

> Este subchunk explica para qué sirve definir el resultado esperado:
> 
> 
> El Researcher y el Curador deben tener claridad sobre **qué entregables debe dejar un ciclo completo del módulo 4.1**.
> 
> Sin este resultado, el sistema sigue operando de forma no trazable o inconsistente.
> 

---

### **4.1.2.2 Qué se espera como resultado operativo**

> El resultado esperado de un ciclo completo del módulo 4.1 es que la etapa quede con:
> 
> - ✅ Un **Journey documentado** y validado con el equipo.
> - ✅ Una lista de **eventos (triggers)** definidos, que activan:
>     - Tareas automáticas.
>     - Tareas manuales digitalizadas en el Desk.
> - ✅ Una estructura de **tareas digitalizadas en el Desk**:
>     - Qué tareas deben ejecutarse.
>     - En qué momento (por qué trigger).
>     - Por qué rol (quién).
> - ✅ Una experiencia de cliente coherente:
>     - Consistencia en el avance de los casos.
>     - Claridad en los puntos de contacto.
>     - Evitación de variabilidad entre operadores.

---

### **4.1.2.3 Qué se espera como resultado editorial y de memoria viva**

> Además de la estructura operativa, el módulo 4.1 debe dejar:
> 
> - ✅ Una **huella digital completa**:
>     - Diagnóstico que justificó la activación.
>     - Journey validado.
>     - Triggers y tareas.
>     - Vacíos detectados y plan de mejora (si quedó algo pendiente).
>     - Acuerdos validados en el Kickoff.
> - ✅ Un **informe editorial del módulo** (ver 4.1.6), validado por el Curador.
> - ✅ Actualización de la **memoria viva en Violet Studio**:
>     - Chunks actualizados según los acuerdos validados.
>     - Notificación generada por la IA cuando corresponda.

---

### **4.1.2.4 Qué se espera como resultado en la Escuela de Conducción y Facilitación**

> Como parte del proceso de mejora continua:
> 
> - ✅ La grabación del Kickoff debe ser revisada por los mentores.
> - ✅ El feedback del mentor debe alimentar:
>     - El aprendizaje del Researcher.
>     - La **mini Biblia de la Escuela de Conducción y Facilitación**.
> - ✅ Cualquier aprendizaje metodológico relevante debe ser incorporado a la memoria viva del rol Researcher.

---

### **4.1.2.5 Indicadores de un resultado de alta calidad**

> Un ciclo de módulo 4.1 se considera de alta calidad cuando:
> 
> - El Journey y triggers quedan claros, comprensibles y usables por el equipo.
> - El Desk refleja la estructura de tareas de forma operable.
> - La experiencia del cliente mejora (flujo más claro, consistente).
> - El informe editorial está bien estructurado y alimenta correctamente la memoria viva.
> - El liderazgo del Kickoff (Facilitación y Conducción) fue valorado positivamente por el feedback de la Escuela.
> - No quedan vacíos operativos críticos sin plan de mejora.

---

### 4.1.3 ✨ Exploración previa requerida

### **4.1.3.1 Propósito de la exploración previa**

> El objetivo de esta exploración no es solo detectar síntomas, sino mapear el sistema real que actualmente hace avanzar los casos en esta etapa.
> 
> 
> Se busca entender:
> 
> - Qué eventos hacen avanzar el sistema.
> - Qué tareas deberían seguirse.
> - Qué fricciones existen hoy.
> 
> No se parte de flujos ideales, sino **desde la práctica real**.
> 

---

### **4.1.3.2 Observación directa con el equipo operativo**

> Hablar con al menos 1 o 2 personas que operen activamente la etapa.Observar cómo organizan su día y cómo toman decisiones.Siempre que sea posible, incluir pantalla compartida o visualización directa.
> 
> 
> Preguntas reveladoras:
> 
> - “¿Cómo sabes qué te toca hacer hoy?”
> - “¿Qué tareas haces en esta etapa?”
> - “¿Qué te hace pasar de una tarea a otra?”
> - “¿Puedes mostrarme cómo ejecutas estas tareas?”
> 
> > 🧠 Regla de calidad: La observación con pantalla compartida es esencial. Sin visualizar cómo el equipo trabaja realmente, el Researcher corre riesgo de subestimar el problema o activarlo prematuramente (Informe 001).
> > 

---

### **4.1.3.3 Trabajo individual del Researcher (con apoyo progresivo de la IA)**

> Después de la observación, el Researcher debe:
> 
> - Identificar momentos donde el sistema avanza o se estanca.
> - Reunir elementos visuales:
>     - Journey anterior (si existe).
>     - CRM.
>     - Flujos existentes.
> - Clasificar los posibles triggers:
>     - 🔵 Eventos Externos.
>     - 🔴 Decisiones.
>     - 🟠 Tareas Internas.
> 
> → Durante este proceso, la IA se usa **progresivamente**:
> 
> - Se alimenta con lo observado.
> - Propone posibles triggers y acciones.
> - El Researcher valida y corrige en vivo, refinando la comprensión del sistema.

> ❗ Aprendizaje no generalizable: Esta exploración es más exigente porque su output se usa en Big Task, Consultas y Recordatorios. No es solo detectar síntomas: es detectar la estructura operativa base.
> 

---

### **4.1.3.4 Qué entregables debe dejar la exploración**

> La exploración previa debe dejar:
> 
> - ✅ Un **diagnóstico claro**:
>     - Qué tareas se hacen hoy y cómo.
>     - Qué eventos generan esas tareas (o por qué no hay eventos claros).
>     - Qué fricciones o inconsistencias se observan.
>     - Si corresponde → evidencia en dashboards (en servicios maduros).
> - ✅ Una **propuesta de activación del módulo**:
>     - Resumen del síntoma.
>     - Justificación de que corresponde activar 4.1.
>     - Propuesta de preparación para el Kickoff (qué puntos clave trabajar).
> 
> → Esta propuesta se valida con la IA y con el Curador antes de convocar el Kickoff.
> 

---

### **4.1.3.5 Qué no es una exploración adecuada**

> No se considera una exploración adecuada:
> 
> - Hacer solo una entrevista informal sin observar el sistema real.
> - No observar pantallas ni ver cómo el equipo realmente opera.
> - Basarse solo en opiniones de jefaturas sin contrastar con el trabajo operativo.
> - No revisar la práctica real en el Desk (cuando ya existe).
> - No revisar dashboards en servicios maduros.
> - Convocar un Kickoff sin diagnóstico previo documentado.

---

### 4.1.4 🛠 Dinámica del módulo

Este módulo se ejecuta en dos fases: primero, un trabajo asincrónico de reflexión individual; luego, un Kickoff sincrónico donde se valida el sistema con el equipo.

**Ambas fases son obligatorias**, salvo casos excepcionales donde el equipo esté perfectamente alineado.

## 4.1.4.1 🧾 Fase asincrónica (tablero + procesamiento)

### **4.1.4.1.1 🌟 Propósito de la fase asincrónica**

### **4.1.4.1.1.1 Propósito central de la fase asincrónica**

> La fase asincrónica busca que cada persona del equipo aporte insumos clave para el trabajo colectivo que se realizará en el Kickoff.
> 
> 
> El objetivo concreto de **Research** en esta fase es:
> 
> ✅ Recolectar las principales frustraciones que vive hoy el equipo operativo en la etapa.
> 
> ✅ Recolectar las principales frustraciones o confusiones que vive el cliente en esta etapa, desde lo que el equipo observa en la práctica.
> 
> ✅ Recolectar las ideas brillantes que el equipo propone para mejorar la etapa.
> 
> ✅ Evaluar el nivel de claridad que tiene el equipo sobre el objetivo operativo de la etapa (por ejemplo: que el cliente rellene la ficha).
> 
> La función concreta para la **Facilitación** es ayudar al equipo a entrar con el **mindset correcto** para esta dinámica:
> 
> ✅ Un mindset de **observación sistémica**.
> 
> ✅ No de diseño.
> 
> ✅ No de validación apresurada.
> 

---

### **4.1.4.1.1.2 Habilidades que se ejercitan en esta fase**

### **4.1.4.1.1.2.1 Habilidades que se ejercitan en el equipo operativo**

> **🏆 Lectura sistémica básica**
> 
> 
> Aprender a observar el flujo de la etapa, detectar síntomas, distinguir triggers reales de tareas internas.
> 
> 🏆 **Alineación operativa**
> 
> Clarificar qué se espera lograr en esta etapa del sistema.
> 

---

### **4.1.4.1.1.2.2 Habilidades que se ejercitan en el Researcher**

> 🏆 Lectura sistémica avanzada
> 
> 
> En esta fase (diseño del tablero), el Researcher trabaja la capacidad de **anticipar qué aspectos del sistema actual son más críticos de explorar**, en base a su observación operativa previa de la etapa.
> 
> Aunque la plantilla de tablero propuesta se aplica casi siempre, el Researcher debe tener criterio para identificar **si conviene proponer ajustes o énfasis específicos**: por ejemplo, reforzar ciertas preguntas, agregar subpreguntas o modular el tono, según el contexto de la etapa y del equipo.
> 
> 🏆 **Facilitación de la metodología**
> 
> El diseño del tablero es un ejercicio de **traducción de la metodología al contexto concreto de la etapa**.
> 
> El Researcher debe asegurar que las instrucciones y preguntas:
> 
> - activen el mindset correcto en el equipo (diagnóstico, no diseño),
> - y generen respuestas útiles para el trabajo colectivo posterior.
> 
> Por lo tanto, también aquí se ejercita la capacidad de **proponer ajustes a la plantilla cuando el contexto lo requiere**, siempre en coherencia con la lógica del módulo.
> 

---

### **4.1.4.1.1.2.3 Referencia cruzada a la Escuela de Facilitación**

> 📌 Ver Mini Biblia de Facilitación v1.1
> 
> - **Facilitación de la metodología** → Mini Biblia 2.1.2
> - **Lectura sistémica** → Mini Biblia 2.1.3
> 
> En esta fase, la **Lectura sistémica** se aplica en la observación previa y en el diseño del tablero (anticipación de focos relevantes).
> 
> La **Facilitación de la metodología** se aplica en el diseño intencionado del tablero asincrónico, garantizando que la plantilla estándar se ajuste correctamente al contexto de la etapa y al nivel de madurez del equipo.
> 

---

### **4.1.4.1.1.3 🚫 Errores comunes a evitar (rol del Researcher)**

### **4.1.4.1.1.3.1 🚫 Tratar el tablero como una “tarea para completar”**

> El tablero no es una tarea con fecha de entrega ni un trámite que el equipo deba “cumplir”.
> 
> 
> Es una **herramienta de exploración compartida**, que aporta insumos valiosos para el diagnóstico colectivo.
> 
> Si el Researcher lo presenta como un simple ejercicio operativo o de cumplimiento, el equipo tenderá a responder de forma superficial o desmotivada, debilitando la calidad del trabajo posterior.
> 

---

### **4.1.4.1.1.4.2 🚫 No explicar bien el propósito de la fase**

> Si el equipo no comprende que esta fase es un **diagnóstico del sistema actual** —y no un ejercicio de diseño o validación—, tenderá a responder desde supuestos, expectativas ideales o propuestas prematuras.
> 
> 
> Sin un marco claro, es común que aparezcan respuestas que saltan a soluciones (“deberíamos cambiar la ficha”) o que describen un sistema ideal, en lugar de aportar insumos sobre cómo funciona hoy la etapa.
> 
> El propósito debe ser explicado con claridad en:
> 
> ✅ el **mensaje de entrega del tablero**,
> 
> ✅ el **hilo en Slack**,
> 
> ✅ y, si es necesario, reforzado en las conversaciones informales previas al Kickoff.
> 
> 👉 El Researcher es responsable de asegurar que este marco esté presente y comprendido por todo el equipo.
> 

---

### **4.1.4.1.1.4.3 🚫Tratar el mensaje de entrega y el hilo en Slack como un simple recordatorio técnico**

> El **mensaje de entrega del tablero** y el **hilo en Slack** no son simples recordatorios operativos:
> 
> 
> son herramientas clave de **facilitación asincrónica** y cumplen un rol central en la activación del **mindset correcto** para la fase.
> 
> Es en estos espacios donde el Researcher debe:
> 
> ✅ modular el tono (ver Mini Biblia, manejo de tonos),
> 
> ✅ enmarcar claramente el propósito de la dinámica,
> 
> ✅ anticipar posibles dudas o desviaciones en el foco,
> 
> ✅ reforzar que esta es una fase formativa, no un trámite.
> 
> Si estos mensajes se envían como comunicados neutros o automáticos, sin diseño intencionado, el equipo tenderá a entrar a la fase con bajo nivel de foco y compromiso emocional.
> 
> 👉 Diseñar estos mensajes es parte integral de la **Facilitación de la metodología** (Mini Biblia, 2.1.2) y debe ser tratado como tal.
> 

---

### **4.1.4.1.1.4.4 🚫No reforzar que la fase sincrónica depende de la calidad de esta fase**

> El equipo debe comprender que el trabajo que realiza en la fase asincrónica **no es un trámite previo**, sino un aporte clave que tendrá consecuencias reales en la evolución del sistema.
> 
> 
> Los insumos que se recolectan en el tablero —frustraciones, ideas, diagnóstico de cómo fluye hoy la etapa— serán la base sobre la cual el equipo de **Diseño y Desarrollo** trabajará en las semanas o meses siguientes.
> 
> En muchos casos, lo que se detecta en esta fase guía el desarrollo de:
> 
> - nuevas automatizaciones,
> - nuevos Desks,
> - cambios en el flujo operativo,
> 
> Si el equipo no percibe esta conexión, tenderá a ver el asincrónico como un ejercicio menor, lo que reduce la calidad de los insumos y el compromiso con la fase.
> 
> Este marco ayuda a activar un compromiso real con el trabajo asincrónico.
> 

---

### **4.1.4.1.1.5 Resultado esperado de la fase asincrónica**

### **4.1.4.1.1.5.1 En el equipo operativo**

> ✅ Que cada miembro del equipo operativo haya tenido un espacio real de protagonismo, donde su mirada sobre cómo fluye hoy la etapa y las principales frustraciones o confusiones que experimenta (propias o del cliente) sean visibles para los actores relevantes del sistema (Researcher, líderes tácticos, mentores de la Escuela).
> 
> 
> ✅ Que el equipo haya desarrollado un **mindset de observación sistémica** y haya comenzado a ejercitar la **determinación de patrones básicos**, a partir de su experiencia en la etapa.
> 
> ✅ Que el equipo haya clarificado su comprensión sobre el **objetivo operativo de la etapa**.
> 
> ✅ Que el equipo comprenda que su aporte en esta fase **tiene impacto real en la evolución futura del sistema**.
> 
> ✅ Que el equipo haya comenzado a activar su mirada propositiva, a través de la pregunta de **idea más brillante**, como un primer paso para calentar motores hacia el trabajo de mejora que se realizará en etapas posteriores.
> 

---

### **4.1.4.1.1.5.2 En términos de insumos para el Kickoff**

> ✅ Que el Researcher cuente con **respuestas bien elaboradas de los operativos** respecto a:
> 
> - Principales **frustraciones que vive hoy el equipo** en la etapa.
> - Principales **frustraciones o confusiones que vive el cliente**, según lo que observa el equipo.
> - Nivel de **claridad del equipo sobre el objetivo operativo** de la etapa.
> - Propuestas surgidas **solo en la pregunta de idea brillante**, claramente separadas de las observaciones de diagnóstico.
> 
> ✅ Que el Researcher disponga de **versiones individuales del Journey (bloque "Así ocurre (según tú)")** bien trabajadas, que reflejen cómo fluye hoy la etapa desde la perspectiva del equipo, y que servirán como base para la construcción del primer borrador del Case Journey en la fase de revisión.
> 

---

### **4.1.4.1.1.5.3 En términos de trazabilidad para el desarrollo posterior**

> ✅ Que los insumos generados en el asincrónico —y posteriormente validados en el Kickoff— puedan servir como base documentada para el trabajo de los equipos de Diseño y Desarrollo en los ciclos siguientes.
> 
> 
> ✅ Que quede **trazabilidad clara y ordenada**, que alimente directamente la construcción del **Case Journey** de la etapa:
> 
> - La **lógica de triggers y acciones** que emerge de esta fase: qué activa el avance del sistema hoy, y qué acciones están (o deberían estar) asociadas a cada trigger. → Este es el insumo central que se plasmará en el **Case Journey**, y que guiará el trabajo de diseño y desarrollo.
> - El **“por qué” de esa lógica**: síntomas detectados en la operación actual (frustraciones del equipo y del cliente), y las ideas más potentes surgidas en la pregunta de idea brillante. → Estos elementos contextualizan y justifican las decisiones que se reflejarán en el Case Journey.
> - Las **deudas técnicas o vacíos detectados**: aspectos de la lógica operativa que aún no están resueltos o que requieren definición adicional en los próximos ciclos de trabajo. → Estas deudas deben quedar documentadas en el Case Journey para que el equipo de Diseño y Desarrollo tenga visibilidad completa del estado actual de la etapa.

---

### **4.1.4.1.1.6 Referencia cruzada a la Escuela de Facilitación**

> 📌 Ver Mini Biblia de Facilitación v1.1
> 
> 
> Habilidades entrenadas en esta fase:
> 
> - Facilitación de la metodología (ver Mini Biblia 2.1.2)
> - Lectura sistémica (ver Mini Biblia 2.1.3)

### **4.1.4.1.2 Bloque: 🌀 Instrucción para la dinámica asincrónica (a incluir en el tablero)**

> Esta parte del tablero es para prepararnos para la reunión de Kickoff.
> 
> 
> El objetivo de este trabajo es **diagnosticar cómo está funcionando hoy esta etapa del sistema**:
> 
> - qué la hace avanzar,
> - qué la traba,
> - y cómo se vive esta experiencia tanto para el equipo como para el cliente.
> 
> ❗ **No estamos diseñando soluciones todavía.**
> 
> Toda la dinámica —salvo la pregunta de **idea más brillante**— es para detectar:
> 
> - **triggers** actuales (qué activa realmente el avance de la etapa),
> - **frustraciones** que dificultan ese avance o que afectan la experiencia del equipo o del cliente,
> - y el nivel de **claridad sobre el objetivo operativo** de esta etapa.
> 
> 👉 Recuerda: el trabajo que hacemos en este tablero será la base para construir el **Case Journey** de la etapa, que luego guiará el trabajo de nuestros equipos de Diseño y Desarrollo.
> 
> 👉 Es un espacio de protagonismo: tu mirada será visible para líderes, mentores y para quienes tomarán decisiones sobre cómo mejorar el sistema.
> 
> 👉 Tu aporte aquí **tiene impacto real**: lo que identifiquemos en este trabajo será lo que se priorice para el desarrollo futuro.
> 

### **4.1.4.1.3 Bloque: 👁️ Lo que ves y vives en esta etapa**

### **4.1.4.1.3.1 Propósito del bloque**

> Este bloque permite que cada miembro del equipo operativo aporte su mirada directa sobre cómo fluye hoy la etapa.
> 
> 
> Aquí buscamos recolectar:
> 
> ✅ **frustraciones propias** que vive el operativo en la etapa,
> 
> ✅ **frustraciones o confusiones que observa en el cliente**,
> 
> ✅ nivel de **claridad sobre el objetivo operativo** de la etapa,
> 
> ✅ y **primeras ideas de mejora** (solo en la pregunta de idea más brillante).
> 
> Es un espacio de **protagonismo individual**: las respuestas serán visibles para líderes, mentores y para quienes tomarán decisiones sobre la evolución futura del sistema.
> 

---

### **4.1.4.1.3.2 Instrucción para el bloque (texto a incluir en el tablero)**

> 🐾 Busca a tu animal y usa el emoticon de tu animal elegido.
> 
> - 🤔 **Responde las preguntas**:
>     
>     Reflexiona sobre esta etapa y responde cada pregunta de forma **breve y clara**, siguiendo la recomendación que viene debajo de cada una.
>     
>     Solo la última pregunta es para propuestas de mejora.
>     
> - 🎙 **Explicación en el Kickoff**:
>     
>     En la reunión sincrónica vamos a trabajar los síntomas reales que aparezcan en estas respuestas. Tu aporte aquí es clave para el diagnóstico colectivo.
>     
> 
> 👉 No busques “responder perfecto”: lo importante es que muestres **cómo ves tú hoy esta etapa**, incluso si tu mirada es distinta a la de otros.
> 

---

### **4.1.4.1.3.3 Estructura de las preguntas**

### **4.1.4.1.3.3.1 🎯 ¿Cuál o cuáles son las condiciones que deben cumplirse para que el caso deje de ser “Etapa analizada” y pueda pasar a la “Siguiente etapa”?**

> Recomendación para el operativo:
> 
> 
> Esta pregunta no es un diagnóstico: busca definir **qué hecho concreto indica que esta etapa ya está cumplida**.
> 
> Ejemplo: “Ficha enviada”
> 
> No incluyas tareas internas o validaciones. Enfócate en **lo esencial**: lo que separa el “seguimos en esta etapa” del “podemos avanzar”.
> 

---

### **4.1.4.1.3.3.2 😖 ¿Cuál es la mayor frustración que vives tú en esta etapa?**

> Recomendación para el operativo:
> 
> 
> Aquí buscamos **frustraciones reales y repetidas** que dificultan tu trabajo hoy.
> 
> Describe un síntoma concreto que esté relacionado con cómo funciona hoy el sistema (no una propuesta).
> 
> Ejemplo: “No sé si una urgencia es real o no, porque no viene marcada en el flujo.”
> 

---

### **4.1.4.1.3.3.3 🧍‍♂️ ¿Qué crees que más frustra o confunde al cliente en esta etapa?**

> Recomendación para el operativo:
> 
> 
> Observa desde la experiencia del cliente: ¿qué cosas tienden a frustrarlo o confundirlo hoy?
> 
> Ejemplo: “El cliente no sabe quién lleva su caso y se frustra porque lo contactan varias personas distintas.”
> 

---

### **4.1.4.1.3.3.4 💡 ¿Cuál es tu idea más brillante para mejorar esta etapa?**

> Recomendación para el operativo:
> 
> 
> Aquí sí queremos propuestas: cualquier idea que creas que podría mejorar la etapa.
> 
> Recuerda que este es un primer espacio para **activar mirada de mejora** (calentar motores), no un diseño formal.
> 
> Ejemplo: “Que la ficha se convierta en un chatbot paso a paso desde el celular.”
> 

---

### **4.1.4.1.4 Bloque:🧩 Así ocurre (según tú) → Proto Caso Journey**

### **4.1.4.1.4.1 Propósito del bloque**

> Este bloque permite que cada miembro del equipo operativo registre su visión personal de cómo avanza hoy un caso en esta etapa, desde su experiencia directa.
> 
> 
> Aquí no buscamos clasificar ni filtrar: queremos que el equipo narre **todo el paso a paso que ocurre en la etapa**, tal como lo vive en la práctica.
> 
> Cuanto más completa y detallada sea esta mirada, más rico será el insumo para construir el **Case Journey**.
> 
> 👉 **Más es mejor**: no limitar la cantidad de pasos. Lo importante es capturar la lógica real de la operación, con toda su complejidad.
> 

---

### **4.1.4.1.4.2 Instrucción para el bloque (texto a incluir en el tablero)**

> 👉 No busques que sea perfecto ni igual al de otros: muestra cómo lo ves tú.
> 
> 
> 👉 Para ordenar tu relato, usa dos tipos de elementos:
> 
> - 🟠 **Tareas internas** → cosas que hace el equipo y que cambian el estado del caso.
> - 🔵 **Eventos externos** → cosas que ocurren fuera del equipo y que hacen avanzar (o frenar) el caso.
> 
> 👉 Incluye tanto:
> 
> - Lo que hace el cliente.
> - Lo que hace el equipo.
> - Lo que ocurre automáticamente.
> - Lo que bloquea o frena.
> - Lo que depende de decisiones.
> 
> 👉 Entre más completa y detallada sea tu versión, **mejor insumo tendremos para construir el Case Journey** de la etapa.
> 
> 👉 Este es un espacio de protagonismo: tu mirada aquí sí tiene impacto real en el desarrollo futuro del sistema.
> 

### **4.1.4.1.4 Bloque: 📬 Feedback**

### **4.1.4.1.4.1 Propósito del bloque**

> Este bloque permite recolectar feedback cualitativo sobre la dinámica asincrónica en sí misma.
> 
> 
> Su objetivo es doble:
> 
> ✅ identificar posibles **fricciones o confusiones** en el diseño de la dinámica (para mejorarla en futuras iteraciones),
> 
> ✅ recoger percepciones del equipo sobre el valor de este espacio (para reforzar el marco de protagonismo en la cultura del sistema).
> 

---

### **4.1.4.1.4.2 Pregunta a incluir al final del tablero**

> 💬 “¿Te hizo sentido este tablero? ¿Qué mejorarías para hacerlo más claro o más útil?”
> 

---

### **4.1.4.1.4.3 Uso del feedback**

> El feedback recolectado en esta pregunta debe ser revisado por el Researcher durante la fase de revisión de resultados (4.1.4.2).
> 
> 
> Este insumo es clave para:
> 
> ✅ iterar y mejorar la plantilla del tablero,
> 
> ✅ ajustar el marco comunicacional en futuras activaciones del módulo,
> 
> ✅ identificar patrones de percepción que puedan ser trabajados en la Escuela de Facilitación (por ejemplo: si el equipo tiende a subvalorar la fase asincrónica, o si hay confusión recurrente sobre los conceptos).
> 
> Además, este feedback debe quedar documentado en el **Repertorio de Módulos** como parte de la trazabilidad de la mejora continua.
> 

### **4.1.4.1.5 🚫 Evitar adelantar la dinámica sincrónica**

> 👉 Indicaciones para el Researcher:
> 
> 
> Para proteger la progresión metodológica del módulo, es importante que el Researcher:
> 
> - No muestre el **Case Journey preliminar** antes del Kickoff.
> - No comparta el diseño de los bloques que se trabajarán en la fase sincrónica.
> - No anticipe procesos de **validación**: en esta fase estamos en diagnóstico.
> - No pida al equipo que priorice o seleccione soluciones: las ideas van solo en la **pregunta de idea brillante**, como calentamiento, sin jerarquización ni validación.
> 
> 👉 Estas indicaciones garantizan que cada fase active su foco específico y que el equipo llegue al Kickoff con una mirada fresca y no condicionada.
> 

### **4.1.4.1.6 💬 Mensaje de entrega de tablero (plantilla)**

### **4.1.4.1.6.1  Ejemplo de mensaje (Slack) (entrega del tablero)**

> 👋 Hola equipo,
> 
> 
> Esta semana iniciamos el Kickoff de la etapa **[Nombre de la etapa]**, trabajando el módulo **“Triggers y Acciones Automáticas”**.
> 
> 👉 Este trabajo se hace en dos fases:
> 
> 1️⃣ **Fase asincrónica** → la que iniciamos ahora
> 
> 2️⃣ **Fase sincrónica** → la que haremos en reunión en unos días
> 
> 🚀 **Propósito de esta fase asincrónica**
> 
> El foco NO es diseñar ni validar. Es **observar con criterio**:
> 
> - Cómo fluye hoy la etapa
> - Qué la hace avanzar
> - Qué la traba
> - Qué vive el cliente
> - Qué vive el equipo
> 
> Cada respuesta que aporten será insumo **real** para el diseño futuro del sistema.
> 
> 👉 No estamos rellenando un formulario: estamos construyendo juntos la mirada que luego guiará el trabajo de Diseño, Automatización y Producto.
> 
> 🏆 **Tu protagonismo importa**
> 
> Este es un espacio de **protagonismo individual**:
> 
> 👉 Cada respuesta será leída por Research, líderes tácticos y mentores.
> 
> 👉 Lo que aquí se levante **sí impacta** en cómo evolucionará el sistema.
> 
> El objetivo es que en la fase sincrónica emerjan:
> 
> ✅ síntomas reales
> 
> ✅ patrones no vistos
> 
> ✅ vacíos operativos
> 
> 📝 **Qué vas a hacer**
> 
> 1️⃣ Responder el bloque de preguntas sobre cómo ves y vives hoy esta etapa
> 
> 2️⃣ Completar tu versión del flujo real ("Así ocurre") → cómo ves tú que avanza hoy un caso en esta etapa
> 
> 👉 No busques “la respuesta correcta”. No importa que veas cosas distintas que otros. Lo valioso es que quede trazada tu experiencia real.
> 
> ⏳ **Plazo para dejar tu trabajo:** **[Fecha y hora]**
> 
> 🔗 **Aquí está el tablero editable:**
> 
> 👉 [Link al tablero]
> 
> Nos vemos en el Kickoff 🚀 ¡Muchas gracias por el compromiso y la mirada que aporten en esta etapa! 🙌
> 

---

### **4.1.4.1.7 💬 Mensaje en hilo (Slack) (marco conceptual)**

### **4.1.4.1.7.1 Ejemplo de mensaje en hilo (Slack)**

> 👋 Abrimos este hilo para el Kickoff de la etapa [Nombre de la etapa] 🚀
> 
> 
> Este mensaje es **igual de importante que la convocatoria principal**.
> 
> No es un recordatorio técnico: es donde explicamos **el propósito del módulo**, **qué estamos entrenando como equipo**, y **cómo conectar eso con lo que hacemos todos los días**.
> 
> ---
> 
> En este Kickoff trabajamos el módulo **“Triggers y Automatizaciones”**, y no estamos aquí para diseñar.
> 
> **Diseñar (Design)** es proponer soluciones nuevas.
> 
> **Investigar (Research)** es entender problemas reales.
> 
> 👉 En esta dinámica estamos en modo **Research**.
> 
> El foco no es imaginar cómo debería ser el sistema, sino **entender cómo funciona hoy**:
> 
> 🔎 ver qué hace que el caso avance, qué lo traba, y cómo lo vive el cliente o el equipo.
> 
> ---
> 
> ### 🧩 ¿Qué es un trigger?
> 
> Un **trigger** es algo que hace que el caso avance.
> 
> No es cualquier tarea: es un momento en que el sistema **cambia de estado**.
> 
> Hay dos tipos:
> 
> - 🔵 **Evento externo**: algo que ocurre sin que lo activemos.
>     
>     *Ejemplo: el cliente envía la ficha, el tribunal publica una resolución.*
>     
> - 🟠 **Tarea interna**: algo que hacemos y que genera un cambio real.
>     
>     *Ejemplo: marcar una urgencia, mover el caso a Para Estudio.*
>     
> 
> > No todo lo que hacemos es un trigger.
> > 
> > 
> > Lo importante es identificar **lo que realmente mueve el sistema** hacia adelante.
> > 

### **4.1.4.1.8 🎥 Recursos audiovisuales complementarios (pendientes)**

### **4.1.4.1.8.1 Propósito del bloque**

> Este bloque deja registrada una deuda pendiente: explorar el uso de recursos audiovisuales que acompañen la fase asincrónica del módulo.
> 
> 
> La idea es que, en el futuro, el hilo de Slack pueda complementarse (o ser reemplazado) por un **video breve**, grabado por el Researcher, que facilite la entrega del **marco conceptual** del módulo y la explicación de la **dinámica asincrónica**.
> 
> El propósito sería reforzar el mindset correcto de la fase y facilitar la comprensión por parte del equipo.
> 

---

## **4.1.4.2 🔎 Lectura de patrones y preparación de la dinámica sincrónica**

### **4.1.4.2.1 Propósito del momento**

> Este momento del trabajo del Researcher ocurre después de la fase asincrónica y antes del Kickoff sincrónico.
> 
> 
> No es solo una revisión de respuestas: es el momento en que el Researcher realiza una **lectura profunda de patrones** y **prepara con intención la dinámica sincrónica**.
> 
> Aquí se trabaja de forma explícita la habilidad de **Lectura Sistémica avanzada** (ver Mini Biblia de Facilitación **2.1.3**):
> 
> 👉 aprender a leer un sistema real a partir de insumos fragmentados, detectar patrones relevantes y preparar la facilitación para que el equipo construya una comprensión colectiva de la etapa.
> 
> En este momento se busca:
> 
> ✅ **Determinar patrones** emergentes en el bloque **👁️ Lo que ves y vives en esta etapa**
> 
> ✅ Construir (curar) el **Caso Journey** a partir de **🧩 Así ocurre (según tú) → Proto Caso Journey**
> 
> ✅ **Diseñar la dinámica del Kickoff**, eligiendo la dinámica más adecuada desde el 📚 **Banco de dinámicas** de las Mini Biblia de la Escuela de Facilitación, con foco en que los operativos puedan **detectar patrones en conjunto** en el sincrónico
> 
> ✅ Vincular el diseño del **Caso Journey** con los **dolores del sistema**, para que las **acciones automáticas** respondan a la realidad de la etapa
> 
> Es un momento táctico clave: es lo que permite que el Kickoff sea **un espacio de aprendizaje colectivo** y no una simple “validación de tablero”.
> 

### **4.1.4.2.2 🔎 Lectura de patrones en 👁️**

### **4.1.4.2.2.1 Propósito del momento**

> Este momento tiene como propósito que el Researcher realice una lectura de patrones profunda a partir de las respuestas del bloque 👁️ Lo que ves y vives en esta etapa.
> 
> 
> No se trata de agrupar respuestas de forma superficial, sino de identificar:
> 
> ✅ **Patrones sistémicos** en las frustraciones del equipo
> 
> ✅ **Patrones sistémicos** en las frustraciones o confusiones del cliente
> 
> ✅ **Patrones de comprensión (o falta de comprensión)** sobre el objetivo operativo de la etapa
> 
> Es clave entender que **la ausencia de patrones claros** o la **gran dispersión en las respuestas** también es un dato del sistema:
> 
> 👉 Puede indicar que la dinámica asincrónica estuvo mal planteada (preguntas poco claras, foco confuso)
> 
> 👉 Puede indicar que el equipo realmente no tiene claridad compartida sobre la etapa
> 
> 👉 Puede revelar una etapa del sistema que está en un estado de alta **desalineación operativa**
> 
> El Researcher no debe forzar patrones que no emergen naturalmente, sino **leer la calidad de la dispersión** como parte del diagnóstico.
> 
> Esta es una aplicación directa de la habilidad de **Lectura Sistémica avanzada** (ver Mini Biblia de Facilitación **2.1.3**).
> 
> La meta NO es preparar un “resumen de respuestas”, sino llegar con una **síntesis de patrones (o de ausencia de patrones)** que luego permita guiar el trabajo colectivo en el sincrónico:
> 
> 👉 que los operativos puedan **ver lo que el sistema muestra hoy**, sea claridad o dispersión, y trabajar sobre esa base.
> 

### **4.1.4.2.2.2 🗂️ Carga y determinación de patrones por pregunta (👁️)**

> En esta fase, el Researcher debe trabajar la lectura de patrones de forma estructurada, pregunta por pregunta, en coherencia con el diseño original de cada pregunta del bloque 👁️ Lo que ves y vives en esta etapa (ver 4.1.4.1.3.3.x).
> 
> 
> 👉 No se debe cargar al agente todo el bloque junto.
> 
> 👉 No se deben mezclar las dimensiones.
> 
> 👉 Cada pregunta tiene su propio propósito metodológico y debe respetarse en la carga y en la lectura.
> 
> Además:
> 
> 👉 En cada carga, el Researcher debe incluir la **Recomendación para el operativo** asociada a la pregunta, para que el agente mantenga el foco metodológico correcto.
> 

---

### **4.1.4.2.2.2.1** 🎯 **Pregunta 1: ¿Cuál o cuáles son las condiciones que deben cumplirse para que el caso deje de ser “Etapa analizada” y pueda pasar a la “Siguiente etapa”?**

- Cargar la **Recomendación para el operativo** + respuestas.
- El agente debe ayudar a detectar:
    
    ✅ Si hay **consenso** en las condiciones de avance.
    
    ✅ Si aparecen **confusiones** o **dispersión**.
    
    ✅ Si la dispersión parece deberse a:
    
    - **Problema en la dinámica** (pregunta mal planteada, foco confuso).
    - **Falta de claridad real** en el equipo sobre las condiciones de avance.
- No se busca determinar patrones en esta pregunta → se busca evaluar el nivel de **claridad compartida**.

---

### **4.1.4.2.2.2.2** 😖 **Pregunta 2: ¿Cuál es la mayor frustración que vives tú en esta etapa?**

- El agente debe ayudar a:
    
    ✅ Detectar **patrones de frustraciones recurrentes** del equipo.
    
    ✅ **Ordenar los patrones por nivel de impacto en la calidad del servicio.**
    
    ✅ Evaluar si actualmente contamos con **capacidad real para resolverlos** (con procesos, automatizaciones, cambios en la estructura, etc.).
    
    ✅ Sugerir **cómo podría resolverse cada patrón** (visión desde el agente).
    
    ✅ Asociar cada frustración detectada a uno o más **triggers del Journey** (dónde se expresa en el flujo actual).
    
    ✅ Comenzar a proyectar el diseño de:
    
    - **Acciones automáticas** que ayuden a reducir ese dolor.
    - **Campos o pasos en un Desk** que ayuden a abordarlo.
- 👉 Esta es una aplicación avanzada de **Lectura Sistémica**: el foco no es solo “leer síntomas”, sino comenzar a construir el puente hacia el diseño futuro del sistema.

---

### **4.1.4.2.2.2.3**🧍‍♂️ **Pregunta 3: ¿Qué crees que más frustra o confunde al cliente en esta etapa?**

- Cargar la **Recomendación para el operativo** + respuestas.
- El agente debe ayudar a:
    
    ✅ Detectar **patrones de frustración/confusión del cliente**.
    
    ✅ **Ordenar los patrones** por nivel de impacto en la experiencia del cliente y en el avance del sistema.
    
    ✅ Evaluar si actualmente contamos con **capacidad real para resolver esos dolores** (procesos, automatizaciones, rediseño de comunicaciones, cambios de flujo, etc.).
    
    ✅ Sugerir **cómo podría resolverse cada patrón** (visión desde el agente).
    
    ✅ Asociar cada dolor detectado a uno o más **triggers del Journey** (dónde se expresa en el flujo actual).
    
    ✅ Comenzar a proyectar el diseño de:
    
    - **Acciones automáticas** o rediseños de comunicación para mejorar la experiencia del cliente.
    - **Campos o pasos en un Desk** que ayuden a reducir esa frustración.
        
        ✅ Evaluar si los síntomas observados requieren ser **complementados con más información directa**:
        
    - Proponer si es necesario realizar **conversaciones cualitativas con clientes** para profundizar.
    - Proponer si es necesario revisar el **NPS en esa etapa** u otros datos de experiencia para validar y enriquecer la lectura.
- 👉 El Researcher debe leer también si el equipo operativo tiene suficiente **empatía y visión compartida** sobre la experiencia del cliente — o si el patrón de respuestas refleja una falta de conexión que deba ser trabajada.

---

### **4.1.4.2.2.2.4:** 💡 **Pregunta 4: ¿Cuál es tu idea más brillante para mejorar esta etapa?**

- Cargar la **Recomendación para el operativo** + respuestas.
- El agente debe ayudar a:
    
    ✅ Agrupar las ideas por **tipo de solución** (automatización, proceso humano, comunicación, estructura).
    
    ✅ Evaluar **a qué patrones de mayor impacto** aporta cada idea (conexión con lo detectado en las preguntas 2 y 3).
    
    ✅ **Rescatar** las ideas que tienen mayor potencial de **atacar los patrones más relevantes**.
    
    ✅ Distinguir entre ideas que son:
    
    - **Accionables en el corto plazo**
    - **Ideas que requieren rediseño profundo**
    - **Ideas que aún son conceptuales y necesitan maduración**
        
        ✅ Evitar que la lectura se vuelva un “catálogo de propuestas creativas sin foco”: el criterio es **conexión con patrones y capacidad de impacto**.
        
- 👉 Esta lectura es clave para preparar el puente hacia el trabajo táctico en etapas siguientes (por ejemplo, diseño de Desk o automatizaciones).

### **4.1.4.2.2.3 🎭 Elección de dinámica de facilitación para el sincrónico**

> 👉 Al finalizar la lectura de patrones de 👁️, el Researcher debe elegir qué dinámica de facilitación usará en el sincrónico para que el equipo pueda:
> 
> 
> ✅ **Detectar patrones en conjunto**
> 
> ✅ Construir una comprensión compartida de los dolores y oportunidades de la etapa
> 
> ✅ Generar protagonismo y apropiación de los patrones emergentes
> 
> 👉 La dinámica se elige desde el **Banco de Dinámicas** de la **Mini Biblia de Facilitación**.
> 
> 👉 Recomendaciones clave:
> 
> ✅ Si el grupo es grande → dividir en subgrupos para agilizar la detección de patrones
> 
> ✅ En la dinámica, cada operativo puede deterctar en el tablero los patrones que quiera. 
> Sin embargo, al momento de dar palabras si alguien detecto un patron y lo comunico no repetirlo.→ no se repiten patrones en voz
> 
> ✅ El tablero puede contener patrones similares, pero en la conversación se busca **evitar repeticiones verbales** → se avanza hasta que no aparezcan más patrones
> 
> ✅ El Researcher debe **celebrar los patrones** cuando son dichos por el equipo → reforzar el protagonismo del grupo
> 
> 👉 El Researcher debe documentar en el tablero:
> 
> - Qué dinámica eligió
> - Por qué la eligió (breve justificación)

### **4.1.4.2.3 🧩 Curación del Caso Journey**

### **4.1.4.2.3.1 Propósito del momento**

> Este momento tiene como propósito que el Researcher construya un **nuevo Caso Journey base** directamente en el **tablero de Lucid**, a partir de:
> 
> 
> ✅ Las versiones de los Journeys individuales completados por los operativos (**🧩 Así ocurre (según tú)**)
> 
> ✅ Los **patrones y dolores** detectados en la lectura de 👁️
> 
> ✅ Su propia visión táctica del sistema
> 
> ✅ Las propuestas de **automatizaciones** conversadas con la IA
> 
> 👉 En esta etapa el Researcher **no está dejando el sistema como es hoy**:
> 
> 👉 Está **proponiendo ya un diseño base** para el **nuevo Journey** de la etapa → que luego será validado y ajustado en el Kickoff sincrónico.
> 
> 👉 Por lo tanto, este es un momento de **diseño inicial**:
> 
> ✅ Se integran los aprendizajes de la fase asincrónica
> 
> ✅ Se propone una estructura de triggers y tareas que pueda:
> 
> - Atender los dolores detectados
> - Aprovechar las capacidades actuales del sistema
> - Servir de base para el diseño futuro de automatizaciones y Desks
> 
> 👉 La conversación con la IA se usa específicamente para:
> 
> ✅ Pensar en **acciones automáticas asociadas a cada evento**
> 
> ✅ Evaluar el sentido y factibilidad de esas automatizaciones
> 
> ✅ Documentar esas ideas como **notas en los componentes de Lucid** correspondientes a cada trigger.
> 

---

### **4.1.4.2.3.2 Proceso de Diseño del Caso Journey**

> 👉 En este momento, el Researcher trabaja directamente en el tablero de Lucid para proponer el nuevo diseño del Caso Journey.
> 
> 
> 👉 El diseño se construye a partir de:
> 
> ✅ Los **Journeys de los operativos** (🧩 Así ocurre)
> 
> ✅ Los **patrones y dolores detectados** en 👁️
> 
> ✅ La reflexión propia del Researcher
> 
> 👉 El Researcher diseña en el tablero:
> 
> - 🔵 **Eventos externos**
> - 🟠 **Tareas internas**
> 
> 👉 En paralelo, conversa con la IA para:
> 
> ✅ Proponer **acciones automáticas** asociadas a los eventos.
> 
> ✅ Por cada acción automática propuesta, anotar en el componente de Lucid:
> 
> - **Qué dolor resuelve**.
> 
> 👉 El foco no es describir cómo es hoy → es proponer un **nuevo Journey base**, mejor alineado con los dolores y oportunidades detectadas.
> 
> 👉 Este diseño quedará listo para ser trabajado y validado con el equipo en el sincrónico.
> 

### **4.1.4.2.3.3 Resultado esperado**

> Al finalizar este momento, el tablero debe contener:
> 
> 
> ✅ Un **Caso Journey curado** en Lucid, con:
> 
> - 🔵 Eventos externos
> - 🟠 Tareas internas
> 
> ✅ Anotaciones claras en el tablero que indiquen:
> 
> - Dónde se expresan los **patrones/dolores** del sistema
> - Qué variantes existen
> - Qué vacíos han sido detectados
> 
> ✅ **Notas en los componentes de triggers** con las **acciones automáticas** propuestas (basadas en la conversación con la IA).
> 
> 👉 El tablero debe quedar listo para ser trabajado colectivamente en el sincrónico:
> 
> ✅ Para que el equipo valide el flujo actual
> 
> ✅ Para que el equipo comprenda cómo los dolores están reflejados en el flujo
> 
> ✅ Para que el equipo pueda discutir sobre el diseño futuro de automatizaciones y Desks.
> 

# 📗 4.1.4.3 🏈 Conducción del Kickoff Sincrónico

---

## 4.1.4.3.1 🪄 Fase de Apertura (referencia Mini Biblia 3.2.1, 3.2.2, 3.2.3)

4.1.4.3.1.1 🎙 Bienvenida Showcera

> Link: ver Mini Biblia 3.2.1
> 

4.1.4.3.1.2 🎭 Dinámica de Rompehielo

> Link: ver Mini Biblia 3.2.2
> 

4.1.4.3.1.3 🌀 Dinámica de Precalentamiento

> Link: ver Mini Biblia 3.2.3
> 

---

## 4.1.4.3.2 👁️ Fase de Diagnóstico Colectivo → "Lo que ves y vives en esta etapa"

(referencia Mini Biblia 3.2.4)

4.1.4.3.2.1 📊 Exposición de patrones y síntesis colectiva

4.1.4.3.2.2 Facilitación de la reflexión → dinámica guiada sobre el tablero

> Link: ver Mini Biblia 3.2.4
> 

---

- **4.1.4.1 🧾 Tablero asincrónico**
    
    ---
    
    ---
    
    - **4.1.4.1.2** 💬 **Mensaje de entrega de tablero**
        
        Este mensaje es una plantilla referencial.
        
        Puede adaptarse según el servicio o etapa, pero debe dejar claro qué se va a trabajar, cómo, y para qué sirve, en un lenguaje simple y directo.
        
        ---
        
        ### Ejemplo de mensaje de convocatoria
        
        > 👋 Hola equipo,
        > 
        > 
        > Esta semana comenzamos el Kickoff de la etapa [Nombre de la etapa], donde vamos a trabajar el módulo “Triggers y Acciones Automáticas”.
        > 
        > El objetivo es entender cómo avanza hoy un caso en esta etapa: qué lo activa, qué lo traba, y qué vive el cliente en ese proceso.
        > 
        > El Kickoff tiene dos fases:
        > 
        > **Fase asincrónica (ahora):**
        > 
        > 1. Cada persona responde un tablero con 4 preguntas.
        >     
        >     Solo la última es para propuestas. Las otras son para observar con criterio.
        >     
        > 2. Luego, completan el Journey base con su versión del flujo real: qué pasos hacen avanzar el caso.
        > 
        > **Fase sincrónica (después):**
        > 
        > Compartiremos nuestras respuestas, compararemos los flujos y discutiremos los puntos clave que aparecieron.
        > 
        > Lo importante no es que todos veamos lo mismo, sino que aparezca lo que nadie estaba viendo.
        > 
        > 👉 Entra al tablero editable y sigue las instrucciones:
        > 
        > 🔗 [Lucid Kickoff – Etapa Nuevo Caso]
        > 
        > 🕐 Tienes hasta el (fecha y hora) para dejar tus respuestas.
        > 
    - **4.1.4.1.3** 💬 **Mensaje en hilo (Slack)**
        
        Este mensaje es **igual de importante que la convocatoria principal**.
        
        No es un recordatorio técnico: es donde **explicamos el propósito del módulo**, **qué estamos entrenando como equipo**, y **cómo conectar eso con lo que hacemos todos los días**.
        
        Acá bajamos el marco conceptual a tierra:
        
        ¿Por qué trabajamos “Triggers y Automatizaciones”? ¿Qué significa diagnosticar en este contexto? ¿Y cómo se diferencia eso de proponer soluciones?
        
        El fodo de la instacia **no es para imaginar cómo debería ser, sino para entender cómo es hoy**.
        
        ### Ejemplo de mensaje en hilo
        
        En este Kickoff trabajamos el módulo **“Triggers y Automatizaciones”**, y no estamos aquí para diseñar.
        
        **Diseñar (Design)** es proponer soluciones nuevas.
        
        **Investigar (Research)** es entender problemas reales.
        
        👉 En esta dinámica estamos en modo **Research**.
        
        El foco no es imaginar cómo debería ser el sistema, sino **entender cómo funciona hoy**:
        
        ver qué hace que el caso avance, qué lo traba, y cómo lo vive el cliente o el equipo.
        
        ---
        
        Para eso, necesitamos identificar los **triggers**:
        
        las cosas que **activan un cambio real** en el sistema.
        
        ---
        
        ### 🧩 ¿Qué es un trigger?
        
        Un **trigger** es algo que hace que el caso avance.
        
        No es cualquier tarea: es un momento en que el sistema cambia de estado.
        
        Hay dos tipos:
        
        - 🔵 **Evento externo**: algo que ocurre sin que lo activemos.
            
            *Ejemplo: el cliente envía la ficha, el tribunal publica una resolución.*
            
        - 🟠 **Tarea interna**: algo que hacemos y que genera un cambio real.
            
            *Ejemplo: marcar una urgencia, mover el caso a Para Estudio.*
            
        
        > No todo lo que hacemos es un trigger.
        > 
        > 
        > Lo importante es identificar **lo que realmente mueve el sistema** hacia adelante.
        > 
        
        ---
        
        ### ✍️ ¿Qué te pedimos ahora?
        
        1. Contesta el tablero desde tu experiencia real.
        2. Edita el Journey con lo que tú crees que hace avanzar el caso.
        3. Las propuestas de mejora van solo en la última pregunta.
        
        ---
        
        **Este Kickoff es para mirar el sistema como es, no como debería ser.**
        
        Diagnosticar con criterio es el primer paso para después diseñar algo que funcione de verdad.
        
        ---
        
        - **🔗 Recursos audiovisuales complementarios (pendientes)**
            
            Para que el mensaje en el hilo cumpla su propósito de formar y motivar al equipo, se recomienda adjuntar (o preparar) los siguientes videos:
            
            **🎥 Video 1: Cómo usar Lucid para editar el Journey**
            
            - **Objetivo:** enseñar a los participantes cómo editar correctamente su copia del Journey base.
            - **Incluye:**
                - Cómo agregar triggers entre bloques.
                - Cómo usar colores, emojis y comentarios.
                - Cómo identificar tareas internas, decisiones y eventos.
            
            **🎥 Video 2: Automatización por tareas y eventos**
            
            - **Objetivo:** acompañar el mensaje del hilo con una explicación clara del concepto de triggers, su utilidad y cómo se representan en el Caso Journey.
            - **Incluye:**
                - Explicación de la diferencia entre eventos externos (hechos jurídicos) y tareas internas (actos jurídicos).
                - Ejemplos concretos de triggers reales y sus acciones asociadas.
                - Introducción al Caso Journey como herramienta para mapear lógica operativa.
                - Uso de la IA para apoyar la clasificación y validación de estos elementos.
            
            📌 **Nota:** Si el equipo es nuevo o el módulo se activa por primera vez en una etapa, estos videos deben estar disponibles y enlazados desde el mensaje de hilo o la instrucción general del tablero.
            
        
        ---
        
- **4.1.4.2 🔎 Revisión de resultados (fase asincronica)**
    
    Una vez que el equipo ha respondido su tablero individual, el Researcher debe generar una **síntesis clara y útil** para preparar la fase sincrónica.
    
    El objetivo no es evaluar personas, sino **diagnosticar el sistema actual** a partir de la experiencia del equipo:
    
    qué síntomas aparecen, qué se repite, qué está ausente y cómo se vive el proceso.
    
    ---
    
    ### 🗂 Carga de respuestas
    
    El Researcher recopila todas las respuestas del tablero en una tabla editable con el siguiente formato:
    
    | Participante | Pregunta 1 | Pregunta 2 | Pregunta 3 | Pregunta 4 | Evaluación de la dinámica |
    | --- | --- | --- | --- | --- | --- |
    
    > El campo “¿Te hizo sentido este tablero? ¿Qué mejorarías para hacerlo más claro o más útil?” debe agregarse en todas las dinámicas.
    > 
    > 
    > Esta retroalimentación será parte de la conversación con el agente IA.
    > 
    
    ---
    
    ### 🤖 Revisión con el agente IA (Preguntas 2, 3, 4 y feedback)
    
    El análisis se realiza **pregunta por pregunta** (excepto Pregunta 1), en conjunto con el agente IA. Para cada una:
    
    1. **Lectura de respuestas individuales más relevantes**
        
        El agente IA presenta directamente las respuestas desde la tabla, señalando:
        
        - Qué se repite.
        - Qué está claro, confuso o fuera de foco.
        - Qué vale la pena citar textual.
    2. **Propuesta de síntesis del agente**
        
        Una lectura general organizada que identifica:
        
        - Fricciones o síntomas comunes.
        - Contradicciones o tensiones.
        - Vacíos importantes.
        - Conexión (o no) con los síntomas detectados.
    3. **Ajuste conjunto con el Researcher**
        
        El Researcher valida o corrige la síntesis. Esta versión curada será la base para el tablero sincrónico.
        
    4. **Revisión de la evaluación de la dinámica**
        
        El agente IA muestra las respuestas a la pregunta “¿Te hizo sentido este tablero?”, para que el Researcher:
        
        - Detecte puntos de confusión o malentendidos en la estructura.
        - Mejore el diseño futuro de la dinámica.
        - Ajuste el mensaje o la facilitación si hay patrones de insatisfacción.
    
    ---
    
    ### 🚫 Sobre el Bloque 3: 🧩 Así ocurre (según tú)
    
    Este bloque **no se revisa con el agente IA**.
    
    Es un trabajo **exploratorio y libre del Researcher**, que debe:
    
    - Revisar los journeys propuestos por el equipo.
    - Extraer hipótesis, pasos críticos y posibles puntos de automatización.
    - Diseñar un primer borrador del **Case Journey**, a trabajar en la jornada sincrónica.
    
    > Este diseño debe ser revisado por el Líder Researcher, para alinear criterios de calidad metodológica.
    > 
    
    > Deuda técnica pendiente: formalizar orientaciones para construir un Case Journey desde el análisis del Bloque 3.
    > 
    
    ---
    
    ### ✅ Resultado final
    
    - Una **síntesis por pregunta** (2, 3, 4) lista para facilitar la conversación del Kickoff sincrónico.
    - Un primer diseño del **Case Journey**, basado en la experiencia real.
    - Un levantamiento cualitativo sobre **cómo se vivió la dinámica**, útil para iterar el módulo.

---

- **4.1.4.3 🧭 Conducción del Kickoff Sincrónico – Esquema Base**
    
    El Kickoff debe desarrollarse con claridad, ritmo emocional y sentido técnico. La dinámica se estructura en cinco momentos discursivos, cada uno con un objetivo específico y con responsabilidades claras entre el **Líder** (voz de la visión) y la **Facilitadora** (energía y cuidado del grupo).
    
    ---
    
    ### 4.1.4.2.1 🪄 Apertura – Reir, Alinear, Disparar
    
    ## 4.1.4.2.1.1🪄Fase 1: Reir
    
    ## 4.1.4.2.1.1.1🎙 Paso 1: **Bienvenida Showcera**
    
    👉 *¿Quién la hace?*
    
    **La persona con más habilidades para “pegarse el show”** — no importa si es el Líder o el Facilitador. Lo importante es **romper el hielo con estilo, humor y calidez**.
    
    ---
    
    ### 🌟 ¿Qué buscamos?
    
    Que el equipo **sienta que está entrando a una conversación distinta**, cercana, entretenida y con sentido. Una bienvenida emocional bien hecha:
    
    - **Desarma la tensión** típica de las reuniones formales.
    - **Activa emocionalmente** al equipo.
    - **Crea confianza** para hablar con honestidad.
    - Marca un tono de **alegría, colaboración y protagonismo**.
    
    ---
    
    ### 🎤 Estándar aspiracional:
    
    > El equipo tiene tanta confianza que quien hace la bienvenida puede entrar cantando, rapeando o inventando un narrativa ficticia. No se trata de ser artista, sino de atreverse a hacer el ridiculo.
    > 
    
    ---
    
    ### 🔑 Recomendaciones prácticas:
    
    - Usa un recurso inesperado: **música, una frase con humor, un objeto simbólico, una referencia pop**.
    - Incluye al equipo: menciónales, haz una broma interna, conéctalos con algo que compartieron recientemente.
    - Evita lecturas, formalidades o frases genéricas.
    - Muestra emoción: **si tú no te diviertes al iniciar, nadie más lo hará.**
    
    ## **4.1.4.2.1.1.2 🎭 Paso 2: Dinámica de Rompehielo (con Humor)**
    
    ---
    
    ### 🧠 ¿Para qué sirve este momento?
    
    La dinámica de rompehielo **no es solo para que hablen todos**: es una herramienta para **generar complicidad, risa compartida y desdramatizar** lo que viene. Tiene que mover emociones, **no parecer una encuesta grupal**.
    
    Este es el segundo disparo emocional de la apertura: ya hubo show, ahora toca **hacer reír al grupo desde lo cotidiano y lo absurdo**.
    
    ---
    
    ### 💡 ¿Qué buscamos?
    
    - Que **todos participen sin presión**, incluso los más tímidos.
    - Que el grupo **suelte una risa genuina o al menos una sonrisa**.
    - Que el equipo se escuche de forma horizontal y divertida.
    - Que la reunión **no arranque en modo oficina**, sino en modo juego + colaboración.
    
    ---
    
    ### 📌 Orientaciones para una buena dinámica:
    
    - **Evita preguntas serias o profundas**: la profundidad vendrá después.
    - Elige preguntas **ligeras, absurdas o que despierten imágenes graciosas**.
    - Prefiere formatos donde **las respuestas sean breves y todos pasen rápido**.
    - **Fomenta lo inesperado**: que el equipo se sorprenda y se ría de sus propias ocurrencias.
    - **No la alargues demasiado**: una buena ronda de 3-5 minutos es suficiente para prender motores.
    
    ---
    
    ### 🚫 Qué evitar:
    
    - Preguntas tipo “¿qué esperas del Kickoff?” (muy racional).
    - Dinámicas competitivas o que generen incomodidad.
    - Falta de ritmo: si la energía cae, el rompehielo no sirvió.
    
    Paso 2: Rompejielo y rompehielo
    
    **Responsable:** Facilitadora
    
    1. Da la bienvenida en tono cálido y cercano.
    2. Refuerza que este espacio **no es para evaluar personas**, sino para **mejorar el sistema juntos**.
    3. Lanza un rompehielo simple, pero emocional:
        - “En una palabra, ¿qué emoción te genera esta etapa hoy?”
        - “Si esta etapa fuera un paisaje, ¿cómo se vería?”
        - “¿Qué te gustaría que cambiara mágicamente en esta etapa?”
    4. Anima a todos a participar. **Si alguien no habla, invítalo directamente con suavidad.**
    5. Reacciona con expresividad: “¡Qué buena imagen!”, “Uff, entiendo esa emoción”, etc.
    
    ## 4.1.4.2.1.2 🧭 Fase 2: Alinear
    
    ## **4.1.4.2.1.3 🎯 Fase 3: Disparar**
    
    ---
    
    ---
    
    ### 4.1.4.2.2 **👁️ Lo que ves y vives en esta etapa**
    
    - **Objetivo:** Presentar las ideas centrales del diagnóstico asincrónico: síntomas detectados, patrones relevantes y fricciones destacadas.
    - **Responsable:** Líder.
    - **Dinámica:**
        - El Líder expone síntesis por pregunta, sin leer respuestas una por una.
        - Lanza preguntas detonadoras para abrir el debate.
        - La Facilitadora asegura que todos participen, reconoce aportes y cuida el tiempo.
    
    ---
    
    ### 4.1.4.2.3 ⏸️ Pausa y T**ransición**
    
    - **Objetivo:** Marcar el cambio de mentalidad: pasamos de “cómo se vive” a “cómo debería gestionarse”.
    - **Responsable:** Líder, con apoyo emocional de la Facilitadora.
    - **Mensaje clave:** Este segundo bloque es una propuesta inicial de diseño, paso a paso. Se puede intervenir libremente, pero respetando el orden para no perder foco.
    
    ---
    
    ### 4.1.4.2.4 🧩 **Exposición del Journey**
    
    - **Objetivo:** Presentar el flujo propuesto por el equipo Research, paso a paso, para que el equipo lo contraste con su experiencia real.
    - **Responsable:** Líder.
    - **Dinámica:**
        - Se explica cada paso brevemente.
        - Se abren intervenciones inmediatas con preguntas como:
            - “¿Este paso refleja la práctica real?”
            - “¿Se entiende su lógica?”
        - Se recogen ideas antes de pasar al siguiente paso. **No es un espacio de decisiones, sino de contraste y propuesta.**
    
    ---
    
    ### 4.1.4.2.5🏁 **Palabra de cierre**
    
    - **Objetivo:** Dar sentido al trabajo realizado, resumir hallazgos clave y proyectar los próximos pasos (ej. diseño del Desk, automatizaciones, formación).
    - **Responsables:**
        - **Líder**: entrega dirección y claridad técnica.
        - **Facilitadora**: cierra con reconocimiento humano y emocional al equipo.
    
    Esta fase es de convergencia. Se valida lo propuesto, se cierran ambigüedades y se deja trazabilidad clara de cómo esta etapa empieza a convertirse en sistema.
    
    > Esta reunión se realiza exclusivamente con el Team Ops (ejecutivos/as legales y abogados/as que operan esta etapa), no con el Consejo.
    > 
    
    ---
    

---

### 4.1.5 🍃 Notas metodológicas específicas

**🔧 1. No se parte desde automatizaciones**

El foco no es diseñar tareas para bots ni montar flujos ideales.

El foco es detectar **qué eventos hacen avanzar el caso**, y **qué acciones deberían seguirse naturalmente.**

**🤖 2. La IA no inventa el Journey: lo ordena con el Researcher**

El Journey base no se genera por sí solo.

Se construye **desde lo observado, lo que se repite en la operación y lo que frustra al cliente.**

La IA asiste para ordenar, **pero no reemplaza la agudeza ni el criterio del Researcher.**

**🧠 3. El tablero es una herramienta pedagógica**

No es solo una visual bonita.

Es la forma que tiene el Researcher de **llevar al equipo a pensar como sistema**, haciendo visible lo que antes era tácito.

Bien usado, el tablero permite que el equipo **se exprese, se ordene y se alinee.**

**🧩 4. La validación no es solo confirmación: es alineación mental**

El Kickoff no es para decir “sí o no” al Journey.

Es para que el equipo **se escuche mutuamente, se entienda, y se alinee con una mirada común de la etapa.**

**⚙️ 5. Las acciones automáticas no replican lo que el equipo hace hoy**

No se trata de copiar el trabajo humano.

Se trata de **detectar lo que el sistema puede ejecutar solo, sin juicio, de forma confiable.**

**🕳 6. Si no hay claridad sobre las acciones, se marca vacío**

No se fuerza la resolución.

Los vacíos son trazables y se trabajan después.

Si un trigger no tiene acción clara, se marca como: **🕳 Vacío técnico**, derivable a Big Task, Consultas o Recordatorios.

**🧱 7. El foco es dejar un sistema mínimo funcional**

No se busca perfección.

Si el Journey está bien clasificado y las acciones tienen sentido, ya existe una **base replicable para escalar o rediseñar.**

**🧑‍🤝‍🧑 8. Esta etapa es operativa, no estratégica**

El módulo se trabaja con el equipo operativo, **no con el Consejo.**

Su objetivo es ver qué ocurre hoy, **no modelar soluciones futuras.**

🔍 Si el objetivo es entender, se explora con el equipo.

🧭 Si el objetivo es rediseñar, se trabaja con el Consejo.

---

### 4.1.6 📤 **Paso a paso posterior al Kickoff**

Una vez finalizado el Kickoff y validado el Journey, el módulo no se considera completo hasta que el Researcher haya dejado trazado todo el sistema en formato útil y vectorizable.

---

**✅ 1. Marcaje final del Journey**

El Researcher revisa cada trigger del Journey validado y marca su estado:

- ✅ Acciones automáticas asociadas acordadas
- 🕳 Vacío técnico declarado (si no quedaron claras las acciones)

Este marcaje se hace directamente en el Lucid, Figma o tabla, usando texto, ícono o etiqueta.

---

**📝 2. Redacción del informe del módulo**

El informe no es un formulario. Es un documento editorial, claro y ordenado, que debe dejar trazado:

- El diagnóstico que justificó la activación
- El Journey validado
- Todas las acciones automáticas asociadas por trigger
- Los vacíos técnicos detectados
- El aprendizaje emergente

El cuerpo del informe puede estar redactado en texto libre, con tablas funcionales para las acciones por trigger.

Debe permitir que cualquier miembro de diseño, IA o desarrollo **entienda qué ocurre, qué se propuso, y qué sigue.**

---

**📤 3. Carga en el Repertorio de Informes por Módulo**

El informe completo del módulo se guarda en:

📚 **Repertorio de Informes por Módulo** → dentro de la **Biblia Research Core**

- Carpeta: `Triggers y Acciones Automáticas`
- Subcarpeta: `Informe - Etapa [Nombre] - [Fecha]`

---

**📘 4. Enlace en la Biblia del Servicio correspondiente**

En la Biblia del Servicio (ej. Litigios), se deja el link al informe bajo la etapa correspondiente, con una nota breve sobre lo que resolvió el módulo y qué puntos quedaron pendientes.

---

**📎 ¿Qué debe quedar registrado?**

- ✅ Journey final validado (en visual o tabla)
- ⚙️ Acciones automáticas asociadas por trigger
- 📑 Informe completo con diagnóstico, acciones y aprendizaje
- 🌱 Diagnóstico de aprendizaje
- 🔗 Enlace referencial en la Biblia del Servicio y la Research Core

---

### ⚠️4.1.7. ⚙️ Requerimientos específicos del Informe del Módulo

**⚠️ Atención IA: esta sección esta débil, debe ser mejorada con el correr del tiempo cuando comencemos a generar y cargar nuestros primeros informes.** 

### 4.1.7.1  🗺️ Journey validado

*(Se adjunta Lucid o tabla con los pasos clasificados como 🟠 / 🔴 / 🔵)*

### 4.1.7.2⚙️ Acciones automáticas asociadas por trigger

### 🔵 Trigger: Cliente hace click en “Enviar Información” en Ficha Web

- **🗂 Tipo**: Evento externo
    - **📍 Etapa**: 🟦 Nuevo Caso
    - **🎯 Propósito**: Marca el cierre del ingreso de información por parte del cliente y activa la preparación del expediente.
        
        
        | N° | Acción automática | Sistema | Propósito | Estado |
        | --- | --- | --- | --- | --- |
        | 1 | Carga información en la BBDD | CRM | Registrar los datos del formulario | ✅ |
        | 2 | Marca “Ficha Web Completada” | CRM | Confirmar cierre de la ficha | ✅ |
        | 3 | Cambia etapa a “Para Estudio” | CRM | Transición operativa al siguiente tramo | ✅ |
        | 4 | Crea tarea “Obtener Docs Nuestros” | CRM / Task | Inicia el trabajo del ejecutivo | ✅ |
        | 5 | Completa campo “Pendiente” | CRM | Deja la tarea en estado inicial | ✅ |
        | 6 | Completa campo “Recomendación” con “.” | CRM | Marcador para observación futura | ✅ |
        | 7 | Crea carpeta del cliente (en mayúsculas) | Drive | Organiza el expediente | ✅ |
        | 8 | Crea subcarpetas estándar | Drive | ACREEDORES, ACTIVOS, etc. | ✅ |
        | 9 | Pega el link en campo [🗒️Drive] | CRM | Acceso directo desde CRM | ✅ |
        | 10 | Genera PDF de la ficha y lo guarda | Drive | Archivo de respaldo | ✅ |
        | 11 | Mueve contacto en embudo “Para Estudio” | Vambe | Sincronización CRM–comercial | ✅ |
        | 12 | Detona plantilla automática [nombre pendiente] | Vambe | Comunicación inicial al cliente | 🕳 |
    
    ---
    
    **🧠 Notas internas:**
    
    - La acción 12 quedó como vacío técnico. Se derivará al módulo de Consultas o Recordatorios.
    - Las demás acciones fueron validadas con el equipo operativo durante la sesión.

---

---

## **4.2. 2️⃣🧩 Módulo Big Task**

---

### **4.2.1 🔧 ¿Qué síntoma activa este módulo?**

Este módulo se activa cuando una tarea crítica del sistema no está clara, bien ejecutada o lista para ser diseñada. Los síntomas más comunes son:

---

### ⚠️ Problemas operativos

1. **Está mal ejecutada**

> Se cometen errores, cada persona la hace distinto o los resultados no son confiables.
> 
1. **Genera confusión operativa**

> No hay acuerdo de qué pasos incluye, qué orden tienen o cuándo se considera bien hecha.
> 
1. **No tiene trazabilidad**

> La tarea se hace, pero no queda claro quién la hizo, cómo se hizo o si fue bien realizada.
> 

---

### **4.2.2 🎯 Resultado esperado del módulo**

Este módulo no busca observar qué hace avanzar el sistema (como en el Módulo 1 – Triggers), sino **diseccionar y estructurar en profundidad una tarea crítica completa**, paso por paso, desde lo operativo hasta lo cognitivo.

El foco es construir un flujo **ejecutable**, no idealizado; **estructurado**, no difuso; y que permita **automatizar lo que se pueda**, y **acompañar lo que se debe**.

---

Al finalizar este módulo, el equipo debe contar con:

---

### **1. Un flujo paso a paso curado**

> Redactado con claridad, en orden real de ejecución.
> 
> 
> No se trata de procesos ideales, sino de cómo ocurre realmente la tarea en terreno.
> 

---

### **2. Clasificación de cada paso por tipo de acción**

> Cada paso debe estar clasificado como:
> 
- 🪨 **Roca**: acción estructurable, precisa, repetitiva, automatizable
- 🌬️ **Viento**: acción que requiere criterio, interpretación o acompañamiento
- 🌀 **Mixto**: combina ambos tipos de acción

---

### **3. Diagnóstico y recursos por paso**

- Para los pasos 🪨 Roca: se propone una posible **automatización, validación o prellenado**.
- Para los pasos 🌬️ Viento: se sugiere al menos **un recurso de apoyo**, como guía, formación, IA o mentoría.

> Estos recursos no se implementan en este módulo, pero se trazan como insumos para Producto, Personas, Diseño o IA.
> 

---

### **4. Propuesta inicial de campos por paso y agrupación por bloques**

> Por cada paso se sugieren los campos funcionales necesarios, clasificados como:
> 
- 🌬️ Viento: campos que requieren apoyo cognitivo (comentario, juicio, justificación)
- 🪨 Roca: campos de digitación, selección o confirmación técnica

> Luego se agrupan en bloques funcionales (futuras pestañas), organizados por tipo de acción o intención del usuario
> 

---

### **5. Narrativa breve de la Big Task**

> Una frase concreta que exprese, desde el punto de vista del usuario, qué se espera lograr con esta tarea.
> 

---

### **6. Tablero trazado, compartido y listo para diagnóstico**

> El tablero contiene:
> 
- El flujo curado
- Los campos propuestos
- Las agrupaciones por bloque
- La carga cognitiva
- Las etiquetas 🪨/🌬️ por paso

> Este tablero es la entrada directa para:
> 
- Diseño del prototipo (Desk en Vercel)
- Validación con usuarios reales
- Presentación en el Consejo (paso 4.2.5)
- Implementación futura

---

### 🧠 Sobre la complejidad del módulo

Este módulo requiere trabajo en equipo.

Si bien parte desde la observación operativa, su potencia está en la **discusión táctica posterior y la capacidad de estructurar lo observado**.

---

### 👥 Roles que participan activamente:

| Fase | Rol protagonista |
| --- | --- |
| 4.2.3 | Legal Researcher (estructuración inicial) |
| 4.2.4 | Legal Designer (traducción a campos e interfaz) |
| 4.2.5 | Legal Designer + Consejo (diagnóstico por paso) |
| 4.2.6 | Product Manager (planificación táctica y deuda) |

> Solo con esta coordinación por capas se puede convertir una tarea compleja en un sistema que funcione bien, escale y acompañe sin fricción.
> 

---

### **4.2.3 ✨ Exploración previa requerida**

Este módulo parte desde la observación directa de quienes ejecutan la tarea crítica. No se trata de preguntar qué creen que hacen, sino de **ver cómo realmente la ejecutan**.

La exploración no busca eficiencia ni rapidez: busca fidelidad, comprensión compartida y trazabilidad para construir desde lo real.

---

### **4.2.3.1 Observación directa a todo el equipo operativo**

El Researcher y el Designer se reúnen con **todas las personas que ejecutan la Big Task**.

Cada integrante del equipo operativo muestra **cómo realiza la tarea en vivo**, compartiendo pantalla o relatando su flujo real.

- Las sesiones pueden ser individuales o grupales.
- El **Researcher guía la conversación y hace las preguntas**, enfocándose en entender los pasos reales, variaciones y criterios usados.
- El **Designer observa y registra todo directamente en el chat con la IA**, dejando trazabilidad paso a paso de lo observado:
    - Acciones concretas
    - Fricciones detectadas
    - Términos usados por los operativos
- No se interrumpe ni se optimiza el flujo: se documenta tal como ocurre.

> Si hay diferencias entre personas, se registran como variantes o flujos paralelos.
> 
> 
> **No se busca consenso**, se busca **entender la diversidad real del proceso**.
> 

---

### **4.2.3.2 Estructura y jerarquía del Desk (curaduría con IA)**

Una vez finalizadas las sesiones de levantamiento, el **Legal Designer toma el liderazgo del proceso de estructuración**, trabajando directamente con la IA para convertir lo observado en una propuesta clara de Desk: pasos ordenados, campos sugeridos y bloques funcionales preliminares.

El Researcher acompaña este proceso como segunda opinión, validando que la propuesta mantenga fidelidad a lo observado y no introduzca distorsiones ni supuestos nuevos.

Se recomienda que el Researcher active el siguiente modulo, mientras deja al Designer trabajar. 

### 🎯 Objetivo

Transformar el flujo observado en una estructura lógica, priorizada y comprensible para el usuario final.

Esta curaduría servirá como **base trazable para el prototipado en Vercel** o para ser enviada directamente a Stitch.

---

### 🧩 Fase 1: Validar y acordar el orden de los pasos

- El Designer presenta a la IA los pasos observados (según el levantamiento del módulo anterior).
- Se **acuerda el orden natural y funcional** de ejecución, evitando interpretaciones o reorganizaciones externas.
- Se corrigen redundancias, divisiones innecesarias o pasos ambiguos.
- Cada paso queda numerado y titulado con una acción clara.

💬 *Ejemplo de trazado en chat:*

```yaml
Paso 1: Revisar documentos entregados
Paso 2: Indicar si están correctos
Paso 3: Comentar en caso de error
```

---

### 🧩 Fase 2: Generación de campos sugeridos

En esta fase, el Designer trabaja con la IA para **crear los campos funcionales** que formarán parte del futuro Desk, a partir de los pasos observados en terreno.

---

### 1️⃣ Crear campos por paso

Por cada paso del flujo operativo, el Designer define **qué se le va a pedir hacer al usuario**, en forma de uno o más campos.

💬 *Ejemplo:*

```yaml
yaml
Paso 2: Indicar si el documento es correcto
→ Campo 1: Selección “Correcto / Incorrecto”
→ Campo 2: Comentario (si es “Incorrecto”)

```

---

### 2️⃣ Clasificar el tipo de esfuerzo: Roca / Viento

Cada campo creado se clasifica según el tipo de esfuerzo que exige del usuario:

- 🪨 **Roca** → Acción precisa y concentrada.
    
    El usuario debe ingresar o confirmar información sin margen de error.
    
- 🌬️ **Viento** → Acción exploradora.
    
    El usuario necesita revisar, buscar o interpretar información antes de responder.
    

---

### 3️⃣ Marcar atributos adicionales (si aplica)

- **Condicional**: el campo aparece solo en ciertas situaciones.
- **Automatizable**: no requiere intervención humana.

---

### 🔁 Validación con el Researcher

Una vez terminado el listado de campos por paso, el Designer presenta su propuesta al Researcher **antes de agrupar**.

El rol del Researcher es validar fidelidad con lo observado:

- Que no falte nada relevante.
- Que no haya campos agregados por deducción.
- Que el orden y contenido respeten la experiencia real.

💬 *Ejemplo trazado en chat:*

```yaml
Paso 2: Indicar si el documento es correcto
→ Campo 1: Selección “Correcto / Incorrecto” (🌬️ Viento)
→ Campo 2: Comentario (solo si es “Incorrecto”) (🪨 Roca – condicional)
→ Campo 3: Fecha del documento (🪨 Roca)

```

---

### 🧩 Fase 3: Agrupación preliminar en bloques funcionales

Con los campos ya validados y clasificados (en Fase 2), el Designer trabaja con la IA para agruparlos en **bloques funcionales**. Cada bloque será una pestaña del futuro Desk y debe contener campos relacionados por tema o tipo de información.

---

### 📦 Cada bloque debe incluir:

1. **🏷️ Nombre del bloque**
    - Una categoría clara que agrupe los campos.
        
        Ej: *Documentos pendientes*, *Datos personales*, *Patrimonio*, *Acreedores*, *Deudas*.
        
2. **🎯 Acción principal esperada en el bloque**
    - ¿Qué debe lograr el usuario en esta sección?
        
        Ej: “Revisar si los documentos entregados son correctos y dejar comentarios si hay errores.”
        
3. **📋 Lista de pasos y campos incluidos**
    - Escribe los campos de cada paso en el bloque que corresponda.
    - Si un mismo paso tiene campos en más de un bloque, indícalo como **(parcial)**.
    - 💬 *Ejemplo:*
        
        ```yaml
        Paso 2: Indicar si el documento es correcto
        → Campo 1: Selección “Correcto / Incorrecto” (🌬️ Viento)
        → Campo 2: Comentario (solo si es “Incorrecto”) (🪨 Roca – condicional)
        → Campo 3: Fecha del documento (🪨 Roca)
        ```
        
    - 💬 *Ejemplo si el paso se divide entre bloques:*
        
        **Bloque A – Revisión inicial**
        
        ```yaml
        Paso 2 (parcial): Indicar si el documento es correcto
        → Campo 1: Selección “Correcto / Incorrecto” (🌬️ Viento)
        
        ```
        
        **Bloque B – Observaciones**
        
        ```yaml
        Paso 2 (parcial): Indicar si el documento es correcto
        → Campo 2: Comentario (solo si es “Incorrecto”) (🪨 Roca – condicional)
        → Campo 3: Fecha del documento (🪨 Roca)
        
        ```
        

---

### 🧠 ¿Qué hace el Researcher?

- Revisa si algún agrupamiento **rompe con lo observado en terreno** o pierde sentido funcional.
- No interviene en decisiones visuales o de diseño, solo en **fidelidad operativa**.

---

### 4.2.3.3 JSON de bloques y campos

Este documento resume la información trazada por la IA durante la Fase 2 (creación de campos por paso) y la Fase 3 (agrupación en bloques), en un formato estandarizado y legible tanto para humanos como para sistemas automatizados.

### 📌 Objetivo del documento:

- Servir como insumo directo para construir el Desk en Vercel o Stitch.
- Reflejar con fidelidad la lógica operativa y visual del flujo.
- Evitar reprocesos innecesarios o dependencias del Designer para estructurar lo ya definido.

---

### 📄 Estructura del documento:

```json

{
  "desk": {
    "nombre_desk": "Validar Documentación",
    "accion_central": "Confirmar si los documentos entregados están correctos",
    "generado_por": "IA asistida por Designer",
    "validado_por": "Researcher"
  },
  "bloques": [
    {
      "nombre_bloque": "Documentos pendientes",
      "accion_esperada": "Revisar cada documento entregado y marcar si está correcto o incorrecto",
      "campos": [
        {
          "paso": "Paso 2",
          "campo": "Selección 'Correcto / Incorrecto'",
          "tipo": "🌬️ Viento",
          "condicional": false}
      ]
    },
    {
      "nombre_bloque": "Observaciones",
      "accion_esperada": "Dejar comentarios sobre documentos incorrectos y registrar fecha de emisión",
      "campos": [
        {
          "paso": "Paso 2",
          "campo": "Comentario (solo si es Incorrecto)",
          "tipo": "🪨 Roca",
          "condicional": true},
        {
          "paso": "Paso 2",
          "campo": "Fecha del documento",
          "tipo": "🪨 Roca",
          "condicional": false}
      ]
    }
  ],
  "meta": {
    "chat_origen": "chat-lexy://modulo-4.2.3.2",
    "designer": "Nombre del Designer",
    "researcher": "Nombre del Researcher",
    "fecha": "2025-05-XX"
  }
}

```

---

### ✅ Consideraciones clave para la IA

- Cada **campo debe quedar vinculado a su paso original**.
- Los bloques deben incluir:
    - nombre funcional
    - una acción clara que se espera del usuario
    - los campos ordenados
    - su tipo (Roca/Viento)
    - si son condicionales
- La IA debe poder generar este documento **con solo haber completado correctamente las fases anteriores** (pasos, campos y agrupación), sin requerir reexplicación.

---

### **4.2.4 🛠 Prototipado**

Una vez generado el **JSON de bloques y campos** (con pasos, acciones, campos y tipo de esfuerzo), el Legal Designer guía la construcción del Desk **directamente desde el chat con el Agente Designer Lexy**.

Este agente está conectado a **Vercel vía API**, lo que permite construir y editar cada bloque de forma automática, sin tener que copiar código manualmente.

---

### 4.2.4.1 🧭 Objetivo

Construir el Desk en Vercel de forma **iterativa y trazable**, asegurando que:

- Cada bloque funcional se construya de forma independiente.
- Los campos ya definidos se traduzcan en una interfaz funcional.
- Se apliquen las mejores prácticas del **Lexy UI System**.

### 4.2.4.2🔹 **Paso 1 – Solicitar el prototipo de un bloque con estándar Lexy**

🧠 **Desde ChatGPT (Agente Designer Lexy)**

🎯 **Objetivo:** Activar la construcción del primer prototipo de un bloque del Desk en Vercel, con la mejor calidad posible desde el inicio.

---

💬 **Prompt estándar:**

> “Prototipemos en Vercel el bloque ‘Documentos pendientes’ del Desk ‘Validar documentos’.
> 
> 
> Usa el **JSON de bloques y campos** ya trazado en este chat (o disponible por ID).
> 
> Quiero que me entregues una **versión inicial de alta calidad**, como si ya hubiera pasado por testeo con usuarios:
> 
> - Diseño basado en la acción que el usuario debe ejecutar.
> - Campos ordenados y jerarquizados según su tipo (🪨 Roca / 🌬️ Viento).
> - Condicionalidad correctamente aplicada.
> - Ayudas visuales cuando corresponda.
> - Texto y botones con lenguaje humano.
> - Sin sobrecarga ni elementos innecesarios.
> 
> Aplica desde el inicio el **Lexy UI System**, incluyendo jerarquía visual, espaciado limpio, accesibilidad y tono claro.
> 
> Si algún campo no puede representarse correctamente, **explícamelo antes de mostrar el prototipo.**
> 
> Quiero una versión que me sorprenda:
> 
> *“Esto está tan bien resuelto que apenas necesito ajustar.”*
> 

---

📤 **Lo que el Agente IA debe devolver:**

- 🧱 Estructura completa del bloque
- ✅ Campos con clasificación (🪨 / 🌬️) y condicionalidad
- 🔗 Link al proyecto en Vercel (preview funcional)
- 📘 Breve explicación de decisiones tomadas por la IA

---

📌 **Notas para asegurar calidad:**

- El Agente debe aplicar directamente las guías del **Lexy UI System**, entendiendo que:
    - 🪨 Roca → requiere concentración → énfasis, ayudas, claridad visual.
    - 🌬️ Viento → requiere exploración → espacio, contexto, orientación.
- Si hay ambigüedad, el agente pregunta antes de avanzar.
- Toda la conversación y decisiones quedan trazadas en el chat

### 4.2.4.3🔹 **Paso 2 – Revisar y comentar el bloque generado (en ChatGPT)**

🧠 **Lugar:** ChatGPT (Agente Designer Lexy)

💻 **Referencia visual:** Link en Vercel

🎯 **Objetivo:** Evaluar la interfaz generada y dejar trazado el feedback, campo por campo, directamente en el chat.

---

### 🔁 ¿Cómo se realiza?

1. El Designer accede al **link de Vercel** generado por el agente.
2. Recorre visualmente el bloque como si fuera el usuario final.
3. Vuelve al chat con el Agente y da feedback libremente pero siendo meticuloso

---

### 🧠 Promptear bien es parte del trabajo

El trabajo de revisar y pedir mejoras no es solo una corrección, **es una habilidad estratégica**.

**Saber expresar con claridad lo que debe cambiar es parte clave del rol de Legal Designer.**

Si el Designer tiene dudas sobre cómo expresarse o qué pedir, **puede preguntarle al propio agente**, quien está capacitado para:

- Enseñarle a dar feedback efectivo.
- Explicar buenas prácticas de diseño en Lexy.
- Simular ejemplos de prompts bien construidos.

💬 *Ejemplo de consulta del Designer al agente:*

> “Quiero que este campo se vea más importante, como si estuviera envuelto o separado del resto.
> 
> 
> No sé bien cómo decirlo... ¿me enseñas cómo se pide eso en diseño UI?”
> 

---

📚 **Formación continua**

Todas las preguntas y dudas que los Designers expresan en el chat con el Agente quedan registradas en la meta data del Agente.

Esta información es revisada por el **Líder del equipo de Legal Designers**, quien:

- Detecta necesidades formativas comunes.
- Asegura acompañamiento personalizado.
- Construye mejores prácticas para el equipo.

---

📌 **Este paso no solo produce una interfaz mejor**, también mejora las habilidades del equipo y retroalimenta el sistema de aprendizaje continuo de Lexy.

### 4.2.4.4🔹 **Paso 3 – Conversar y ejecutar los ajustes solicitados (Agente IA)**

🧠 **Lugar:** ChatGPT (Agente Designer Lexy)

🎯 **Objetivo:** Aplicar los cambios pedidos por el Designer, conversando primero sobre cualquier complicación, y devolviendo el resultado con explicaciones claras.

---

📤 **Lo que el Agente IA debe hacer antes de ejecutar:**

- Leer el feedback completo del Designer.
- Comentar el feedback e identificar posibles complicaciones técnicas o ambigüedades.

Solo después de esta conversación, se realizan los cambios.

---

📤 **Lo que el Agente IA debe devolver tras ejecutar:**

- 🧱 **Bloque actualizado** con los cambios solicitados.
- 🔗 **Link al proyecto en Vercel** (preview funcional actualizado).
- 📘 **Breve explicación de decisiones tomadas por la IA**, incluyendo:
    - Qué se cambió.
    - Qué se negoció.
    - Qué se mantuvo o adaptó y por qué.

---

📌 **Notas para asegurar calidad:**

- El Agente debe aplicar directamente las guías del **Lexy UI System**, entendiendo que:
    - 🪨 Roca → requiere concentración → énfasis, ayudas, claridad visual.
    - 🌬️ Viento → requiere exploración → espacio, contexto, orientación.
- Si hay ambigüedad, el Agente **debe conversar antes de ejecutar**.
- Toda la conversación y decisiones quedan trazadas en el chat, formando parte del historial del diseño.

### 4.2.4.5🔹 **Paso 4 – Aplicar el estilo del Lexy UI System (bloque por bloque)**

🧠 **Lugar:** ChatGPT (Agente Designer Lexy)

🎯 **Objetivo:** Aplicar el estilo visual y la experiencia Lexy al bloque, dejando la versión lista para ser presentada a usuarios reales o al Consejo.

---

📌 **Este paso se activa una vez que el Designer ha cerrado su revisión funcional.**

El foco es estilizar el bloque para que **se sienta claro, usable y humano**, antes de su validación externa.

> En Lexy, se estiliza bloque por bloque. Cada unidad debe reflejar el estándar visual y emocional Lexy antes de pasar al siguiente.
> 

---

📤 **El Agente IA aplica:**

- 🪨 Roca → énfasis visual, ayudas visibles, ejemplos si es necesario
- 🌬️ Viento → aire, contexto, instrucciones claras
- Microcopy útil, accesibilidad visual y botones con intención
- Espaciado limpio, jerarquía visual y diseño sin fricción

---

📤 **El Agente IA devuelve:**

- 🔗 Link del bloque en Vercel (con estilo aplicado)
- 📘 **Breve explicación de decisiones visuales tomadas**, por ejemplo:
    
    > “Se aplicó estilo tarjeta al campo Roca.
    > 
    > 
    > Botón actualizado con lenguaje humano.
    > 
    > Espaciado ajustado para legibilidad entre secciones.”
    > 

---

✅ **El Designer puede responder con:**

1. **“Aceptado”**
    
    → El bloque queda **preparado para presentación externa**
    
    → Se avanza al siguiente bloque
    
2. **“Ajustes menores”**
    
    → El Agente los aplica y vuelve a mostrar el bloque
    
    → El ciclo se repite hasta aceptación
    
3. **“Rechazado”**
    
    → El Agente pide explicación breve y propone nueva solución
    
    → Si no se resuelve, el bloque puede marcarse como “en pausa” para revisión posterior
    

---

📌 **Este paso no cierra el bloque para siempre.**

Solo lo deja en estado **“Listo para validación externa”**, sea por usuario o Consejo.

La trazabilidad definitiva ocurre después de esa instancia.

### 4.2.4.6🔹 **Paso 5 – Validación integral del prototipo con usuarios clave, Researcher y Product Manager**

🧠 **Lugar:** Espacio compartido (videollamada + Vercel)

🎯 **Objetivo:** Presentar el **Desk completo** a usuarios reales, al Researcher y al Product Manager, observar su experiencia de principio a fin, y dejar trazadas todas las **deudas técnicas, funcionales o de experiencia** que emerjan antes del Consejo.

### 👥 Participantes recomendados:

- 🧑‍💼 Usuarios reales que ejecutan esta Big Task.
- 🔎 Researcher del flujo.
- 🧭 Product Manager del servicio.
- 🎨 Designer como facilitador

---

### 🖥️ Dinámica sugerida para la sesión:

📌 **Deuda técnica**

Esta sección queda pendiente para ser desarrollada por el próximo curador de la Biblia.

Debe definir con claridad el formato, las preguntas detonadoras y las herramientas colaborativas que se usarán para facilitar la conversación y documentar la validación del prototipo completo.

---

📓 **Lo que sí debe ocurrir al menos:**

- El prototipo completo se recorre en conjunto.
- Se escuchan reacciones, dudas y observaciones.
- Se anota en el chat del agente todo lo relevante, por bloque.

💬 *Ejemplo de trazado:*

> “Usuario no entendió cuándo usar ‘Documento complementario’ → posible fusión con otro bloque.”
> 
> 
> “Product Manager indica que falta lógica de integración con plataforma X → deuda técnica anotada.”
> 
> “Researcher propone eliminar paso 6: ya no ocurre en la práctica.”
> 

---

📌 **Resultado del Paso 5:**

- Validación real del Desk completo.
- Comentarios de usuarios y expertos operativos.
- Deudas trazadas por tipo: UX, funcional, técnica.
- Desk queda listo para presentación estratégica ante el Consejo.

---

## **4.2.5 🧙‍♂️Consejo del Servicio**

🎯 *Diagnóstico táctico para hacer más eficiente y efectivo cada paso operativo*

---

### 🧭 Objetivo del paso

Revisar el **Desk completo**, paso por paso, con el Consejo del servicio y los equipos tácticos, para **mejorar la ejecución futura** de cada acción mediante automatización, formación o soporte.

📌 **No se discute el diseño del Desk ni el orden de los pasos.**

Todo lo mostrado ya fue validado operativamente.

El único foco es:

> “¿Cómo ejecutamos este paso de la mejor forma posible?”
> 

---

### 👥 Participantes

- 🧠 **Researcher**: presenta los pasos operativos (flujo levantado)
- 🧑‍🎨 **Legal Designer**: muestra cómo se tradujeron en Vercel
- 🧭 **Product Manager**: toma nota de deuda, decisiones y próximos pasos
- ⚙️ **TI**: analiza posibles automatizaciones
- 🧑‍🏫 **Personas**: identifica oportunidades de formación, acompañamiento o documentación
- 🧩 **Miembros del Consejo del Servicio**

---

### 🧃 Estructura de la sesión

1. **Presentación del flujo (Researcher)**
    - Se muestran los pasos levantados, sin abrir a discusión.
    - Cada paso viene **etiquetado como**:
        - 🪨 **Roca** (estructurable, automatizable)
        - 🌬️ **Viento** (requiere criterio)
        - 🌀 **Mixto** (elementos de ambos)
2. **Recorrido rápido del Desk en Vercel (Designer)**
    - Solo para visualizar cómo cada paso se traduce en interfaz.
    - No se edita ni rediseña.
3. **Receso de 5 minutos**
    - Espacio para preparar ideas y pensar con foco.
4. **Diagnóstico paso por paso (moderado por Designer)**
    - Se discute cómo hacer **más eficiente** cada paso (automatización, simplificación)
    - Y cómo hacerlo **más efectivo** (formación, acompañamiento, claridad)
    - Se anotan propuestas, recursos necesarios y responsables

---

### 📓 Resultado esperado

- Se identifican acciones para mejorar la ejecución de cada paso:
    - Automatizar (TI)
    - Formar o acompañar (Personas)
    - Redefinir lógica operativa (Producto)
    - Trazar deuda pendiente (si no se puede resolver aún)
- El Product Manager deja todo documentado y prepara la priorización para la etapa siguiente (4.2.6)

---

### 🧾 Notas metodológicas

- Esta sesión **no evalúa el diseño visual ni el orden de los pasos.**
- Las preguntas clave no son “¿Esto está bien diseñado?”, sino:
    
    > “¿Qué necesitamos para que este paso no falle?”
    > 
    > 
    > “¿Qué haría este paso más simple, rápido o claro para quien lo ejecuta?”
    > 
- El protagonismo táctico se activa:
    - **TI automatiza**
    - **Personas forma o acompaña**
    - **Producto anota deuda o prioriza soluciones**

---

---

### **4.2.6 🍃 Notas metodológicas**

---

### **4.2.7 🔁 Paso a paso posterior al Kickoff**

### **4.2.6.1 📥 Revisión manual y marcaje del flujo**

### **4.2.6.2 📤 Carga inicial al agente IA Researcher**

### **4.2.6.3 🤖 Análisis inicial del agente IA**

### **4.2.6.4 ✅ Validación guiada por parte del Researcher**

### **4.2.6.5 📘 Diagnóstico de aprendizaje emergente**

### **4.2.6.6 📝 Generación del informe modular**

### **4.2.6.7 📚 Carga final al repositorio y la Biblia del Servicio**

---

## 4.3 3️⃣**🧩** Módulo Recordatorios Inteligentes

**(Preparación de Trinity: Biblia + Protocolo + Dataset por etapa)**

---

### 4.3.1 🔧 ¿Qué síntoma activa este módulo?

Una etapa del servicio tiene comunicaciones poco claras, fricciones frecuentes o baja tasa de cumplimiento ante tareas solicitadas.

Además, no existe una estructura vectorizable de interacciones, excusas ni respuestas.

---

### 4.3.2 🎯 Resultado esperado

- 📘 Una **Biblia Trinity por etapa**, con:
    - Interacciones informativas + plantillas + consultas frecuentes
    - Interacciones colaborativas + excusas + protocolos adaptativos
- 📂 Estructura de campos base para la **BBDD Trinity por cliente**
- 🧠 Reglas de respuesta IA según tipo de interacción, canal y comportamiento del cliente
- 📝 Insumos trazables para diseño posterior del Desk Trinity

---

### 4.3.3 🛠 Dinámica del módulo

| Fase | Acción |
| --- | --- |
| 🌟 Exploración | Revisión de correos reales, mensajes, fricciones, feedbacks |
| 🔧 Generación del tablero | Mapeo de interacciones (colaborativas / informativas) |
| 🍃 Facilitación | Discusión con CX o legales para tipificar excusas y validar protocolos |
| 🧾 Curaduría | Redacción de la Biblia CX por etapa |
| 📌 Registro | Guardado vectorial para IA y activación de tickets de diseño |

---

### 4.3.4 📎 Trazabilidad final

- 🧩 Tabla o visual curado por etapa
- ✅ Plantillas validadas
- 🧠 Reglas por excusa
- 📂 Campos propuestos para dataset por cliente
- 🔗 Enlace a la fase de diseño (Desk Trinity)

---

### 4.3.X🧩 Implementación técnica posterior a la Biblia (para desarrollo)

Una vez construida y validada la **Biblia CX de la etapa**, el equipo de desarrollo debe implementar la infraestructura que permita que la IA:

---

### ⚙️ 1. Proponga borradores de correo

- Basados en las plantillas curadas por etapa y tipo de interacción.
- Personalizados según la metadata del cliente (estado, excusa, canal, historial).
- Integrados con Gmail o herramientas externas mediante **Google Apps Script** si aplica.

---

### 💬 2. Gestione conversaciones en WhatsApp a través de Vambe

- La IA debe poder:
    - Leer y comprender el historial conversacional del cliente.
    - Proponer la próxima respuesta (modo supervisado).
    - Enviar directamente (modo autónomo, si está autorizado).
    - Registrar automáticamente: excusa detectada, tiempo de respuesta, resultado de la interacción.

### 4.3.X 🤖 Proyecto Trinity – IA Omnicanal de Experiencia Cliente

**Duración estimada:** 2 meses

### 🎯 Objetivo Final

Desarrollar un sistema de **interfaz Humano–IA** que gestione todas las comunicaciones con clientes en Lexy —por **correo, WhatsApp, Meta (Messenger/Instagram)** y otros canales futuros— con criterios de supervisión, aprendizaje continuo y trazabilidad.

Este sistema no es solo una IA que responde automáticamente, sino una **plataforma de conversación viva** donde:

- La IA **propone mensajes** según el contexto, el canal y el historial del cliente.
- Los humanos **supervisan, editan o aprueban** cuando es necesario.
- El sistema **aprende de las excusas, respuestas y resultados**, mejorando su criterio con cada interacción.
- Se establece una **base de datos por cliente** que permite personalizar cada mensaje y registrar decisiones clave.
- La experiencia conversacional es **orquestada desde una interfaz única (Trinity Desk)**, que integra todos los canales y niveles de autonomía IA.

En resumen, **Trinity es la interfaz donde vive, evoluciona y se curan todas las conversaciones con clientes en Lexy.**

---

## 🧠 Fundamento del Proyecto

El proyecto **Trinity** se basa en cuatro componentes conectados que permiten diseñar, entrenar y operar una IA que gestiona las interacciones con clientes, con criterio humano, trazabilidad y aprendizaje continuo.

### 🔩 Componentes estructurales

1. **📘 Biblia CX por servicio**
    
    Define todas las interacciones con clientes, sus plantillas, excusas frecuentes y protocolos.
    
    Están **agrupadas por etapa** del servicio y sirven como referencia principal para el entrenamiento y operación de Trinity.
    
2. **🧠 Agente IA de Research CX**
    
    Asiste a los Researchers en la construcción estructurada de las Biblias CX, recopilando interacciones reales, clasificando excusas y proponiendo protocolos.
    
3. **📂 Base de datos por cliente (BBDD Trinity)**
    
    Registra el historial de conversación, excusas, respuestas, etapa y nivel de autonomía de IA por cliente.
    
4. **🖥 Trinity – Desk Omnichannel**
    
    Interfaz tipo Kanban donde se supervisan, editan, entrenan y escalan todas las comunicaciones con clientes, desde el modo IA supervisada hasta su operación autónoma.
    

---

## 🟢 Fases de implementación

| Fase | Acción |
| --- | --- |
| 1️⃣ | Construir la **Biblia CX por servicio** con el apoyo del **Agente IA de Research CX**. |
| 2️⃣ | Levantar la **BBDD por cliente**, conectada al CRM y al historial de interacciones. |
| 3️⃣ | Activar el **Desk Trinity – Omnichannel** como espacio de supervisión, entrenamiento y operación. |

---

## 📘 Componente 1: Biblia CX por Servicio

Organizada por etapa, incluye dos grandes tipos de interacción:

---

### 🧩 A. Interacciones Informativas

> El cliente no debe hacer nada, solo entender lo que se le comunica.
> 

| Campo | Contenido |
| --- | --- |
| 💬 Plantilla de mensaje | Correo / WhatsApp |
| 🧭 Evento que lo detona | Cambio de etapa, resolución, ingreso |
| ❓ Consultas frecuentes | Preguntas típicas y respuestas sugeridas |
| 🛠 Protocolo de respuesta | ¿Responde IA? ¿Escala a humano? |
| 🚨 Umbral de fricción | Cuándo se desactiva la IA |

---

### 🧩 B. Interacciones Colaborativas

> El cliente debe realizar una acción concreta para que el caso avance.
> 

### 1. Definición de la interacción

| Campo | Contenido |
| --- | --- |
| 📥 Input requerido | Ficha, documento, firma, etc. |
| 📬 Plantilla inicial |  |
| Canal | Por correo y whatsapp |
| ⏰ Deadline  | Tiempo antes de dar de baja al cliente |
| 🔁 Secuencia de recordatorios | Frecuencia y duración máxima |
| 🎯 Propósito operativo | Qué permite avanzar o resolver |
| 🧑‍⚖️ Escalamiento a humano | ¿Cuando? |

---

### 2. Excusas frecuentes + Protocolo asociado

| Campo | Contenido |
| --- | --- |
| 💬 Excusa textual | Lo que dice el cliente |
| 🗂 Categoría | Salud, tiempo, frustración, técnica, emocional |
| 📬 Plantilla  |  |
| ⏰ Nuevo Deadline  |  |
| 🔁 Nueva Secuencia de recordatorios | ¿Sí/No? ¿Cuántos días? |
| 🧠 Adaptación del tono | Cambio de tono o contenido |
| 🧑‍⚖️ Escalamiento a humano | ¿Cuando? |
| Canal | Por el cual el cliente envio su ultima comunicación |

---

## 🧠 Componente 2: Agente IA de Research CX

### 🎯 Función

Guiar a los Researchers CX para estructurar las interacciones en cada etapa y servicio.

| Acción | Resultado |
| --- | --- |
| Detectar interacciones clave | Informativas y colaborativas |
| Recoger mensajes reales | Desde CRM, WhatsApp, Email |
| Clasificar excusas | Categorizar y agrupar |
| Definir protocolos | De pausa, adaptación o escalamiento |
| Proponer plantillas | Segmentadas por canal y tono |
| Identificar fricciones | Mejorar la Biblia |

---

## 📂 Componente 3: Base de Datos por Cliente (BBDD Trinity)

### 🎯 Propósito

Alimentar a la IA con contexto real y actualizado por cliente.

| Campo | Descripción |
| --- | --- |
| 📌 ID y etapa actual | Vinculado a CRM |
| 💬 Historial de mensajes | Correo y WhatsApp |
| 😖 Excusas registradas | Texto y categoría |
| 🤖 Nivel de autonomía IA | Supervisada / Parcial / Total |
| Otros |  |

---

## 🖥 Componente 4: Trinity – Desk Omnichannel

### 🎯 Propósito

Gestionar la operación y evolución del sistema conversacional IA.

Supervisa, entrena, y permite escalar las respuestas de Trinity.

---

### 📌 Vista principal: tablero Kanban

| Columna | Función |
| --- | --- |
| 🧑 Supervisión Humana | IA propone → humano valida |
| 🤖 Autonomía Parcial | IA responde → humano observa |
| ⚠ Fricción Detectada | Feedback negativo / NPS bajo / ticket |
| ✅ IA Autorizada | IA responde sola, revisión por muestra |

---

### 📂 Detalle de tarjeta (cliente)

- Historial completo de conversación (correo + WhatsApp)
- Propuesta IA editable
- Feedback estilo ChatGPT (“frío”, “confuso”, “repetido”)
- Botón "Asignar excusa" → conecta con protocolo en la Biblia CX
- Acceso directo a la ficha del cliente en la BBDD Trinity

---

## 📈 Ciclo de Escalamiento de Autonomía IA

| Fase | Descripción |
| --- | --- |
| 1️⃣ Supervisión total | IA propone, humano valida |
| 2️⃣ Supervisión parcial | IA responde, humano observa |
| 3️⃣ Autonomía total | IA responde sola |
| 4️⃣ Revisión por fricción | Si hay error, vuelve a supervisión |

---

# 5. 📚 Memoria Curada de los Módulos

## **5.1 Contexto y propósito**

La Memoria Curada por Módulo es el sistema que usamos para dejar registro de cada módulo cerrado, no solo como un informe técnico, sino como una fuente útil, reflexiva y vectorizable. Esta memoria permite:

- Revisar cómo se aplicó la metodología en distintos contextos.
- Detectar patrones repetidos entre etapas o servicios.
- Documentar ajustes metodológicos para futuras referencias.
- Entrenar al asistente IA con experiencias comparables y reales.
- Entregar insumos al design o product owner para la elaboración de maquetas o prototipos.

No reemplaza al Journey ni al informe final. Su valor está en dejar huella del proceso vivido: qué se intentó, qué funcionó, qué se adaptó y qué se aprendió. La memoria es una herramienta táctica para construir una cultura de diseño reflexiva, trazable y compartida.

---

## **5.2 ¿Qué se registra?**

Por cada módulo cerrado, se completa una ficha estructurada con:

- Contexto de la etapa
- Síntoma que justificó el módulo
- Aprendizajes por fase (exploración, tablero, facilitación)
- Enlaces al Journey y al informe
- Un resumen vectorizable que permite que la IA sugiera comparables

---

## **5.3 ¿Para qué sirve?**

- Detectar patrones funcionales entre etapas de distintos servicios
- Comparar cómo se han resuelto síntomas similares en otros contextos
- Documentar decisiones metodológicas que funcionaron (o no)
- Entrenar al asistente IA para ofrecer referencias útiles y precisas

---

## **5.4 Columnas de la Base de Datos para la trazabilidad semántica y comparativa**

### 5.4.1 📂 Datos generales (contexto base)

**Etapa** *(texto)*

> Permite identificar en qué punto del proceso se aplicó el módulo.
> 
> 
> Ayuda a comparar entre etapas equivalentes o con similar función operativa.
> 

**Servicio** *(selección)*

> Ubica el informe en un universo operativo (Salud, Litigios, Renegociación, etc.)
> 
> 
> Es útil para buscar comparables dentro del mismo servicio o para detectar diferencias entre servicios.
> 

**Descripción breve de la etapa** *(texto corto)*

> Condensa qué ocurre realmente en la etapa, más allá de su nombre.
> 
> 
> Este campo es clave para que la IA encuentre similitudes funcionales aunque la etapa tenga otro nombre.
> 

**Fecha de cierre** *(fecha)*

> Permite organizar cronológicamente los módulos y ver evolución de criterios.
> 
> 
> También ayuda a comparar versiones antiguas vs. actuales.
> 

**Researcher responsable** *(texto)*

> Ubica la autoría y estilo de ejecución.
> 
> 
> Puede ayudar a detectar estilos personales o aprendizajes repetidos entre Researcher.
> 

**Síntoma que activó el módulo** *(texto largo)*

> Es la huella más importante para comparar casos.
> 
> 
> Muestra el dolor real que llevó a activar el módulo, lo que permite agrupar por problemas comunes.
> 

---

### 5.4.2 🧠 Aprendizaje por fase (base para comprensión metodológica)

**Aprendizaje en la exploración** *(texto medio)*

> Deja registro de lo que se detectó en terreno.
> 
> 
> Clave para saber cómo se observan las tareas de los usuarios.  
> 

**Ajustes realizados al tablero y por qué** *(texto medio)*

> Muestra qué se adaptó al Journey base.
> 
> 
> Útil para ver qué estructuras resisten cambios y cuáles se modifican según la etapa.
> 

**Aprendizaje en la facilitación del Kickoff** *(texto medio)*

> Refleja la calidad del cierre con el equipo.
> 
> 
> Detecta si hubo participación real, validación efectiva o barreras metodológicas.
> 

---

### 5.4.3📎 Enlaces y cierre (referenciabilidad)

**Link al informe completo (PDF/Markdown)** *(enlace)*

> Documentación integral de todo el proceso.
> 
> 
> Clave para trazabilidad documental, formación de nuevos Researcher y lectura curatorial.
> 

**¿Fue cargado en la Biblia del Servicio?** *(checkbox)*

> Marca si ese caso está disponible como ejemplo dentro del sistema de conocimiento.
> 
> 
> Ayuda a mantener actualizada la curaduría.
> 

---

### 5.4.4🧠 CURADOR– Para trazabilidad vectorial

1. **Resumen vectorizable (IA only)** *(texto oculto o técnico)*

> Texto estructurado y sintético que condensa la naturaleza funcional de la etapa, síntomas, estructura del Journey y ajustes.
> 
> 
> Permite a la IA comparar etapas aunque tengan distinto nombre, servicio o Journey.
> 
> Ejemplo:
> 
> `Etapa sin decisiones humanas. Trigger principal: cliente envía ficha. Síntoma: no hay reacción clara posterior. Journey simplificado. Comparable a Onboarding de Renegociación.`
> 

---

## 5.5 Base de Datos

[Informes por Modulos - Research](%F0%9F%93%97%20%F0%9F%94%8E%20Biblia%20Research%20Core%20v%202%205%201fa2f9107409803890def9c4bb9bc362/Informes%20por%20Modulos%20-%20Research%201fc2f9107409801291c5f4eac18214bf.csv)

---